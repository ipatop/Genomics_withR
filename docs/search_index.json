[
["index.html", "Genomics with R for biologists Overview 0.1 Course Aims 0.2 Intended Learning Outcomes 0.3 Next steps 0.4 Data availability 0.5 Acknowledgments", " Genomics with R for biologists Ines Lucia Patop inespatop@brandeis.edu 2020-08-30 Overview The idea of the practical part will be to give you tools to be able to manage regular data-analysis in molecular biology labs. Also we think that this training in basic programing and statistics will be of high value for your future projects. 0.1 Course Aims Learn basic coding intuition and usage of R for analysis and plots. Undestand the main issues we have to deal with in Genomics. Learn how to do basic analysis, Chipseq, RNAseq, SingleCell. 0.2 Intended Learning Outcomes By the end of this course students will be able to: Create your own R code. Do basic and complex analysis. Read and understand R code. 0.3 Next steps I have a project on shell commands for biologist. Will be available soon. 0.4 Data availability All the data used in this book is publiclily available. Preprocessed files can be found in this reposotory 0.5 Acknowledgments Ane Martin Anduaga and Sebastian Kadener for usefull discussion. "],
["introduction-to-r-and-rstudio.html", "Lab 1 Introduction to R and RStudio 1.1 Objectives 1.2 Introduction 1.3 RStudio world 1.4 Create a project 1.5 Useful shortcuts in RStudio: 1.6 Installing and loading packages 1.7 Creating objects 1.8 R as a calculator 1.9 Functions 1.10 Loops 1.11 Conditions 1.12 Character objects 1.13 Identify 1.14 Modify 1.15 Useful resources 1.16 Activity:", " Lab 1 Introduction to R and RStudio 1.1 Objectives After this section you should be able to: Create projects and scripts in RStudio Install and load packages Do basic statistical analysis and plots Create basic for loops and if conditionals 1.2 Introduction We will be working with R and Rstudio, a user-friendly platform to use R. So, first you will need to download both R and RStudio. R is open-source and free programing language. This means that everybody, and I mean all of us, can collaborate, create packages and share things with others. This also means that everything we make in R is for public use and that, vice versa, we can use everything that anybody did in R. R is “object-orientated” a programing language. This basically means that most of the “things” in the environment are objects. I will not go deeper into it, but you can read more here. You will see in this class different types of objects. Each type of object has different properties which means we can not do everything with each type of object. In this class we will give you some data and simple tasks so you can start playing around and get use to basic commands and operators. But first, we will need to establish some common language: Let’s try to see some of the definitions more commonly used so we can understand them. I recommend you to do some research on your own. Shell or Terminal: the computer shell is a user interface to access to an operating system’s services. In linux and mac is easier to access. You can read more here. Programing language: is a language in a wide sense, ie, it is a set of rules in which you can give orders to the computer. A computer basically, computes. Yes, that is why they are called computers. Then, you can use your computer as a calculator, as a table manager, to write text, etc. The idea is that if you know the language of a programing language you can tell your computer to do stuff for you. We will use R language. Script: a text file that has the code (text in the programing language you are using) you will execute in the computer. In order for this to be executed you need to “copy-paste” the parts of code you wanna run into the shell. We will work in R-studio so this is done automatically with the ctr-enter command. Working Directory: in which folder (or directory) of your computer you will be running the code. As default R will run in your base-directory. This is the core of your computer. I recommend you to have a specific folder inside the documents folder with each of you projects and to run everything there. We will learn also how to set this up. Environment: All the objects, functions and everything you have loaded at that moment. This is a short-term memory thing. If we do not save this, everything we did will be deleted after we close the program. It would be like the words you have a in a text file if you do not save the file they will be lost. Functions: as mathematical functions, this takes inputs and generates outputs. We will see some in this class. For loop, if, else: this are basic logic operators that allows us to generate specific outputs. We can use it inside functions or as independent. Package: R has the option to load many premade functions. The R package is a set of documented functions that someone did and put to be available for the rest of the community. We will use in this course many of them like: DeSeq2, ggplot2, etc. 1.3 RStudio world R Studio has everything integrated. You can have the script, the environment, the actual shell and a useful window to access data and to view the plots and see the manual and description of every function and package. Here we can create a project in which everything will be integrated. This might not be the most efficient thing in terms of memory use but is the simplest for now. When you start to understand the logic of the programing language I encourage you to run R in different supports like typing “R” in your computer shell and run directly from command line. Regarding RStudio see the image bellow: Figure 1.1: Regular RStudio setup. Upper left panel: the script. Everything you write here you can just execute by pressing CTR + ENTER. Upper right panel: the environment. Lower left panel: the “console”, work exactly as the terminal. Is the representation of the terminal just for R. If you want, you can run other things that are not R in the shell (not the console), if you are interested read this nice article https://support.rstudio.com/hc/en-us/articles/115010737148-Using-the-RStudio-Terminal Lower Right: The multi layer panel that allows you to see and browse the files, plots and help pages. 1.4 Create a project 1. Open RStudio: Create a project: File &gt; New Project… &gt; Existing Directory &gt; choose the folder. Automatically this should change the working directory to this folder. However, it is nice to check this we should run the following command: getwd() #Get working directory 2. Create the script: File &gt; New File… &gt;R Script Now we can start putting things in the script and running them in the “console” or representation of the shell in RStudio. So, let’s check the working directory and change it if needed. To run the command, just write “getwd()” and press CTR+ENTER. This should generate this in the “Console”: getwd() [1] &quot;/Users/skl/Documents/Class/0_class&quot; #here your working directory Now we know how to run things in RStudio. Save the script and the working directory: when you close the project it will automatically ask. I recommend to save at least the script everytime you can. File &gt; save 1.5 Useful shortcuts in RStudio: tab: auto-complete control + the up arrow or command + up arrow: auto-complete tool that works only in the interactive console control + enter or command + enter: executes the selected lines of code control + s : save 1.6 Installing and loading packages When we open R the basic package with all the basic functions is loaded but we will use other functions from other packages. For now, we will start with ggplot2. This is not installed in our computer yet so we have to install it. This is done only ONCE in the computer. Then we need to load it in the current environment. This is done EVERY TIME we reopen R. install.packages(&quot;ggplot2&quot;) #only once library(&quot;ggplot2&quot;) #everytime we reopen R session You might have noticed that I use “#” this a good way to add comments to the code. Any line that begins with a “#” will NOT be executed. We will be using packages that are part of Bioconductor. This is a big repository for biological relevant packages. They are installed in this way: if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) #only once BiocManager::install(&quot;DESeq2&quot;) #only once library(&quot;DESeq2&quot;) 1.7 Creating objects Objects in R are created using the assign symbols: &lt;- and = as follows: object.name &lt;- Object.Assingnemet. This means that objects names should start with a letter and should NOT contain spaces. You can replace them with a dot or an underscore. Objects can be of different class and will be overwritten without any warnings. If we execute the object name we will access it as better as the Console can do it. For numbers it is simple but you will notice that for other objects it is not. x&lt;-0.5 x class(x) #this tells us the class of the x object ## [1] 0.5 ## [1] &quot;numeric&quot; If we assign other thing to x, it will be overwritten: x&lt;-1 #this is overwriting x x class(x) #this tells us the class of the x object ## [1] 1 ## [1] &quot;numeric&quot; We can create as many objects as we want y&lt;-2.3 y class(y) ## [1] 2.3 ## [1] &quot;numeric&quot; 1.8 R as a calculator R will operate as a calculator for numbers. It has a lot of prebuilt functions. Let’s see one obvious. x+y (x+y)/2 ## [1] 3.3 ## [1] 1.65 We can now apply this sum a new object z&lt;-x+y z ## [1] 3.3 And divide it by 2. z/2 ## [1] 1.65 Which is the same as doing the mean of x and y. mean(c(x,y))#what is this c()???? ## [1] 1.65 To create a vector of numbers (or anything), you can just use c(n1,n2), you can also store this vector in a new object. v&lt;-c(x,y) v class(v) ## [1] 1.0 2.3 ## [1] &quot;numeric&quot; You can now use it inside fucntions. mean(v) ## [1] 1.65 We can add (append) more elemts to the vector. t&lt;-c(v,5) t mean(t) #...and so on ## [1] 1.0 2.3 5.0 ## [1] 2.766667 1.9 Functions We can think as functions exactly as we know mathematical functions. They take an input and generate an output. \\[ y=f(x) \\] \\[ output=function(input) \\] In R language that looks like this: nameofunction&lt;-function(x){ what the function does } and the can do literally anything R can do. Math, plot, modify tables, etc. Lets create a new mean function. We will call is mean.us. This will take the mean of two numbers. They will be called n1 and n2. mean.us&lt;-function(n1,n2){ y&lt;-((n1+n2)/2) return(y) #return is the one part of this function that actually makes it to return a value } #lets see if this works mean.us(2,3) ## [1] 2.5 We can make it even more fancy and print a message mean.us&lt;-function(n1,n2){ y&lt;-((n1+n2)/2) return(paste0(&quot;The mean of &quot;,n1,&quot; and &quot;,n2,&quot; is: &quot;,y)) } mean.us(2,3) ## [1] &quot;The mean of 2 and 3 is: 2.5&quot; We can do now the mean plus 1 mean.plus1&lt;-function(n1,n2){ y&lt;-((n1+n2)/2+1) return(paste0(&quot;The mean of &quot;,n1,&quot; and &quot;,n2,&quot; plus one is: &quot;,y)) } mean.plus1(2,3) ## [1] &quot;The mean of 2 and 3 plus one is: 3.5&quot; 1.10 Loops Loops are useful to apply a function or an action to multiple objects. We will see for loops but be aware that another common loop type is the while loop. For loops will go over each element of a vector or list provided. In R language they look like this: for (x in vector) { DO SOMETHING }. And it literally means that it will go over each element of the vector, each time x will take the value of the element it goes that time and will do something. #i this is a little complex so lets go one step at a time: i is an object that will be getting the value of each elemnt we go thru for(x in c(1,2,3,4)){ print(paste0(&quot;x is: &quot;,x)) } ## [1] &quot;x is: 1&quot; ## [1] &quot;x is: 2&quot; ## [1] &quot;x is: 3&quot; ## [1] &quot;x is: 4&quot; We can now do something more complex inside the loop. for(x in c(1,2,3,4)){ c=x/2 print(paste0(&quot;c is: &quot;,c)) } ## [1] &quot;c is: 0.5&quot; ## [1] &quot;c is: 1&quot; ## [1] &quot;c is: 1.5&quot; ## [1] &quot;c is: 2&quot; We can also loop over vectors that are already in our list of objects. #t is mande of many elements already t #if we want to sum 1 to each element in t and print it out we can do as follows for(i in t){ print(i) c=i+1 print(c) } ## [1] 1.0 2.3 5.0 ## [1] 1 ## [1] 2 ## [1] 2.3 ## [1] 3.3 ## [1] 5 ## [1] 6 This is usefull for other type of lists and vectors vec&lt;-c(&quot;a&quot;,&quot;b&quot;) for (i in c(vec)){ print(paste0(&quot;i is: &quot;,i)) } ## [1] &quot;i is: a&quot; ## [1] &quot;i is: b&quot; And we can access it in differen ways: for (i in 1:length(vec)){ print(paste0(&quot;i is: &quot;,i)) print(paste0(&quot;elemnt i is: &quot;,vec[i])) } ## [1] &quot;i is: 1&quot; ## [1] &quot;elemnt i is: a&quot; ## [1] &quot;i is: 2&quot; ## [1] &quot;elemnt i is: b&quot; 1.11 Conditions R assigns using = and compares using ==,&lt; and &gt;. It can then use if and else to generate conditions and actions. This can be more complex by adding AND, OR gates with &amp; and | respectively. x=1 #lets explore x x ## [1] 1 Compare, equal to: x==1 ## [1] TRUE Smaller than: x&lt;2 ## [1] TRUE Bigger than: x&gt;2 ## [1] FALSE Apply this comparisons to an if/else: if (x &lt; 2){ c=x+1 print(paste0(&quot;c is: &quot;, c)) } else { print(&quot;x is too big&quot;) } ## [1] &quot;c is: 2&quot; Change the condition: if (x &lt; 1){ c=x+1 print(paste0(&quot;c is: &quot;, c)) } else { print(&quot;x is too big&quot;) } ## [1] &quot;x is too big&quot; 1.12 Character objects So far, we saw opperations with numbers. But R can have objects with words or characters. We can have a complex phrase phrase&lt;-&quot;I am a beatufill phrase. Hello world&quot; phrase ## [1] &quot;I am a beatufill phrase. Hello world&quot; Or a vector of character elements: chrvec&lt;-c(phrase,&quot;abcde&quot;,&quot;67&quot;) chrvec ## [1] &quot;I am a beatufill phrase. Hello world&quot; ## [2] &quot;abcde&quot; ## [3] &quot;67&quot; class(chrvec) ## [1] &quot;character&quot; 1.13 Identify We can operate over them. For example, we can select the elemnt that has certain characteristic. For this we will use grep. This is based on regualar expression. Lets select the elemnts that have the letter d. grep(pattern = &quot;d&quot;,x = chrvec,value = T) ## [1] &quot;I am a beatufill phrase. Hello world&quot; ## [2] &quot;abcde&quot; grep(pattern = &quot;d&quot;,x = chrvec,value = F) #What changed between the previous one and this one? ## [1] 1 2 Clearly, the fist two elements have the letter d. What if we want to select the one that has it at the end? grep(pattern = &quot;d$&quot;,x = chrvec,value = T) ## [1] &quot;I am a beatufill phrase. Hello world&quot; The same can be done for the begining. This of course gives us an empty result. grep(pattern = &quot;^d&quot;,x = chrvec,value = T) ## character(0) 1.14 Modify We can modify the objects. We will use gsub gsub(pattern = &quot;d&quot;,replacement = &quot;I am replacing d&quot;,x = chrvec) ## [1] &quot;I am a beatufill phrase. Hello worlI am replacing d&quot; ## [2] &quot;abcI am replacing de&quot; ## [3] &quot;67&quot; 1.15 Useful resources A package to learn R: Swirl Support from RStudio: Usefull resource with usefull packages in R Girhub: Bioinformatic resources Free books: R for data science unix command line 1 unix command line 2 data structure with python 1.16 Activity: Create a new funciton that has inside a for loop and other that has an if/else condition. plus.one.onlyifpos &lt;- function(n){ if(n &gt; 0){ return(n+1) } else { return(&quot;number is negative&quot;) } } plus.one.onlyifpos(20) plus.one.onlyifpos(-20) "],
["data-manipulation.html", "Lab 2 Data manipulation 2.1 Objectives 2.2 Introduction 2.3 Load data 2.4 Data exploration 2.5 Subsetting 2.6 Activity:", " Lab 2 Data manipulation 2.1 Objectives After this section you should be able to: Load, explore and manipulate data in R 2.2 Introduction One of the main uses of R is for data manipulation and plot. This is similar to what many of us do in any regular table editor as excel or google spread sheet. We will use the following packages. You can read in detail the manual of each of them. #Install packages #install.packages(&quot;ggplot2&quot;) #install.packages(&quot;dplyr&quot;) #install.packages(&quot;plyr&quot;) #Load the package library(&quot;ggplot2&quot;) library(&quot;dplyr&quot;) library(&quot;plyr&quot;) library(RColorBrewer) library(car) #Manuals #vignette(&quot;dplyr&quot;) #?ggplot2 #?plyr 2.3 Load data There are many ways to load data. In the following chapters we will use a diverse set of functions to read the data from files. Some of them are: read.table() #general to any type of table read.csv() #specific for comma sepparated tables read.delim() #specific for tab delimited tables Some of the important options of these function are: read.table(file = &quot;location/of/your/file.txt&quot;,sep = &quot;.&quot;,header = T or F) Where the separator can be a comma, dot, etc. You can see more details using: ?read.table In this case we will use data that is already available in R. The package datasets provides a handful set of data to analyze. We will use the ChickWeight dataset. This is data set of weight in chickens with age an different diet. This will allow us to visualize the data and to do some statistic tests. # Install the package #install.packages(&quot;datasets&quot;) # For a full list of these datasets, type library(help = &quot;datasets&quot;) # Load the library and dataset library(datasets) data(ChickWeight) #What happens in the Environment section of RStudio? 2.4 Data exploration It is important to understand the data before heading into the analysis. We will go over some techniques for this. # To see the table, you can click on the environment part or run this... #View(ChickWeight) # As you can see this is a table, just in case we want to convert it to a data.frame ChickWeight&lt;-as.data.frame(ChickWeight) To see only the beginning, we can use the head function: head(ChickWeight) ## weight Time Chick Diet ## 1 42 0 1 1 ## 2 51 2 1 1 ## 3 59 4 1 1 ## 4 64 6 1 1 ## 5 76 8 1 1 ## 6 93 10 1 1 What is n doing? head(ChickWeight,n = 20) ## weight Time Chick Diet ## 1 42 0 1 1 ## 2 51 2 1 1 ## 3 59 4 1 1 ## 4 64 6 1 1 ## 5 76 8 1 1 ## 6 93 10 1 1 ## 7 106 12 1 1 ## 8 125 14 1 1 ## 9 149 16 1 1 ## 10 171 18 1 1 ## 11 199 20 1 1 ## 12 205 21 1 1 ## 13 40 0 2 1 ## 14 49 2 2 1 ## 15 58 4 2 1 ## 16 72 6 2 1 ## 17 84 8 2 1 ## 18 103 10 2 1 ## 19 122 12 2 1 ## 20 138 14 2 1 What is the structure of the data.frame? str(ChickWeight) ## &#39;data.frame&#39;: 578 obs. of 4 variables: ## $ weight: num 42 51 59 64 76 93 106 125 149 171 ... ## $ Time : num 0 2 4 6 8 10 12 14 16 18 ... ## $ Chick : Ord.factor w/ 50 levels &quot;18&quot;&lt;&quot;16&quot;&lt;&quot;15&quot;&lt;..: 15 15 15 15 15 15 15 15 15 15 ... ## $ Diet : Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## - attr(*, &quot;formula&quot;)=Class &#39;formula&#39; language weight ~ Time | Chick ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;outer&quot;)=Class &#39;formula&#39; language ~Diet ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;labels&quot;)=List of 2 ## ..$ x: chr &quot;Time&quot; ## ..$ y: chr &quot;Body weight&quot; ## - attr(*, &quot;units&quot;)=List of 2 ## ..$ x: chr &quot;(days)&quot; ## ..$ y: chr &quot;(gm)&quot; With the $ operator we can explore the columns class(ChickWeight$weight) ## [1] &quot;numeric&quot; We can see the dimensions of the table for example: how many rows it has? nrow(ChickWeight) ## [1] 578 How many columns? ncol(ChickWeight) ## [1] 4 The names of columns names(ChickWeight) ## [1] &quot;weight&quot; &quot;Time&quot; &quot;Chick&quot; &quot;Diet&quot; With the [] we can access the individual elements names(ChickWeight)[3] ## [1] &quot;Chick&quot; We can see the levels of a factor levels(ChickWeight$Diet)[1:3] ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; What is the difference if we just print the column? ChickWeight$Diet[1:3] ## [1] 1 1 1 ## Levels: 1 2 3 4 Can we see the levels of a numeric vector? This is a reminder that the data type is important. levels(ChickWeight$weight) # nop We can now get different basic statistics now: mean(ChickWeight$weight) ## [1] 121.8183 summary(ChickWeight$weight) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 35.0 63.0 103.0 121.8 163.8 373.0 summary(ChickWeight) ## weight Time Chick Diet ## Min. : 35.0 Min. : 0.00 13 : 12 1:220 ## 1st Qu.: 63.0 1st Qu.: 4.00 9 : 12 2:120 ## Median :103.0 Median :10.00 20 : 12 3:120 ## Mean :121.8 Mean :10.72 10 : 12 4:118 ## 3rd Qu.:163.8 3rd Qu.:16.00 17 : 12 ## Max. :373.0 Max. :21.00 19 : 12 ## (Other):506 To see what is this exactly doing, just go to the help page: ?summary To save this summary table we can create an object with just the result of the summary chick_sumary&lt;-summary(ChickWeight) chick_sumary ## weight Time Chick Diet ## Min. : 35.0 Min. : 0.00 13 : 12 1:220 ## 1st Qu.: 63.0 1st Qu.: 4.00 9 : 12 2:120 ## Median :103.0 Median :10.00 20 : 12 3:120 ## Mean :121.8 Mean :10.72 10 : 12 4:118 ## 3rd Qu.:163.8 3rd Qu.:16.00 17 : 12 ## Max. :373.0 Max. :21.00 19 : 12 ## (Other):506 class(chick_sumary) ## [1] &quot;table&quot; We can change the data kind, and assign it to a different object chick_sumary_df&lt;-as.data.frame(chick_sumary) This is not that useful as you can see if you inspect the data in using View(chick_sumary_df) this is because it is a complicated format, we better just save the table. We will see other ways to save data in R in the future chapters. You can see more details using: ?write.table write.table(chick_sumary, &quot;mydata.txt&quot;, sep=&quot;\\t&quot;,row.names = F,col.names = T) #this is clearly no perfect but for the important part, the numeric and integer columns, we have the stat 2.5 Subsetting Subsetting means extracting part of the data. There are many different ways to do this. One important notion for tables and data frames is that dimensions go as follows: data[row,column] #we can see specific columns and rows ChickWeight[1,1:3] #row 1, column 1:3 ## weight Time Chick ## 1 42 0 1 ChickWeight[1:3,1] #col 1, row 1:3 ## [1] 42 51 59 ChickWeight[1,1] #row1, col1 ## [1] 42 If we want to know for example only the data from the chickens taking the diet 4 head(ChickWeight[ChickWeight$Diet==4,]) ## weight Time Chick Diet ## 461 42 0 41 4 ## 462 51 2 41 4 ## 463 66 4 41 4 ## 464 85 6 41 4 ## 465 103 8 41 4 ## 466 124 10 41 4 Why == and no =? Remember in R, = is an assignment, as the &lt;-, while the == is for comparison. head(ChickWeight$Diet==4) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE Lets explore the class: class(ChickWeight$Diet==4) ## [1] &quot;logical&quot; So, when we do ChickWeight[ChickWeight$Diet==4,], R is just showing the ChickWeight for which ChickWeight$Diet==4 is TRUE head(which(ChickWeight$Diet==4)) ## [1] 461 462 463 464 465 466 head(ChickWeight[ChickWeight$Diet==4,]) ## weight Time Chick Diet ## 461 42 0 41 4 ## 462 51 2 41 4 ## 463 66 4 41 4 ## 464 85 6 41 4 ## 465 103 8 41 4 ## 466 124 10 41 4 And for more conditions, we can use AND (&amp;) to integrate them. head(ChickWeight[ChickWeight$Diet==4 &amp; ChickWeight$Time&gt;6,]) ## weight Time Chick Diet ## 465 103 8 41 4 ## 466 124 10 41 4 ## 467 155 12 41 4 ## 468 153 14 41 4 ## 469 175 16 41 4 ## 470 184 18 41 4 Other option is OR (|). Remember, computers will read as things come \\[ condition-A AND condition-B OR condition-C condition-A &amp; condition-B | condition-C \\] Is not the same as \\[ condition A &amp; (condition B | condition C) \\] head(ChickWeight[ChickWeight$Diet==4 &amp; ChickWeight$Time&gt;6 &amp; ChickWeight$Time&lt;20,]) ## weight Time Chick Diet ## 465 103 8 41 4 ## 466 124 10 41 4 ## 467 155 12 41 4 ## 468 153 14 41 4 ## 469 175 16 41 4 ## 470 184 18 41 4 And if we just want the weights of these… ChickWeight$weight[ChickWeight$Diet==4 &amp; ChickWeight$Time&gt;6 &amp; ChickWeight$Time&lt;20,] why this gives an error? Because we only have one dimension now, not 2. ChickWeight$weight is one dimention object, so we have to use [ ], not [ , ]. head(ChickWeight$weight[ChickWeight$Diet==4 &amp; ChickWeight$Time&gt;6 &amp; ChickWeight$Time&lt;20]) ## [1] 103 124 155 153 175 184 2.6 Activity: This activity integrates knowledge from the previous chapter. 1. Remove the first and last row of the ChickWeight data frame 2. Create a vector with the second column from the data frame "],
["visualization-and-statistical-test.html", "Lab 3 Visualization and Statistical test 3.1 Objectives 3.2 Introduction 3.3 Plots 3.4 Statistical test 3.5 Activity: 3.6 Resources", " Lab 3 Visualization and Statistical test 3.1 Objectives After this section you should be able to: Plot and explore the data in many ways. Do statistical tests on the data. 3.2 Introduction We will use the same data we already explored in last chapter. Remember: chickens weight, age (Time) for different diets. There are many things we can explore in this data. Each question we might want to answer will be better addressed using different plots. For example: 1. If the chickens are older we expect them to be bigger. This can be visualized using a dotplot. 2. We might want to see the distribution of weight separated by diet. This can be addressed by a histogram. 3.3 Plots We will use the package ggplot2. It is a very useful and documented package. We will focus on the ggplot function. This function generates plots as layers. This allows us to manipulate the colors, the plot type, etc. I know it can be difficult to understand it at the beginning but after a while it becomes really intuitive. Important things to consider: 1. We will be able to plot anything that is a column in the data frame. 2. Everything is or can be a layer in the plot. 3. When you decide to color or shape by a factor that separates your data this will impact the plot. Again,we can plot any column. So lets axplore the columns. It is important to know the class of each column. It is not the same trying to plot a number, than a letter. names(ChickWeight) #names of the columns in the data frame ## [1] &quot;weight&quot; &quot;Time&quot; &quot;Chick&quot; &quot;Diet&quot; head(ChickWeight) #head of the data frame ## weight Time Chick Diet ## 1 42 0 1 1 ## 2 51 2 1 1 ## 3 59 4 1 1 ## 4 64 6 1 1 ## 5 76 8 1 1 ## 6 93 10 1 1 str(ChickWeight) #structure of the data frame ## &#39;data.frame&#39;: 578 obs. of 4 variables: ## $ weight: num 42 51 59 64 76 93 106 125 149 171 ... ## $ Time : num 0 2 4 6 8 10 12 14 16 18 ... ## $ Chick : Ord.factor w/ 50 levels &quot;18&quot;&lt;&quot;16&quot;&lt;&quot;15&quot;&lt;..: 15 15 15 15 15 15 15 15 15 15 ... ## $ Diet : Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## - attr(*, &quot;formula&quot;)=Class &#39;formula&#39; language weight ~ Time | Chick ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;outer&quot;)=Class &#39;formula&#39; language ~Diet ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;labels&quot;)=List of 2 ## ..$ x: chr &quot;Time&quot; ## ..$ y: chr &quot;Body weight&quot; ## - attr(*, &quot;units&quot;)=List of 2 ## ..$ x: chr &quot;(days)&quot; ## ..$ y: chr &quot;(gm)&quot; 3.3.1 Line and points To see things as correlations, we usually use points and lines. We will see how to do it using different plot options. Dot plot with basic qplot (from ggplot but les complex) qplot(data=ChickWeight,x = weight, y=Time, geom = c(&quot;line&quot;,&quot;point&quot;)) Figure 3.1: Point and line plots qplot(data=ChickWeight,x = weight, y=Time, geom = c(&quot;line&quot;,&quot;point&quot;), colour=Diet) #adding the color helps to separate the data Figure 3.2: Point and line plots The same using ggplot: ggplot(data = ChickWeight, aes(y = weight, x=Time,colour=Diet))+ #data and basic things about the plot geom_point() + #add the type of plot scale_colour_brewer(palette = &quot;Set1&quot;) #add a colot pallet Figure 3.3: Point and line plots ggplot(data = ChickWeight, aes(y = weight, x=Time,colour=Diet))+ #data and basic things about the plot geom_point() + #add the type of plot geom_smooth() + #add a trend line of mean plus se scale_colour_brewer(palette = &quot;Set1&quot;) Figure 3.4: Point and line plots 3.3.2 Historgam and density plots Histograms are used to represent the distribution of a variable over the population. If you want to read more you can go to this link. Other way to represent the same thing is to use cumulative plots we are not going to explore them now but if you are interested in doing them with ggplot you can go to this link Density plots are similar to histograms but implies a more complex treatment of the data. They look like smooth histogram. They are the probability density function of the variable. qplot(data = ChickWeight,x=weight, binwith=10) Figure 3.5: Histogram and Density plots qplot(data = ChickWeight,x=weight, binwith=10, colour=Diet) #the color separates the data Figure 3.6: Histogram and Density plots qplot(data = ChickWeight,x=weight, geom = &quot;density&quot;, colour=Diet) Figure 3.7: Histogram and Density plots With ggplot ggplot(data = ChickWeight, aes(x=weight,color=Diet))+ geom_histogram(fill=&quot;white&quot;, position=&quot;identity&quot;)+ scale_colour_brewer(palette = &quot;Set1&quot;)#this is selecting the color scheme, try taking it out, or mofyfying it Figure 3.8: Point and line plots ggplot(data = ChickWeight, aes(x=weight,fill=Diet))+ geom_density( alpha=0.5)+ #the density plot with the option to modify the transparency of the polot solor, it goes between 0 and 1. Try modifying it. scale_colour_brewer(palette = &quot;Set1&quot;) Figure 3.9: Point and line plots 3.3.3 Boxplot Boxplots are a nice way to visualize the data distribution and to get and intuition of how this is different between conditions. As you can see in this figure, it summarizes a LOT of information: Figure 3.10: Boxplot description. Figrue affapted from https://www.simplypsychology.org/boxplots.html ggplot(data = ChickWeight, aes(y=weight,x=as.factor(Time),fill=Diet))+ #Note how the x, y and color changes geom_boxplot()+ #this is adding the boxplot scale_colour_brewer(palette = &quot;Set1&quot;) Figure 3.11: Boxplot What happens if we do not use the as.factor? Again, a reminder that the data type is important! ggplot(data = ChickWeight, aes(y=weight,x=Time,fill=Diet))+ geom_boxplot()+ #this is adding the boxplot scale_colour_brewer(palette = &quot;Set1&quot;) Figure 3.12: Boxplot It seems interesting to separate this by age (Time). This is achieved by another layer named facet. ggplot(data = ChickWeight, aes(x=weight,fill=Diet))+ geom_density( alpha=0.5)+ scale_colour_brewer(palette = &quot;Set1&quot;)+ facet_wrap(~Time,scales = &quot;free&quot;) #This will separate the data into panels given the time, try looking for the meaning of the scale option Figure 3.13: Plot separating by age of the chicken ggplot(data = ChickWeight, aes(y=weight,x=as.factor(Time),fill=Diet))+ geom_boxplot()+scale_colour_brewer(palette = &quot;Set1&quot;)+ facet_wrap(~Time,scales = &quot;free&quot;) Figure 3.14: Plot separating by age of the chicken ggplot(data = ChickWeight, aes(y=weight,x=as.factor(Time),fill=Diet))+ geom_violin()+ scale_colour_brewer(palette = &quot;Set1&quot;)+ facet_wrap(~Time,scales = &quot;free&quot;) Figure 3.15: Plot separating by age of the chicken 3.3.4 Saving plots Imagine you want now to save some of these plots. You can use the button export in RStudio. But you can also use the pdf function. This function allows us to determine the width and height of the plots. Check what happens if you modify the option in the plots below. These pdf files will be saved on your working directory with the name, width and height determined in the function. Important things: Do not forget to put the “.pdf” at the end of the file name. What do you think it will happen if you forget it? When you finish running the plots that you want to be in the pdf file, you have to run dev.off(). This will close the plot. If you forget this, you will not be able to open the plot. pdf(&quot;densityplot.pdf&quot;,width = 20, height = 20) #save the plot as a pdf, control width and height of the pdf ggplot(data = ChickWeight, aes(x=weight,fill=Diet))+ geom_density( alpha=0.5)+ scale_colour_brewer(palette = &quot;Set1&quot;)+ facet_wrap(~Time,scales = &quot;free&quot;) dev.off() #end the plot pdf(&quot;density_and_violin.plot.pdf&quot;,width = 20, height = 20) #save the plot as a pdf, control width and height of the pdf ggplot(data = ChickWeight, aes(x=weight,fill=Diet))+ geom_density( alpha=0.5)+ scale_colour_brewer(palette = &quot;Set1&quot;)+ facet_wrap(~Time,scales = &quot;free&quot;) ggplot(data = ChickWeight, aes(y=weight,x=as.factor(Time),fill=Diet))+ geom_violin()+ scale_colour_brewer(palette = &quot;Set1&quot;)+ facet_wrap(~Time,scales = &quot;free&quot;) dev.off() #end the plot ## quartz_off_screen ## 2 ## quartz_off_screen ## 2 3.4 Statistical test 3.4.1 Descriptive statistics We already saw a way to get the descriptive stats from a table by using summary. We will try to compare the weight of chickens under different diets without considering the age. First, we will now do a mean and SD table for each diet. There is one function that can do this for us. ddply is a function that first divides the data by a variable written as .(Var) and then perform an specific function. With the indication of “transform” this will create a new column in out data stat_ChickWeight&lt;-ddply(ChickWeight, .(Diet), transform, Mean=mean(weight,na.rm = T), SD=sd(weight,na.rm = T)) head(stat_ChickWeight) ## weight Time Chick Diet Mean SD ## 1 42 0 1 1 102.6455 56.65655 ## 2 51 2 1 1 102.6455 56.65655 ## 3 59 4 1 1 102.6455 56.65655 ## 4 64 6 1 1 102.6455 56.65655 ## 5 76 8 1 1 102.6455 56.65655 ## 6 93 10 1 1 102.6455 56.65655 Is this what we wanted? What happens if instead of “transform” we use “summarize”? Check ?ddply for more detail. statWeight_ChickWeight&lt;-ddply(ChickWeight, .(Diet), summarise, Mean=mean(weight,na.rm = T), SD=sd(weight,na.rm = T)) head(statWeight_ChickWeight) ## Diet Mean SD ## 1 1 102.6455 56.65655 ## 2 2 122.6167 71.60749 ## 3 3 142.9500 86.54176 ## 4 4 135.2627 68.82871 This is usefull for ploting, here a good plot: ggplot(statWeight_ChickWeight, aes(x=Diet, y=Mean, fill=Diet)) + geom_bar(stat=&quot;identity&quot;, position=position_dodge()) + geom_errorbar(aes(ymin=Mean-SD, ymax=Mean+SD), width=.2, position=position_dodge(.9)) Figure 3.16: Boxplot 3.4.2 T-test/Wilcoxon To compare means we can do a T test but to do this we need to test the assumptions of this test: Normality of the data and Homoscedasticity (ie, the variance is similar between the two groups we want to compare) Question : Is there any significant difference in the weights between diet 1 and 3? Preliminary test to check independent t-test assumptions Assumption 1: Are the two samples independents? Yes, they are two different samples Assumption 2: Are the data from each of the 2 groups follow a normal distribution? Shapiro-Wilk normality test for the different diets shapiro.test(ChickWeight$weight[ChickWeight$Diet==1]) ## ## Shapiro-Wilk normality test ## ## data: ChickWeight$weight[ChickWeight$Diet == 1] ## W = 0.89336, p-value = 2.211e-11 The function with allows us to do a simpler writing with(ChickWeight, shapiro.test(weight[Diet == 1])) ## ## Shapiro-Wilk normality test ## ## data: weight[Diet == 1] ## W = 0.89336, p-value = 2.211e-11 with(ChickWeight, shapiro.test(weight[Diet == 2])) ## ## Shapiro-Wilk normality test ## ## data: weight[Diet == 2] ## W = 0.90399, p-value = 3.159e-07 pvalue &lt; 0.05, these are not normally distributed. We can NOT use t-test here. If we remember the histograms, this makes sense. qplot(data=ChickWeight, x = weight, facets = &quot;Diet&quot;,geom = &quot;density&quot;) Figure 3.17: Density plot sepparated by Diet type Assumption 3: Do the two populations have the same variances? We’ll use F-test to test for homogeneity in variances. This is implemented by a function named var.test. This will require you to have which variable you want to test and separated by which variable. This is clearly also not homoscedastic. var.test(weight~ Diet, data = ChickWeight[ChickWeight$Diet %in% c(1,2),]) ## ## F test to compare two variances ## ## data: weight by Diet ## F = 0.62601, num df = 219, denom df = 119, p-value = 0.002928 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.4525703 0.8530014 ## sample estimates: ## ratio of variances ## 0.626013 What happens if you try to run this var.test(weight~ Diet, data = ChickWeight)? We will use then Wilcoxon. wilcox.test(weight~ Diet, data = ChickWeight[ChickWeight$Diet %in% c(1,2),],exact = FALSE) ## ## Wilcoxon rank sum test with continuity correction ## ## data: weight by Diet ## W = 11213, p-value = 0.02181 ## alternative hypothesis: true location shift is not equal to 0 Are them different? 3.4.3 Anova/Kruskal–Wallis Another way to test differences is to do an ANOVA or its non-parametric alternative Kruskal–Wallis. We already know that this data cannot be analyzed using parametric test as anova. But let’s explore just for fun. Let’s check all the diets together # Compute the analysis of variance res.aov &lt;- aov(weight~ Diet, data = ChickWeight) # Summary of the analysis summary(res.aov) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Diet 3 155863 51954 10.81 6.43e-07 *** ## Residuals 574 2758693 4806 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We see that the diet is a significant component of the variance of the data. Now we should know from where it is coming. We need to do a multiple pairwise-comparison. We will use Tukey Honest Significant Difference for this. TukeyHSD(res.aov) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = weight ~ Diet, data = ChickWeight) ## ## $Diet ## diff lwr upr p adj ## 2-1 19.971212 -0.2998092 40.24223 0.0552271 ## 3-1 40.304545 20.0335241 60.57557 0.0000025 ## 4-1 32.617257 12.2353820 52.99913 0.0002501 ## 3-2 20.333333 -2.7268370 43.39350 0.1058474 ## 4-2 12.646045 -10.5116315 35.80372 0.4954239 ## 4-3 -7.687288 -30.8449649 15.47039 0.8277810 However, you should be screaming at me now: I did not check the assumptions! Homogeneity of variances: plot(res.aov, 1) Figure 3.18: Residuals vs Fitted leveneTest(weight~ Diet, data = ChickWeight) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 3 9.6001 3.418e-06 *** ## 574 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We have just found what we already know. The variance is not homogeneous. The variance across groups is statistically significantly different. Normality of the residuals: plot(res.aov, 2) Figure 3.19: QQ plot # Extract the residuals aov_residuals &lt;- residuals(object = res.aov ) # Run Shapiro-Wilk test shapiro.test(x = aov_residuals ) ## ## Shapiro-Wilk normality test ## ## data: aov_residuals ## W = 0.94065, p-value = 2.014e-14 Non parametric then: kruskal.test(weight~ Diet, data = ChickWeight) ## ## Kruskal-Wallis rank sum test ## ## data: weight by Diet ## Kruskal-Wallis chi-squared = 24.45, df = 3, p-value = 2.012e-05 What would you conclude about this data? 3.5 Activity: Find another thing you want to test with this data. Solve this in a graphical and statistical way. Save the plots 3.6 Resources Statistics with R: https://cran.r-project.org/doc/contrib/Seefeld_StatsRBio.pdf Stat and plots with R: http://www.sthda.com/english/ "],
["sequencing-techniques-and-preprocessing.html", "Lab 4 Sequencing techniques and preprocessing 4.1 Objectives 4.2 Introduction 4.3 Different type of data (DNA, RNA, splicing, single-end paired-end) 4.4 From the sequencer machine to the sequence 4.5 General processing 4.6 Using the terminal 4.7 A bit of shell commands 4.8 Resources and Bibliography", " Lab 4 Sequencing techniques and preprocessing 4.1 Objectives After this section you should be able to: Have an overview of different sequencing techniques and different genomic data Understand the pre-processing of the data before loading it into R 4.2 Introduction Large scale sequencing techniques become more and more common as high throughput sequencing technologies became cheaper and widely available. The main objective of these techniques is to quantify the levels of different molecules: DNA, RNA and proteins. The “central dogma of molecular biology” states the main flow from the information stated on genes in the DNA to the expression of proteins. DNA is transcribed to RNA that then is translated to proteins. DNA –&gt; RNA –&gt; Protein However, this straight line misses a lot of other molecules as miRNAs, lincRNAs, transposons, etc. Moreover, not only the levels but also the quality and property of each molecule is important. One example is different RNA splicing isoforms or protein modifications. 4.3 Different type of data (DNA, RNA, splicing, single-end paired-end) It is important to know which type of sequencing techniques are available, its pros and cons and which type of molecules we are able to capture without sequencing. Even more important we need to understand the characteristics of the data we are analyzing. For example, DNA and RNA libraries differ in the fact that one undergoes splicing. That will affect the way the data is processed. Nowadays, there are two main types of libraries for nucleotides: short reads libraries and long reads libraries. Long-read techniques are more recently developed with two main technologies available: Pacific Biosciences’ (PacBio) single-molecule real-time (SMRT) sequencing and Oxford Nanopore Technologies’ (ONT) nanopore sequencing. In this book we will focus on short-read libraries, as the ones processed by Illumina machines. This technology is based on PCR amplification of the material and the base pairing with different fluorescently tagged nucleotides. Figure 1.1: Illumina sequencer strategy, adapted from Illumina user manual www.illumina.com/technology/next-generation-sequencing.html There are many library preparation protocols for Illumina sequencers. All of these techniques must include a step of fragmentation and adapter ligation. These adapters are essential to the inclusion of the fragments in the sequencer machine. Moreover, different samples might be pulled together by the use of different adapters with specific sample barcode. The idea of a barcode is the presence of specific sequences that can identify the origin of each sequence fragment. The process of separating each sample is called demultiplexing. Figure 4.1: Demultiplexing strategy Depending on the molecule of interest the library preparation to detect them will be different. For DNA the addition of the Illumina adaptors can be done by ligation or by tagmentation (which does the fragmentation and tagging at the same time). In this case, as DNA has NOT an orientation (is double stranded and palindromic) we do not care which adapter get in which side of the fragment. Figure 4.2: DNA library prep Contrary to DNA, RNA is single stranded and have a particular direction (5´-3´). It can be produced from the sense or antisense strand of the DNA which is a key property as some parts of the DNA encode different genes in each strand. Therefore, it is important to maintain the direction information from the RNA molecules. This is usually achieved thru the different 3´and 5´ Illumina adaptors. There are many types of RNA molecules with different biochemical properties. To capture each of them, there are different biochemical approaches. For small RNAs (20-30nts), usually the library starts with specific small RNA extraction methods. To capture polyadenylated mRNAs, we can add a poly A selection step using polyT oligo beads for example. If this step is done after the RNA is fragmented then this library will be 3´UTR selected. This type of libraries do not provide information about the splicing isoforms for example but it is useful to asses gene expression levels and is cheaper than multiple qPCRs. Most commonly used single cell sequencing technology use this type of libraries. To study also non-polyadenylated transcripts, as lncRNA and circRNAs, we have to deplete the libraries from ribosomal RNA which is the majority of the RNA. This can be achieved by using DNA complementary probes to rRNA followed by RNAseH digestion (cut RNA-DNA hybrids). Figure 4.3: Different RNA librarie strategies Regarding sequencing itself we can choose the length of the read and if we want to read only from side of the fragment (single-ended) of from both sides (paired-ended). Both options have different advantages. To capture different splicing patterns for example, paired-end is recommended. 4.4 From the sequencer machine to the sequence Illumina sequencing machines can be thought as fluorescence microscopes. The information they generate are basically photographs in which each color represent one nucleotide. The first step to produce the sequences is to process these images an convert them in sequences. This is done using the Illumina program bcl2fastq. This process is named basecalling and process the raw data form Illumina: basecalls files (BCL) and produces Fastq files. Figure 4.4: From BCL to Fastq Each fragment sequenced by the machine is named READ and all the reads together form a LIBRARY. Fastq format basically encodes the “name” of each read, the nucleotides and quality in ASQII format. Figure 4.5: Fastq Format The overall quality of the library can be assed using programs as FastQC. These programs read the quality and generate a overall measurement of them. Each time the machine sequences a read it evaluates the confidence it has to assign it to a particular nucleotide. This is a general idea of what the quality of each base means. Low quality reads can be filtered and low-quality bases can be trimmed from reads using tools as trimgalore or cutadapt. 4.5 General processing Once we have the sequencing data in fastq format we have to find where each read comes from. This is called alignment. The next step is to quantify how many reads comes from each place in the genome. Figure 4.6: General pre-processing of the sequencing data. ###Alignment (bam files, annotation files, BOWTIE2 and STAR) Once we have the fastq file we have to “find” which part of the genome it is coming from. This process is called alignment. Unless we are working with uncommon organisms, most genomes are already sequenced, which means we already know the sequence of each part of the genome. Therefore, this step is almost trivial. We have to align the reads to the genome. The reads are in fastq format, and the genome are in fasta format. The fasta format start with &gt; The name of the chromosome and then it stores the sequence of the chromosome. &gt;chr1 AAATTCGGGCCAA... Maybe you have already heard about BLAST alignment. Unfortunately, this is not fast enough to aligns the millions of reads we generate from each sequencing experiment. Therefore, new techniques were developed. There are many different really good tools available. To choose one we need to consider the type of molecule we are working with and the type of sequencing technique used. It is not the same to align DNA that RNA. The main difference is the splicing awareness and the use of the gene annotation. Another thing to consider the type of sequencing performed (single vs paired end). Figure 4.7: DNA vs RNA alignement single and paired end The gene annotation files contain the information about which gene is encoded in each part of the genome. It include exons, introns and different transcript variants. There are different format of annotation files. The mostly used ones are gtf and bed12. Both contain the information about gene name, chromosome, start, end, number of exons and where each exon start. Of course, both the genome and the annotation files are updated frequently so you should consider update them as you can. Databases commonly used are ENSEMBL and UCSC. Just to show one example, gtf of fly annotation version dm6: #gff-version 2 #source-version rtracklayer 1.38.3 #date 2018-04-23 #genome-build . BDGP6 chr3R FlyBase gene 567076 2532932 . + . gene_id &quot;FBgn0267431&quot;; gene_name &quot;Myo81F&quot;; gene_source &quot;FlyBase&quot;; gene_biotype &quot;protein_coding&quot;; chr3R FlyBase transcript 567076 2532932 . + . gene_id &quot;FBgn0267431&quot;; gene_name &quot;Myo81F&quot;; gene_source &quot;FlyBase&quot;; gene_biotype &quot;protein_coding&quot;; transcript_id &quot;FBtr0392909&quot;; transcript_name &quot;Myo81F-RB&quot;; transcript_source &quot;FlyBase&quot;; transcript_biotype &quot;protein_coding&quot;; One we have aligned the data, we will have .sam files or its binary “lighter/smaller” version .bam. These files are composed of one line per read. Each line has the read names, its sequence and the location to where it was aligned it also have encoded a lot of different quality metrics including the already discussed fastq quality. Each alignment will have different alignment quality. A perfect read with a perfect match to the reference genome would give a perfect score. The presence of gaps on the alignment would reduce the alignment quality. Reads with low quality (less than 20 for example) are usually filtered and not used in downstream analysis. Here the example for two reads of the data sets used in next chapter. SRR548157.14400783 16 chr2L 24 1 36M * 0 AGAACAGATATTTAGATTGCCTCTCATTTTCTCTCC HHDHHHHHHHHFHHHHHHHHFHEHHHHHHHHHHHFG AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:36 YT:Z:UU SRR548157.4410720 0 chr2L 247 1 36M * 0 AGTGCCAACATATTGTGCTAATGAGTGCCTCTCGTT E@=?@BDDBDHGHGHDHGIGGIBGGDEGFGB@BEBD AS:i:0 XS:i:0 XN:i:0 XM:i:0 XO:i:0 XG:i:0 NM:i:0 MD:Z:36 YT:Z:UU Reads can be also aligning to one or multiple sites in the genome. This last option is usually called: multiple mapping. For repetitive sequences in the genome, as rRNA loci and transposons, it is expected that they will map to multiples places. For other loci, the multiple mapping can be an indication of low-quality reads. For RNA sequencing analysis multiple mapping reads are problematic when quantifying gene expression so sometimes they are removed from downstream analysis. Alignment files can be sorted or unsorted. This means basically if the reads are sorted in the order they were in the fastq file or in the order they appear aligned to the genome. A sorted file basically will have the reads aligned to chr1 before the ones from chr2, and so on. This is important as some tools (as the visualization) require reads to be sorted. 4.5.1 Visualization of alignment (IGV) Alignment files can be visualized using different tools as [UCSC genome browser] (https://genome.ucsc.edu/goldenPath/help/hgTrackHubHelp.html) or [IGV](https://software.broadinstitute.org/software/igv/home. IGV have the option to load your own genomes and annotation data. To load it we will need the sorted bam files. This will allow us to visualize each read with its alignment quality, gaps, etc. Figure 4.8: Alignement files (.bam) loaded into the IGV genome browser. As bam files are really big there are options to store only the total count visualization. These files format can be bigwig or TDF for example. It is importan to note the different scales (just noxt to the file name). Figure 4.9: Bigwig files (.bw) loaded into the IGV genome browser. 4.5.2 Gene counts / read (esat feature counts) /peak calling Many times, it is important to account for the number of reads aligning to each part of the genome. This is what we call quantification and for each type of data we will use different quantification tools. One example of DNA sequencing data is ChipSeq data, in which we want to know to which parts of the DNA certain protein is binding to. In that case, the number of reads represent the level of binding of that protein. One tool to see this is MACS2 For RNA, the number of reads coming from one gene basically represents the level of expression of that gene. For 5´end libraries the tool we can use is ESAT. For full transcript libraries we can use tools as featurecounts. To see splicing patterns, leafcutter is one option. 4.6 Using the terminal The terminal is just a way to execute commands in your computer. It is alternatively referred to as a computer console, root console or system console. It is a non-graphical output of the computer connected with the keyboard. With it you can do anything that you would do with the mouse like for example copy a file or moving it from one location to another. Different operating systems for personal computers as Unix (linux and Mac OS) or Windows have different functioning. Most of the genomic programs are written and executed in Unix, if you have a Windows machine you can use a terminal emulator as the ones listed here. A list of useful commands can be found in many places, here one example. The first thing I would recommend you to try is to find which is your working directory (sometimes called folder). Remember, is the place in which you are located right now and where things will be executed. You can do so by typing. pwd If you want to know what is inside your current directory, you can list the files and folders (directories) by ls There are other options to visualize this. What happens if you type this? ls -l Usually commands have options and this option is usually indicated by the - sign. Lets try now something more: ls -la You can see that now it appears to be extra directories inside. This is because the option -a basically is exposing the hidden files and directories. The directory .. and . are ways to point to the directory containing the working directory and the working directory itself. I know it is complicated, so let’s see an example. What happens if you do ls -l ./ ? and ls -la? Basically you will see the same elements because ./ is the current directory. ../ is the “upper” directory, meaning the directory that contains the working directory. Try it out. To change directory, cd is your command. You just have to say were you want to go. Try: cd ../ and explore it with ls. Then you can go back into the one you were before with cd ./thenameyousawbeforewithpwd Once you know where you are and how to move, you can start creating new directories or folders with mkdir. Each command has certain things you must provide. Try to run just mkdir. You will get an error message like this usage: mkdir [-pv] [-m mode] directory .... This is literally letting you know what is the expected ways of things. Basically, it needs the name of the directory you want to create. Try now mkdir try What happens if you do ls. Do you see it now? To copy a file, we use cp. It works as follows cp whatyouwant towhereyouwantwiththenameyouwant. For example, cp try trycopy To move the location of a file you use mv what where. For example: mv try ../ Use ls ../ to see if is there. To remove it you have to use rm ../try. You will get an error message as follows: rm: try/: is a directory. To avoid it you have to use the option -r. Basically r comes from recursive and is because you want to delete the folder with all the files inside so it “recursively” removes. Try now rm -r ../try. Use ls ../ to check that it is out. You can also do cd ../ and then ls ./ to see that you removed it. To edit and create text files like scripts I use vi There are many tutorials you can find online. This is good. Just by saying vi newtext.txt, you will be in your brand-new text to edit it. Understanding the directories is important. There are a set of “special” directories I would like to mention so you just have them in mind. / – The Root Directory Is where all the things are. All you programs, folders, etc. Lets see some examples of the sub-directories you will find there. /bin – Essential User Binaries The /bin director contains the essential user binaries (programs) that must be present when the system is on. This means that for example, your operative system bash shell will be there but your google chrome no. Your installed programs will be in /usr/bin /boot – Static Boot Files The /boot directory contains the files needed to boot the system. /etc – Configuration Files /etc/ directory contains system-wide configuration files – user-specific configuration files are located in each user’s home directory /home The /home directory contains a home folder for each user. /lib – Essential Shared Libraries The /lib directory contains libraries needed by the essential binaries in the /bin and /sbin folder. Libraries needed by the binaries in the /usr/bin folder are located in /usr/lib. /tmp – Temporary Files Applications store temporary files in the /tmp directory. /usr – User Binaries &amp; Read-Only Data The /usr directory contains applications and files used by users, as opposed to applications and files used by the system. 4.7 A bit of shell commands Shell is a another language as R. As scripts in R, they also have a particular way of working. I am not going to go into detail with them but will try to give some ideas of for loops that can be useful to write scripts. Shell commands ends with .sh and to rum them you just type: sh yourshellscript.sh In a shell script you can do everything that you would do directly in the terminal. You can create them by vi myshellscript.sh and then adding things like: mkdir AAA Remember, to edit the text you will have to use the insert mode (presing the key A for example). To save your changes you have to be out of the insert mode (pressing scape key) and then :w. This will “write” the changes. Then you can exit the editor with :q. If you want to quit without saving you can press :q!. Try it out and see what happened using ls for example. Then you can execute the script by typing sh myshellscript.sh What do you expect to happened now? Do you see any changes with ls? The asterisk * is used to complete “any chararcters” ls tr* Will list any file that start with tr. You could then list files ending with “.bam” to list the alignment files: ls *.bam For loops in shell works as follows: for list_files do something you want to do done Variables in shell are created just with the = sign VARIABLE=somevalue And can be called using $VARIABLE. Try this in your terminal X=2 $X We can now integrate all this and see one example. This is an example of a loop to create the tdf file from each bam file: for FILE in *.bam #This will go over all the files that ends with .bam and will store them in a variable named FILE do NAME=`echo $FILE | cut -d &#39;bam&#39; -f1` #it creates a name using the function cut, just remove the bam echo &quot;##############Running sample: $NAME##############&quot; #echo is to print things in the terminal igvtools count -w 5 --minMapQuality 20 --strands read &quot;$FILE&quot; ./&quot;$FILE&quot;.tdf genome.fa&quot; done 4.8 Resources and Bibliography Griffith M, Walker JR, Spies NC, Ainscough BJ, Griffith OL (2015) Informatics for RNA Sequencing: A Web Resource for Analysis on the Cloud. PLoS Comput Biol 11(8): e1004393. https://doi.org/10.1371/journal.pcbi.1004393 An introduction to Next-Generation Sequencing Technology, Illumina, available at www.illumina.com/technology/next-generation-sequencing.html Alberts B, Johnson A, Lewis J, et al. Molecular Biology of the Cell. 4th edition. New York: Garland Science; 2002. From DNA to RNA. Available from: https://www.ncbi.nlm.nih.gov/books/NBK26887/ Amarasinghe, S.L., Su, S., Dong, X. et al. Opportunities and challenges in long-read sequencing data analysis. Genome Biol 21, 30 (2020). https://doi.org/10.1186/s13059-020-1935-5 https://www.howtogeek.com/117435/htg-explains-the-linux-directory-structure-explained/ "],
["chip-sequencing-analysis.html", "Lab 5 Chip Sequencing Analysis 5.1 Objectives 5.2 Introduction 5.3 Data pre-processing (peak-calling): 5.4 Exploring the results: 5.5 Annotating the peaks. 5.6 Annotate with ChIPseeker 5.7 Sequence Motif analysis 5.8 Extra: How to solve some common annotation issues. 5.9 Extra: Detailed explanation of the MACS output files 5.10 Activity 5.11 Resources and Bibliography 5.12 Session info: all the packages installed.", " Lab 5 Chip Sequencing Analysis 5.1 Objectives After this section you should be able to: Explore results from ChipSeq data. Modify tables and change gene names. Use different ChipSeq gene annotation packages from R. Find sequence motif enrichment in sequencing data. 5.2 Introduction Chip-seq procedure: “ChIP-seq” is short for “chromatin immunoprecipitation (ChIP) followed by sequencing (seq)”. ChipSeq data is basically DNA sequencing data in which the DNA is sequenced AFTER immunoprecipitating a protein of interest. Therefore, we expect to sequence the pieces of DNA that are interacting with the precipitated protein. If the protein of interest is a transcription factor (TF) for example, we expect to get the regions of DNA close to the genes that are being regulated by this particular TF (ie. the promoters of the genes). If we immunoprecipitate RNA polymerase 2, we expect to get the regions of the DNA that are being transcribed to RNA. But, how do we know if certain region of the genome is really interreacting with the protein of interest? As in any analysis, it is important to have a control to see the probability to have a signal in a particular region just by chance. Usually as a control we use the DNA sequencing BEFORE immunoprecipitation (IP). This data is usually called input (INP), as it is the input material used for the IP. What we are looking then will be “enrichment” of each region of the genome in the IP compared with the INP. The biochemical procedure usually goes as follows: Figure 1.1: Commonly used ChipSeq procedure. DNA is fragmented followed by immunoprecipitation for the protein of interest. Finally, DNA library is prepared and sequenced. As you can see there is an enrichment of the DNA regions bonded to the protein of interest. To study this type of data we will re-analyze the data generated in Meireles-Filho et al 2014. In this work the authors study genome-wide the binding of two transcription factors (Clk and Cyc) in the fruit fly (Drosophila melanogaster). To do so they do Chip sequencing. These two transcription factors are core components of the circadian clock in animals. Just as an introduction these two transcription factors bind to specific regions on the genome and activate transcription. Clk oscilates over the day due to a set of feedback loops with other core-clock components. These set of molecular interactions generate an autonomous oscilating molecular clock with a period of almost 24 hr. This clock can be re-set by light input. We will study RNA oscilations over the day in next chapter. Figure 4.1: Circadian clock at the molecular level. The molecular feedback loop is formed by the negative feedback of Period (PER) and Timeless (TIM) on their own transcription. Figure adapted from Dubowy et al 2017 Figure 4.2: Cyc, Clk and Time levels over the day. Figure adapted from Alves Meireles-Filho et al 2013 Figure 4.3: Light control of the circadian clock. Figure adapted from Alves Meireles-Filho et al 2013 5.3 Data pre-processing (peak-calling): Our goal is then to quantify signal enrichment in certain part of the genome in IP vs INP sequencing. This is achieved by comparing the ALIGNEMENT of the reads of IP vs INP. This process is called “peak calling” because it is trying to determine the “pileup” of reads along the genome forming “peaks”. As any peak the algorithm used will report high of the peak, summit location, width and finally a pvalue corresponding to the comparison of the signal in that region in IP vs INP. Here we can see how the pileup reads look like in IGV. We are looking here at the promoter of the genes tim, a known target of CLK protein. As you can see, the peak is clear in the IP comapred with the INP. Figure 4.4: IGV pileup traks over tim. Upper line IP, lower line INP. To do this analysis genome wide, we need a tool that can do this for all the genom. There are few tools available, we use here MACS algorithm to assess the peaks from the sequencing data. Basically, this analysis relies in the aligned data (.bam files). It compares the IP with the INP control. For this analysis I aligned the data from GEO with Bowtie2, an aligner that is used for DNA data (not splice aware). Finally ran the MACS command in the terminal as follows: macs2 callpeak -t head_clk_ip_rep1.sorted.bam head_clk_ip_rep2.sorted.bam -c ./head_clk_input_rep1.sorted.bam ./head_clk_input_rep2.sorted.bam -g dm -n PeakAna_clk_Ip_vs_INP -B -p 0.05 Where, -t indicates that the following arguments are the IP samples, -c the control samples, -g the genome name in this case “dm”, -n the name that all the output files will have, -B indicates to the program to store visualization files (in .bdg format usefull to visualize in IGV). The output after running MACS on the shell: File name Description PeakAna_clk_Ip_vs_INP_model.r An R script for producing a PDF illustrating the peak model PeakAna_clk_Ip_vs_INP_model.pdf The PDF image of the read distribution in model peaks and fragment size estimation PeakAna_clk_Ip_vs_INP_peaks.xls Key parameters used by MACS and detailed information of every peak identified by MACS PeakAna_clk_Ip_vs_INP_peaks.bed Peak locations in BED format PeakAna_clk_Ip_vs_INP_peaks.subpeaks.bed Subpeak locations in BED-like format. This file is generated by PeakSplitter, which is called by MACS PeakAna_clk_Ip_vs_INP_summits.bed Summit locations of the peaks in BED format PeakAna_clk_Ip_vs_INP_MACS_bedGraph Directory where the BedGraph files are generated. For each control or ChIP-seq sample, a BedGraph file describes the read distribution along the whole genome 5.4 Exploring the results: We will see the first part of the output we get in the “NAME_peaks.xls”: We can see here that we have all the columns we expect and we cqn try to see places we know are interesting for us. #knitr::include_graphics(&#39;images/hex-rmarkdown.png&#39;) macs.res&lt;-read.table(&quot;../macs2_analysis_p0.05/PeakAna_clk_Ip_vs_INP_peaks_bed.txt&quot;,header = T) head(macs.res) ## chr start end length abs_summit pileup X.log10.pvalue. fold_enrichment ## 1 chr2L 34224 34348 125 34306 20.88 2.75497 1.97319 ## 2 chr2L 34965 35180 216 35108 23.26 3.33362 2.02190 ## 3 chr2L 40369 40577 209 40492 30.42 7.01721 2.83398 ## 4 chr2L 57282 57429 148 57365 22.07 3.47781 2.08079 ## 5 chr2L 58368 58696 329 58541 39.37 12.02019 3.64098 ## 6 chr2L 62014 62139 126 62048 19.68 2.42109 1.86559 ## X.log10.qvalue. name ## 1 1.12350 PeakAna_clk_Ip_vs_INP_peak_1 ## 2 1.65302 PeakAna_clk_Ip_vs_INP_peak_2 ## 3 5.05903 PeakAna_clk_Ip_vs_INP_peak_3 ## 4 1.77350 PeakAna_clk_Ip_vs_INP_peak_4 ## 5 9.82848 PeakAna_clk_Ip_vs_INP_peak_5 ## 6 0.83175 PeakAna_clk_Ip_vs_INP_peak_6 5.5 Annotating the peaks. With this information we want to be able to conclude something about this transcription factor regulation. The first thing to see is genes that might be regulated. This is basically looking which is the closest gene to each peak. To do this we will just looking at the annotation file that have the information of which gene is in each region of the genome (we can think of this as the “map” of the genome). What problems you can think that this approach might have? Think about enhancers for example. For this we will use the following libraries: library(GenomicFeatures) #This is an R package to deal with genomic data. You can read more at https://bioconductor.org/packages/release/bioc/vignettes/GenomicFeatures/inst/doc/GenomicFeatures.pdf library(ChIPpeakAnno) #This is a package to annotate Chip-Peaks data https://bioconductor.org/packages/release/bioc/vignettes/ChIPpeakAnno/inst/doc/ChIPpeakAnno.html 5.5.1 Read the annotation file In class we saw what were annotation files. Those were files that contained the “map” of the genome. This map shows us where each gene start and end and where each exon, intron and UTR is in that gene. We will work with a GTF file. Remember that annotation files can be in many formats. They can be downloaded from different places as UCSC genome browser, Ensemble, etc. To read the GTF file we will use the makeTxDbFromGFF function. We are doing this because it will allow us to change it to another format, sqlite. txdb &lt;- makeTxDbFromGFF(file=&quot;../macs2_analysis_p0.05/annot2.chr.gtf&quot;, format = &quot;gtf&quot;, dataSource=&quot;dm6&quot;, organism=&quot;Drosophila melanogaster&quot;) #this funciton is actually reading the GTF file and creating a data base. Try reading the help documentation of this funciton. #Now we need to save this as an sqlite: saveDb(txdb, file=&quot;../macs2_analysis_p0.05/dm6.sqlite&quot;) #Look at your working directory, what happened? txdb &lt;- loadDb(&quot;../macs2_analysis_p0.05/dm6.sqlite&quot;) #this is loading the sqlite directly without creating the database ## TxDb object: ## # Db type: TxDb ## # Supporting package: GenomicFeatures ## # Data source: dm6 ## # Organism: Drosophila melanogaster ## # Taxonomy ID: 7227 ## # miRBase build ID: NA ## # Genome: NA ## # transcript_nrow: 34767 ## # exon_nrow: 87482 ## # cds_nrow: 62757 ## # Db created by: GenomicFeatures package from Bioconductor ## # Creation time: 2020-08-30 21:11:57 -0400 (Sun, 30 Aug 2020) ## # GenomicFeatures version at creation time: 1.38.2 ## # RSQLite version at creation time: 2.2.0 ## # DBSCHEMAVERSION: 1.2 5.5.2 Get the genes from this annotation data base The function genes actually extract the genomic ranges (chr start, end, strand, etc) from the genes in the annotation data base we are working with txdb. ge &lt;- genes(txdb, columns=c(&quot;tx_name&quot;, &quot;gene_id&quot;, &quot;tx_type&quot;)) #get the genes genomic ranges, what do you think are the options we are passing to this function? (read the help manual to check). #lets look at the genes: as.data.frame(head(ge)) ## seqnames start end width strand tx_name gene_id ## FBgn0000003 chr3R 6822498 6822796 299 + FBtr0081624 FBgn0000003 ## FBgn0000008 chr2R 22136968 22172834 35867 + FBtr0071.... FBgn0000008 ## FBgn0000014 chr3R 16807214 16830049 22836 - FBtr0306.... FBgn0000014 ## FBgn0000015 chr3R 16927212 16972236 45025 - FBtr0415.... FBgn0000015 ## FBgn0000017 chr3L 16615866 16647882 32017 - FBtr0112.... FBgn0000017 ## FBgn0000018 chr2L 10973443 10975293 1851 - FBtr0080168 FBgn0000018 ## tx_type ## FBgn0000003 transcript ## FBgn0000008 transcript ## FBgn0000014 transcript ## FBgn0000015 transcript ## FBgn0000017 transcript ## FBgn0000018 transcript 5.5.3 Get the genomic ranges of the peaks from MACS and find which gene is closer to them (ie. Annotate them) Now we will use the function GRanges to actually get the genomic ranges of the peaks from MACS. And we will annotate them with the function annotatedPeak and the genes function to map them to the closer gene. Basically we are using the information about the genes (start, end, etc) to see which is the closest one to each peak. peaksGR&lt;-GRanges(macs.res) #create the GRanges object of the macs-table. annotatedPeak &lt;- annotatePeakInBatch(peaksGR, AnnotationData=genes(txdb)) #look at the begining of the table as.data.frame(head(annotatedPeak)) ## seqnames start end width strand length abs_summit pileup ## X00001.FBgn0031209 chr2L 34224 34348 125 * 125 34306 20.88 ## X00002.FBgn0031209 chr2L 34965 35180 216 * 216 35108 23.26 ## X00003.FBgn0267987 chr2L 40369 40577 209 * 209 40492 30.42 ## X00004.FBgn0267987 chr2L 57282 57429 148 * 148 57365 22.07 ## X00005.FBgn0267987 chr2L 58368 58696 329 * 329 58541 39.37 ## X00006.FBgn0051973 chr2L 62014 62139 126 * 126 62048 19.68 ## X.log10.pvalue. fold_enrichment X.log10.qvalue. ## X00001.FBgn0031209 2.75497 1.97319 1.12350 ## X00002.FBgn0031209 3.33362 2.02190 1.65302 ## X00003.FBgn0267987 7.01721 2.83398 5.05903 ## X00004.FBgn0267987 3.47781 2.08079 1.77350 ## X00005.FBgn0267987 12.02019 3.64098 9.82848 ## X00006.FBgn0051973 2.42109 1.86559 0.83175 ## name peak feature ## X00001.FBgn0031209 PeakAna_clk_Ip_vs_INP_peak_1 00001 FBgn0031209 ## X00002.FBgn0031209 PeakAna_clk_Ip_vs_INP_peak_2 00002 FBgn0031209 ## X00003.FBgn0267987 PeakAna_clk_Ip_vs_INP_peak_3 00003 FBgn0267987 ## X00004.FBgn0267987 PeakAna_clk_Ip_vs_INP_peak_4 00004 FBgn0267987 ## X00005.FBgn0267987 PeakAna_clk_Ip_vs_INP_peak_5 00005 FBgn0267987 ## X00006.FBgn0051973 PeakAna_clk_Ip_vs_INP_peak_6 00006 FBgn0051973 ## start_position end_position feature_strand insideFeature ## X00001.FBgn0031209 21823 25155 - upstream ## X00002.FBgn0031209 21823 25155 - upstream ## X00003.FBgn0267987 54817 55767 + upstream ## X00004.FBgn0267987 54817 55767 + downstream ## X00005.FBgn0267987 54817 55767 + downstream ## X00006.FBgn0051973 25402 65404 - inside ## distancetoFeature shortestDistance fromOverlappingOrNearest ## X00001.FBgn0031209 -9069 9069 NearestLocation ## X00002.FBgn0031209 -9810 9810 NearestLocation ## X00003.FBgn0267987 -14448 14240 NearestLocation ## X00004.FBgn0267987 2465 1515 NearestLocation ## X00005.FBgn0267987 3551 2601 NearestLocation ## X00006.FBgn0051973 3390 3265 NearestLocation 5.5.4 Change the gene format. What do you notice about the table annotatedPeak? Can you recognize any of the genes? Try to google some of them. The gene names are now in a format that is general for fly genes. This format is the one we have from flyblase.org, a database for fly genes. These names are useful for databases purposes but are not indicative of their function. Therefore, we want now to put the gene-names that we all know (no the Fb…), to do so we need to use the following packages: library(AnnotationDbi) #annotation data base package: https://bioconductor.org/packages/release/bioc/vignettes/AnnotationDbi/inst/doc/IntroToAnnotationPackages.pdf library(org.Dm.eg.db) #Drosophila melanogaster (Dm) data base library(dplyr) #this package allows us to manipulate better the data.frames 5.5.4.1 Get the names of the genes What we need now is to build some kind of dictionary that will be able to translate between both name types: FB to Symbol. So, we first create an object with the GeneNames in both types. To do so we will use the select function. As you will notice if you try the first line of comand select(org.Dm.eg.db, c(as.character(annotatedPeak$feature)), \"SYMBOL\", keytype = \"ENSEMBL\"), there is a problem with this function. Basically this comes from the fact that both AnnotationDbi and dplyr have a function named select. R will call the function from the last package executed. To tell R which package we want to use we have to write: Package::function, in this case: AnnotationDbi::select. Other solutions to this “function name collision” issue are: execute the package from which we want to use the conflicting function in the last place. Rename the conflicting function after running the first package. In this case: library(AnnotationDbi) ##annotation data base package library(org.Dm.eg.db) ##Drosophila melanogaster (Dm) data base dm.select=select library(dplyr) GeneNames = AnnotationDbi::select(org.Dm.eg.db, c(as.character(annotatedPeak$feature)), &quot;SYMBOL&quot;, keytype = &quot;ENSEMBL&quot;) ## &#39;select()&#39; returned many:many mapping between keys and columns GeneNames$feature=GeneNames$ENSEMBL How does this looks like? head(GeneNames) ## ENSEMBL SYMBOL feature ## 1 FBgn0031209 Ir21a FBgn0031209 ## 2 FBgn0031209 Ir21a FBgn0031209 ## 3 FBgn0267987 &lt;NA&gt; FBgn0267987 ## 4 FBgn0267987 &lt;NA&gt; FBgn0267987 ## 5 FBgn0267987 &lt;NA&gt; FBgn0267987 ## 6 FBgn0051973 Cda5 FBgn0051973 class(GeneNames) ## [1] &quot;data.frame&quot; GeneNames=GeneNames[,-1] #what is this doing? To see what happened we can look at the object again after that head(GeneNames) ## SYMBOL feature ## 1 Ir21a FBgn0031209 ## 2 Ir21a FBgn0031209 ## 3 &lt;NA&gt; FBgn0267987 ## 4 &lt;NA&gt; FBgn0267987 ## 5 &lt;NA&gt; FBgn0267987 ## 6 Cda5 FBgn0051973 5.5.4.2 Create a data frame with the peak annotation and the NEW names We will then put the names into the first table. To this end we will use dplyr package function by doing a left_join. This is actually a type of merging in which we keep everything that is in the first object. Why do you think we do this? We can explore the join options, here are some graphic explanation, and if you want to know more you can go to the manual and try the examples. Also, I would recommend you to read the cheatsheet. Figure 5.1: Different joint options from dplyr. Adapted from cheatsheet. class(annotatedPeak) # this tells us the class, which type is it? annotatedPeak_df=as.data.frame(annotatedPeak) # we will change it to data.frame to have an object we can manipulate better and write to a table annotatedPeak_df=left_join(annotatedPeak_df,GeneNames, by=&quot;feature&quot;) #What is this doing? ## [1] &quot;GRanges&quot; ## attr(,&quot;package&quot;) ## [1] &quot;GenomicRanges&quot; 5.5.5 Explore and export the table We can now see how the table looks like and export it as a .txt table so we can explore it outside R. as.data.frame(head(annotatedPeak_df))#how it looks? write.table(annotatedPeak_df,file = &quot;../macs2_analysis_p0.05/ChipPeakAnno_results.xls&quot;,row.names = T,col.names = T,sep=&quot;\\t&quot;) #this is writing the table, look in your directory and try opening it with excel. ## seqnames start end width strand length abs_summit pileup X.log10.pvalue. ## 1 chr2L 34224 34348 125 * 125 34306 20.88 2.75497 ## 2 chr2L 34224 34348 125 * 125 34306 20.88 2.75497 ## 3 chr2L 34965 35180 216 * 216 35108 23.26 3.33362 ## 4 chr2L 34965 35180 216 * 216 35108 23.26 3.33362 ## 5 chr2L 40369 40577 209 * 209 40492 30.42 7.01721 ## 6 chr2L 40369 40577 209 * 209 40492 30.42 7.01721 ## fold_enrichment X.log10.qvalue. name peak ## 1 1.97319 1.12350 PeakAna_clk_Ip_vs_INP_peak_1 00001 ## 2 1.97319 1.12350 PeakAna_clk_Ip_vs_INP_peak_1 00001 ## 3 2.02190 1.65302 PeakAna_clk_Ip_vs_INP_peak_2 00002 ## 4 2.02190 1.65302 PeakAna_clk_Ip_vs_INP_peak_2 00002 ## 5 2.83398 5.05903 PeakAna_clk_Ip_vs_INP_peak_3 00003 ## 6 2.83398 5.05903 PeakAna_clk_Ip_vs_INP_peak_3 00003 ## feature start_position end_position feature_strand insideFeature ## 1 FBgn0031209 21823 25155 - upstream ## 2 FBgn0031209 21823 25155 - upstream ## 3 FBgn0031209 21823 25155 - upstream ## 4 FBgn0031209 21823 25155 - upstream ## 5 FBgn0267987 54817 55767 + upstream ## 6 FBgn0267987 54817 55767 + upstream ## distancetoFeature shortestDistance fromOverlappingOrNearest SYMBOL ## 1 -9069 9069 NearestLocation Ir21a ## 2 -9069 9069 NearestLocation Ir21a ## 3 -9810 9810 NearestLocation Ir21a ## 4 -9810 9810 NearestLocation Ir21a ## 5 -14448 14240 NearestLocation &lt;NA&gt; ## 6 -14448 14240 NearestLocation &lt;NA&gt; 5.6 Annotate with ChIPseeker We are going to use now ChIPseeker, another chip-seq annotation package. We need to do again many things, like extracting the Gene-names. Luckily we already did part of the work. library(ChIPseeker) #we will use the Genomic Ranges object created previously and the txdb also peakAnno &lt;- annotatePeak(peaksGR, TxDb=txdb, verbose=FALSE) peakAnno_df &lt;- as.data.frame(peakAnno) GeneNames = AnnotationDbi::select(org.Dm.eg.db, c(as.character(peakAnno_df$geneId)), &quot;SYMBOL&quot;, keytype = &quot;ENSEMBL&quot;) GeneNames$geneId=GeneNames$ENSEMBL head(GeneNames) ## ENSEMBL SYMBOL geneId ## 1 FBgn0031209 Ir21a FBgn0031209 ## 2 FBgn0031209 Ir21a FBgn0031209 ## 3 FBgn0267987 &lt;NA&gt; FBgn0267987 ## 4 FBgn0051973 Cda5 FBgn0051973 ## 5 FBgn0051973 Cda5 FBgn0051973 ## 6 FBgn0051973 Cda5 FBgn0051973 GeneNames=GeneNames[,-1] peakAnno_df=peakAnno_df %&gt;% left_join(GeneNames, by=&quot;geneId&quot;) #this is merging the two tables by the column Geneld 5.6.1 Explore and Export the output If we look at the head of the file we can see that we have a different annotation format for the peaks and that we actually have a distance to the TSS. We will save this file as well. head(peakAnno_df) write.table(peakAnno_df,file = &quot;ChIPseekerAnno_results.xls&quot;,row.names = T,col.names = T,sep=&quot;\\t&quot;) #try looking at it on excel or any other spreadsheet editor, what are the differences you see with the previous one? ## seqnames start end width strand length abs_summit pileup X.log10.pvalue. ## 1 chr2L 34224 34348 125 * 125 34306 20.88 2.75497 ## 2 chr2L 34224 34348 125 * 125 34306 20.88 2.75497 ## 3 chr2L 34965 35180 216 * 216 35108 23.26 3.33362 ## 4 chr2L 34965 35180 216 * 216 35108 23.26 3.33362 ## 5 chr2L 40369 40577 209 * 209 40492 30.42 7.01721 ## 6 chr2L 57282 57429 148 * 148 57365 22.07 3.47781 ## fold_enrichment X.log10.qvalue. name ## 1 1.97319 1.12350 PeakAna_clk_Ip_vs_INP_peak_1 ## 2 1.97319 1.12350 PeakAna_clk_Ip_vs_INP_peak_1 ## 3 2.02190 1.65302 PeakAna_clk_Ip_vs_INP_peak_2 ## 4 2.02190 1.65302 PeakAna_clk_Ip_vs_INP_peak_2 ## 5 2.83398 5.05903 PeakAna_clk_Ip_vs_INP_peak_3 ## 6 2.08079 1.77350 PeakAna_clk_Ip_vs_INP_peak_4 ## annotation geneChr geneStart geneEnd ## 1 Exon (FBtr0078163/FBgn0051973, exon 7 of 13) 1 21823 25155 ## 2 Exon (FBtr0078163/FBgn0051973, exon 7 of 13) 1 21823 25155 ## 3 Exon (FBtr0078163/FBgn0051973, exon 5 of 13) 1 21823 25155 ## 4 Exon (FBtr0078163/FBgn0051973, exon 5 of 13) 1 21823 25155 ## 5 Intron (FBtr0078163/FBgn0051973, intron 2 of 12) 1 54817 55767 ## 6 Promoter (1-2kb) 1 25402 59268 ## geneLength geneStrand geneId transcriptId distanceToTSS SYMBOL ## 1 3333 2 FBgn0031209 FBtr0113008 -9069 Ir21a ## 2 3333 2 FBgn0031209 FBtr0113008 -9069 Ir21a ## 3 3333 2 FBgn0031209 FBtr0113008 -9810 Ir21a ## 4 3333 2 FBgn0031209 FBtr0113008 -9810 Ir21a ## 5 951 1 FBgn0267987 FBtr0347585 -14240 &lt;NA&gt; ## 6 33867 2 FBgn0051973 FBtr0078163 1839 Cda5 5.6.2 Positive controls. We can now explore the data back at IGV and see if the genes we get a significantly enriched for this TF are actually enriched. Lets think about some controls we can do with the data. Which is the protein we are analyzing? Is there any gene we already know that protein might be regulating? Well, yes. We are analyzing Clk, that happens to regulate tim. So, making it more general: Other option to see if our analysis and the data in general make sense is to go to previous literature and see what genes we know that are regulated by this TF. Then, we expect them to be enriched in our analysis. peakAnno_df_tim=peakAnno_df[which(peakAnno_df$SYMBOL==&quot;tim&quot;),] #What we are doing here?, remember Lab 2! peakAnno_df_tim=peakAnno_df_tim[order(peakAnno_df_tim$X.log10.pvalue.,decreasing = T),] # we order them by log10(pval), what that really means? as.data.frame(head(peakAnno_df_tim)) ## seqnames start end width strand length abs_summit pileup ## 3983 chr2L 3504149 3508352 4204 * 4204 3507246 140.77 ## 3984 chr2L 3504149 3508352 4204 * 4204 3507246 140.77 ## 3985 chr2L 3504149 3508352 4204 * 4204 3507246 140.77 ## 3986 chr2L 3504149 3508352 4204 * 4204 3507246 140.77 ## 3987 chr2L 3504149 3508352 4204 * 4204 3507246 140.77 ## 3988 chr2L 3504149 3508352 4204 * 4204 3507246 140.77 ## X.log10.pvalue. fold_enrichment X.log10.qvalue. ## 3983 34.61634 3.45781 31.83545 ## 3984 34.61634 3.45781 31.83545 ## 3985 34.61634 3.45781 31.83545 ## 3986 34.61634 3.45781 31.83545 ## 3987 34.61634 3.45781 31.83545 ## 3988 34.61634 3.45781 31.83545 ## name annotation geneChr geneStart geneEnd ## 3983 PeakAna_clk_Ip_vs_INP_peak_539 Promoter (&lt;=1kb) 1 3493986 3507218 ## 3984 PeakAna_clk_Ip_vs_INP_peak_539 Promoter (&lt;=1kb) 1 3493986 3507218 ## 3985 PeakAna_clk_Ip_vs_INP_peak_539 Promoter (&lt;=1kb) 1 3493986 3507218 ## 3986 PeakAna_clk_Ip_vs_INP_peak_539 Promoter (&lt;=1kb) 1 3493986 3507218 ## 3987 PeakAna_clk_Ip_vs_INP_peak_539 Promoter (&lt;=1kb) 1 3493986 3507218 ## 3988 PeakAna_clk_Ip_vs_INP_peak_539 Promoter (&lt;=1kb) 1 3493986 3507218 ## geneLength geneStrand geneId transcriptId distanceToTSS SYMBOL ## 3983 13233 2 FBgn0014396 FBtr0077567 0 tim ## 3984 13233 2 FBgn0014396 FBtr0077567 0 tim ## 3985 13233 2 FBgn0014396 FBtr0077567 0 tim ## 3986 13233 2 FBgn0014396 FBtr0077567 0 tim ## 3987 13233 2 FBgn0014396 FBtr0077567 0 tim ## 3988 13233 2 FBgn0014396 FBtr0077567 0 tim 5.6.3 Plots This package has some useful plot functions so we can explore the results more easily. First we can see the peaks over the chromosomes. For that we use the function covplot. Its name comes from “coverage plot”. What do you think about the results? Do they make sense? covplot(peaksGR, weightCol=&quot;X.log10.pvalue.&quot;,chrs=c(&quot;chr2L&quot;,&quot;chr2R&quot;,&quot;chr3L&quot;,&quot;chr3R&quot;,&quot;chr4&quot;,&quot;chrX&quot;,&quot;chrY&quot;)) Figure 5.2: Coverage plot. And then a general distribution of the peaks in relation with he transcription start site (TSS). For that we use the function peakHeatmap and plotAvgProf2. peakHeatmap(peaksGR, TxDb=txdb, upstream=1000, downstream=1000, color=&quot;darkviolet&quot;) Figure 5.3: Peak heatmap. ## &gt;&gt; preparing promoter regions... 2020-08-30 21:12:31 ## &gt;&gt; preparing tag matrix... 2020-08-30 21:12:32 ## &gt;&gt; generating figure... 2020-08-30 21:12:37 ## &gt;&gt; done... 2020-08-30 21:12:41 plotAvgProf2(peaksGR, TxDb=txdb, upstream=1000, downstream=1000, xlab=&quot;Genomic Region (5&#39;-&gt;3&#39;)&quot;, ylab = &quot;Read Count Frequency&quot;) #Try exploring the options of this function. Figure 5.4: Average coverage plot. ## &gt;&gt; preparing promoter regions... 2020-08-30 21:12:42 ## &gt;&gt; preparing tag matrix... 2020-08-30 21:12:42 ## &gt;&gt; plotting figure... 2020-08-30 21:12:45 5.7 Sequence Motif analysis Another goal now is to analyze this peaks and see a pattern enrichment and see if we can find a Binding Motif for Clk in fly head. This is basically DNA analysis, so we will have to figure out the regular DNA motifs and see if there is any specific enrichment. For this we will use the following libraries: library(Biostrings); library(seqLogo); library(BCRANK); library(gridExtra) 5.7.1 Put the peak sequences in fasta format To parse the corresponding sequences from the reference genome, the getSeq function from the Biostrings package can be used. The following example parses the sequences for each peak set and saves the results to separate FASTA files, one for each peak set. In addition, the sequences in the FASTA files are ranked (sorted) by increasing p-values as expected by some motif discovery tools, such as BCRANK. library(&quot;Rsamtools&quot;) #we will use the Rsamtools package for this. peaksGR &lt;- peaksGR[order(peaksGR$X.log10.pvalue., decreasing=TRUE)] #order the peaks according to pvalue. as.data.frame(head(peaksGR)) ## seqnames start end width strand length abs_summit pileup ## 1 chr2L 3133811 3135424 1614 * 1614 3134481 140.17 ## 2 chr2L 3136702 3137388 687 * 687 3136981 140.77 ## 3 chr2L 7649255 7651111 1857 * 1857 7649737 140.77 ## 4 chr2L 7661000 7661782 783 * 783 7661451 140.77 ## 5 chr2L 14249821 14250599 779 * 779 14250165 140.77 ## 6 chr2L 18077759 18081655 3897 * 3897 18078127 140.77 ## X.log10.pvalue. fold_enrichment X.log10.qvalue. ## 1 106.096 12.73315 97.93874 ## 2 106.096 12.78695 97.93874 ## 3 106.096 12.78695 97.93874 ## 4 106.096 12.78695 97.93874 ## 5 106.096 12.78695 97.93874 ## 6 106.096 12.78695 97.93874 ## name ## 1 PeakAna_clk_Ip_vs_INP_peak_474 ## 2 PeakAna_clk_Ip_vs_INP_peak_477 ## 3 PeakAna_clk_Ip_vs_INP_peak_1071 ## 4 PeakAna_clk_Ip_vs_INP_peak_1079 ## 5 PeakAna_clk_Ip_vs_INP_peak_1893 ## 6 PeakAna_clk_Ip_vs_INP_peak_2290 pseq &lt;- getSeq(FaFile(file = &quot;../macs2_analysis_p0.05/dm6.fa&quot;), peaksGR) #extract the sequence of the peaks using the genome fasta file dm6.fa and the genome-ranges in the object peaksGR We can now see how the pseq object looks like. as.data.frame(head(pseq)) ## x ## 1 ACCCATTAAATTGTCAATATTACTTAAGCCCTTTATGGTATTGGAAACTCCCGTTTCACATAATTAAACATGGAATGCAGCAAAAAATTTTCCGTGCAATTGCAAATGGCATTTTACGAGAGAAAATTGTTGACAATAATGAAGCTGATGAACATTTGTGGTTGTGTTCATTGTCATTGTTGCTGCGTTAGTTATTCTACCATCGGTTGGGGTGCATTTGGGCCAGTCTGGAACTGTTTGCGTCATTGTTCAGTTTTAGTTCTCTGCGGTTGCCTGAAATTGTCGTAATGCATTTACGGACATCGCACACACATGTGGCCCAAGTGCGGTTTTGTAGCTGGAAATGTTGGCTGTGTACTGTAAACAAGATTTTAGCAAACCCACTTGCATTTCTCCTGGGGGTCATGTGTCAGCACTTATAATTTTGTTTAAAGAACTAAGAGAAAAATGTCCACTATCTAGAAAATCATTACTATCAAAAAACCCAATTTATATCAGTAACGTTCGATTTCTAAACTCATATTGACATTTTTGTATGTATATTATGTATGTATATAAATGTTCATATTTGTTTCCCTTTTGGTTGCGTACCTAACCACCACCTATAAATTAGCCCGTTCTGCCAATATTAGCCCTTTCATATCTCGTTACTCATACGCCACGTGGTCACGTTTTTGCCTAAGCTCTACGTAGCTGCACTCGCTGCACTTTCCGCTTACGTTTTGTTATTATTTTCCCCAGTACTCGTTAGCCTTGTCTAGTGCCAAAATGAAATGACAATGTTTTCCCAGCGCACAGAACTCAAATCGTAAATCATTTTCTTTTTTTTGGGGTGTTGGCAAAGGTAAACAATGTCACATAGGAGCCCGCAGTTGTCTGTCAGTAGAGAAAAAGGCAAAAAGATTAGAGATATATGGACTGCGGAGAGCGGGGCAGAATGCGAGATATATAGCAACTCAAGTTTGTGTTGCCACGAACTTTGACAGTTACATGCGCTGCACCATTGCAGAATGACAAACGAAGGCGAAAAAAGCCATGAGTTGCACAAAATGTATTTATCTGTCATTCCAGTTTTCACTTTCGCAAAAAGTGGTAGATTTTGGGTTTTGTGTGGAATCATATCTAGCTTTATAGCTCTTGGGGAACTATAATATGACTTAAATACCAAATATTTATATACTCAAGTTTAATATAATACATTTCACGTAGTTTTAACGCAAAACGGAATATGCTAGAATTTATCTTTTCCACTTCGTTTCCCCTCTGATTCTCGCACTTTCCCCCAAACTCTCGGCGTTTGTGTGTGTGCCTGTCTGGCTTTTCTTTTTCGTCTCCGTTCGTGACAGCTTGTTTTTTTGGGGGCGTGGCGAGGGGCGGAAGGGGTTGGGCATTTGGGTCAACTATCGACTGCAATTTGAGCCTTTCAAACTGTCGCCGACACAAAACGAAGGGCTCAGCTGAAAAAAAAAACACACAGTCAGGCAGAGTAAAAGTTGCGGAAAGTGTGACAGCAACTCATTGCAGATGGACATTTGCCGAGTCTGCTGGGAATCCCCTCAAGTGCTCTGGAAATTTGATTTCGATTTCCATATGATTTTGATTTGGCCAGCGAAC ## 2 CTTCCCCTTTTATTACTGTTCCAAGGACATTCAAATTAAGCATTCATTTGCGGTGATATCACCGGCTTTAATGCTCTGAACTCCACGAAGAGTTGACTAACCTCGAACTGTGCTACATTTTTTTATGCACCTCCATCATACACACATTTTGTCGTGTAATTTGCACGCTGAGTCTATTAAATGCACTGCAACCGAGTTGTGTCAGCACCTCAGGTGTACAGAGCTTTCACTCACACTCATATACGATTCATAAACATTTGTTGTGGCGCCCAACGTGGGGCATGAAATGCGACGTGTTACACAAGTGGGAAGAAGAAGGTGCAAGTCATTAAGTAAGCTTGTTTTTGTTCTGATTTTTCTCGTTGTTTTCAGGGAAGAGGCCATAAAAGCTTCGTGCGCCACGCACACATGCACACATAATTATAATGGGCATTAAAACGGACGCCTGTGGCCTAACTCTTAGTTTGTCTTGTTCGCCAGCAGGCTTCTTAACCCTCACACTGTCCAACTTGGCTACCTCTGAGTGCTTTATGGCGCAACTGGTAGAATGATTCGCCGAGCATAATATTTAACTCGGAATTCCCTGCTAAACGCACATAATGTCTGCCCAAGACAGTCCCGGTTCCCAGCGGCGAAATTCATTTTCTTGTCGCTTACAAATTATTTTAAAGGTATTTAAAGTTAGAT ## 3 AAAACAGAAGCTCTAGCATTGTTGTGATACATTAAAGAACTTTACTGACCTGGCCAATTTGTGGATAGTGCTGCAGCTCCATCTCGAGCACCCGCATGGACGGCTTGGGGGTTGTCAGCTCCTGGCCCGTGCACATCTCGTAGAGCAGGTGGCCAAAGCAGACGATGTCCACGTTCTCGATCTCGGTGACCGAGCGGGACCACATGACGGCGTTAATGCGCGAACTGAGGCCCAGGAGGCCGTTCTCCAGGCCCGATAACCTGATGGGTGAAAAACGGAATAAATGTTACGGAAAATGCATAATTAAATGGCGGACCCCTTGTGCTTTCCTTCCCTTTTGTTTCGGTCTTAATTATGCAACATATTCGATGGCTACCCTGCCGTATATTGATGGCCAACACGTGGAAACGTCGGCCGCAAAGTGTCTACTTTTATGGATTTATGTGCGAGCGAGAGGGAGCAGGTATCATCTGCTATCTCTTTCCTCACTGGCCATGTGCCTTAATGACAAAGAGCGTATGTCAGACCTGATATGACAATATTATGACACTCTACACAACACAGCGCTGTATATTGCGGATTGGTTGGGGCTTTTGGTTCGAGGGTCCTGCCGGCATTTCCTAGTATTCATTAGGCCAAATGTGGCTGACTAGTTGGAAAGGTATTCCGAATTGGCTGACAATAGAGGTTCTGAAGATGCTAGTTGTCGTGTGCTATAGTTTATTGGCTTTTGTTGCCAGTTGCCTTTGTTTATTTTATGATCATTTTAATTAGTTTTGAAAATCAGATAAGTATAAATATACGAAAAAAAATCATTTGGGCTTAAAAAAGTTCAATACAAATTGTTGAGTCAACAGGTTACTCCAGAAGTATTTGTTGTCAAATTTACTATCAAATATAAGCATGTTTTTCTTTAGCTGTTATAAAACAATAAAAGCGTTGTGCAGACATTAAATGCTTTCTTTTATTGTCATTGCAAATATCCTGAAATTCTTCACTCAATTTCACTTGAGCAAGCATTTTCTTTTCTACTTCGTCAATCAGCTTTTCAGCTTACTAAATTCCATTTTACCCGTTTTCTTCACGTTGGTCTTTCAACTTTCCTGTGGCCCTATCAATAGCTGTACGTATGTATAAGCAATTTATATGAAAATCAGCTTTTCAATGCGCACAGCGATACCCTGGCGACGAAGGCAGCAAAATTGGGTCATGCACTTGGCGCAAACTTGAACGCAGAAAATCCGCACTTTAATCGACTTTCACCTATAGGAATTCTAGCTTGCAGATCCCACCCTCTTTTAGTCCCGTCCCTGGGCTGCAATATAACCATCTTTTTCGCCGACCATTTATTTTTAAAATGGCAAAAAGCTTAAGCTTTATTTTTGTTACACCCATTCGATGTTTGCAAGTGGGTGGTTTAGTGGGTGGCGCTTACGCGTTGTCGCACAGCAGCTACATGGATAGGAGGGGGCCAGTCAGGGGCTCACGAAACAGGGACATGCATTTAAAGTGCCCTGAAATGGGCAACGATTCTGGGGAATTGCTTTTAATTTGCCATTTAGGCTGAAATCGATGTCGGTTCTATTTGGGTGAATTTTGAATGACTGAAATTTTGCAGTGGAGATAGGGGGGCAGGCCACCGATTCGATATAAAATATTGCAGCCATTATTAAATTAGTTAACAGTTGAGTGGGTCCCAATCGACAACGGACTCACCTGGCTGCCCCGTTCTGCAGGATGACATTGCCGCTGTGCAGGTGACCGTGAAGCGGAAAACCGCGCTCCTTCAGGAAGAGCAGTGCCTCCAGAATCTGTCGTCCCAGGCGCTGCACCTGGCTCACCGGTAAGCCATTTGGC ## 4 GGCGCCAACAATCGTAATGGATCCTGGCATGAAAACGGGATGAGGAGACCCAATGGTCACCGCCCTCTAAATGCCGAAAGTCAACTGCGTCATTGTTTGGGGAGAACAGGCCAGCTCCAGCTGAATTTCCTCGATTTTCCGAGGGGTGAGATAAAGGGCCCCGGGCCAGGATGGCCAGGCCCATTTCCAGTGACCTTGCATCATTAACTTAATTGCTCAAACAGTAGTCGGTCCGTCCAATTGCCGGGCTGAATTATTCAGTTGTTCTGCTCGGCCAACTGGCAATTTTGCGTCTTTACTAATGTCACCACAAGCTCATAGAGGAAGCGCTGTCTCTCTCTATTCGGCGCTGCACTGGAAAAGCCATCCGACAGAACCGTTTTTCCATGGGGGCCGGTGAAAATCCCCCACGTGCATTCGGTGTGGTCGTTGGCCCGTTCACGTTGTCCCCCCATTTTAAAGGGGCGTCACGTGTAGCGGGGCTTAGTCCCCCCCACCACAATTTGACATTTTTTACGAAAACAAAATGCAGAGATACGAAGAGAAAAACCAGGCCCAAACAATTTTCACCGGACTAATTGGATTCAAGAGTTTTCCTGCTGCGCTTTTGTCAACGCATATTGCAACAGAAATATTCATATTTATTTATATATAAAAATTCACTGTCAGTACAGCCTAGCCTATAGTTGAATACATACCTGCATCGTCTTATCCAGTATGAAATTACAACAATTCCACCCAATATCAAACCACCTAAGGCACACCAAAAGAGGGTCTGAAAAG ## 5 AGGAAAACTCCTAACAAGCTTTAAAAACCTAGCAAGCTAACTACCTTTTTCTTAATTCTCTGGTTCGTTTCGCACACCTGATTAATGGGTTAATGTATCTATTTTTATGCACCCAGCTGCCACTCAGTTGGCTTTGACTGGTCTCGGGGATAAGTGGCAAAGAGGCCGGCTAATCAGGCCCAAAGGTAAAGCCAAAGCCAAAGCCATGAACCAACGAACCGCCCAACAGCCCAACCACCGAAACGCCCCACCCATCCGCTGGTGACCCACTTGAGCATGCACCGCTCGTGACATTGGGCAGGGAAACGTGCAGAAGCGACGGGAAATCGACAAGAAGACAAACAAAACAGCAAAACGTGCAGAACGTCACTTTCGGGCCGCCTTTTTGTTGTTAATTTAGAGAGATGCGTCACAGCGAAAAGTGTTAAGAAAGAAATGCGCGGAAAATCAGGAAATGTAAGCGGTGAGAACTGCGCATTAAGCATCGCATTGCATCGCACGGCAAAACGCAGCCAAATAAAGCGAAACAACAGCGGAGACAGGCGCAATGTTGACAATTGTTGAAACTGACAGTTTGACGTTTTAACTCACGCGCCAAACGCCAAACGTCAAACGGCAGCAACAACCAACACAATATCAACATCAGCAACATAGTAATACGTTGTACGGCCAAACGGCAATCTAGGCAAATCCACCGAGTAGACAACTCAATGAGCCATTTTGATGGACACCTCCGACGACAGCTGTACGGCACACGAATGTATATAATGCATATTCAT ## 6 TGGAATACTTGGAATTTATTAAGTACCTCGTTGTTATAACTAGTAGTTGTCTCCAGTTAACATAAAGCTATTATAAATGTCATAATAAACAACCGCTTATCAGTACTTAGCCGACGAGTGCTTAGGGCTCAATTAAATTAACAACAATTACGTAAATGGAAAAGAACAAAACCCACCACGTAATGTTTGGGTTTAAATACGTCATCCTAGGCGGAAAACAACAAACCAAAATACGCATACTAAATCGATTTCTCGAGCTATTTCTGTACATTCACCTGTCCTGCATTGCTAATACGCCGTGTTGCTCGCGCGTTATTTAATGTTTGAGCCATCGATGTCGATGTCGTGCTGCAATGTCAATATCAAAGACACTGCGCACAGCAAGGTTGCCGAAGCCGTAGTAGTTTACCGCCGTGCAATTGCTGAATTTCTGCTGTGCGGCTAATTGAATTTAGAGGGGCGACAGGTGCCACAATGCCAGGTATAAATGCCGGATTGCCAAAGAGCGCTAATTAATAGCCTAGTGGACCACGCAACGCGGCGTATACCATCGAGAACGAGCGCGAAACGTTAAAGGCACATCCAAAGTTTAAACTATTTCCGCAGAGATTTTGATAAACAGCTCCAAAATGGTGGTCAATTTCAAGGTGTTCAAGAAGTGTTCCCCGAACAACATGATCACGCTCTACATGAACAGGCGTGATTTTGTAGATTCCGTGACTCAGGTGGAACCCATTGGTAGGTGTCACAGACCGAAACCCTTGAGCAATGGGATTTACGAATGAGGAAATCCATCAAAAAATAAATTCGTGTAGGAATTGGTACCCATATTCGATTGAAGTATCTTATAGTTTGAAAATAACTTCAGTGTAACTTTTGTTTCAACTTAACACATTGGAATTTTTAATACCTTCCTTGAAAAGTGATATCAAATCAAAATTATATTATAAAAACTCCATTTCGAATCTGCATATGCCGACCAGCAAATATAAACTCAGGGAGTTATTCAAAATTGCATCTGAATTCAATAGCCCAGGGAGTTAAGTTAAATTGGCTGCGCTAGCAGCTAACCAAGTTCATCGATTACGCGAGCAAGCAAACCAAGAGGCTGGGCGCTTGTAAATAATATTCTCCAATTAATAAGCGTCCTCTTGCAGATGGAATCATTGTGCTGGACGATGAGTACGTGCGCCAGAACCGCAAGATCTTCGTGCAGTTGGTCTGCAATTTCCGATATGGGCGCGAGGACGACGAGATGATCGGTCTGCGGTTCCAGAAGGAACTGACCCTGGTCTCGCAGCAGGTGTGCCCACCCCAGAAGCAGGACATCCAGTTGACCAAGATGCAGGAGCGTCTGCTGAAGAAGCTTGGCTCCAATGCCTATCCCTTCGTGATGCAGATGCCACCAAGCTCGCCGGCCTCGGTGGTTCTCCAGCAGAAGGCCAGTGACGAGAGCCAGCCCTGCGGAGTCCAGTACTTCGTAAAGATCTTTACCGGAGACAGCGACTGCGATCGATCGCATCGCAGGAGCACCATTAACCTGGGCATCCGCAAGGTGCAGTACGCACCGACCAAGCAGGGCATCCAGCCCTGCACCGTCGTTCGCAAGGACTTCCTTCTGTCGCCCGGAGAGCTCGAACTGGAGGTCACCCTCGACAAGCAGCTGTACCATCACGGCGAGAAGATCTCGGTGAACATCTGCGTGCGCAACAACTCCAACAAGGTGGTGAAGAAGATCAAGGCCATGGTGCAGCAGGGCGTCGATGTGGTCCTGTTCCAGAACGGTCAGTTCCGCAACACGATCGCCTTCATGGAGACGAGCGAGGGATGTCCCCTGAACCCGGGATCCAGCCTGCAGAAGGTCATGTATCTGGTGCCCACCCTGGTGGCCAATTGCGACCGCGCAGGCATCGCCGTTGAGGGTGATATCAAGCGCAAAGACACAGCTCTGGCCTCGACCACACTGTGAGTAAAATTTATTCACATCATAGCTTAGCAGATGAAACATTAATATTATACTCTATTAAGTATCAACTTAAAATCATACCATAAAATCAATCAAATTTTAAAGTTAGGAACCTTTTTAAAAATCGTATTTTCCCGGTGACTAACAGTTCTTTAGCTAAATGTGTTTACAAAATGGCATAAAACGCATACTAATACTAAGTGAAAAATGCATATTTAAAATTCTATTTCAGTATTGCCAGTCAGGATGCGAGGGATGCCTTTGGCATAATTGTTTCATATGCTGTGAAGGTCAAGCTTTTCTTGGGAGCCCTGGGCGGCGAGCTCTGCGCTGAGCTACCATTTATTCTGATGCACCCGAAGGTAATAAAAGGTGTGCCCAAATATTTGAATAGTTATTGAAAGGCAATCAATTATTTACAGCCAAGTCGCAAGGCCCAACTGGAAGCCGAGGGCTCCATTGAGGCCTAAACTGAAAGGGCTACCTCAACCAACGAAAAAAATGGCGTATTTCTACAAGTCAAACCGATTTTTGTAGATCCTAAAAAATGCTGATGTTGCTGAAATGTTCTGAACTGCAGTCGTCGTACTTTTCCTATATAGCAAATCCAATATCCATATATTGTATGTGTGTATGTGTATTATATTTATAACTCAACTAACAATTAAATATGAACAGAGTTTATGTATGTATTTTGGAGTATTCTATTGAATTTAGCACGGTGTATTTGAAAAGGCTCCAGCATTGAAAGTTTGTATGGAATGCGCACTAAATATTTAATAATGTGCTTACGAAGGCATTTCGTAGTATTTGATATCTTGCAATGTCTGCTGATTATGTACATTGAAGTGCAATGGGGAAATCAACAGAAGCCAGTGCAATCTATTCAATTACTAATAGTGGGTCTTGCATTTGTGGCTTAGTAATTCCAATTATTGCTACTCTGAAAAGCCGAGGAGCAGCCTAATTAATACTTGGCCACTATGCTGGAGGAAGTTTACTGAACTGAATTCGAGTAAGGAAAATGGACAATAATTGATATAATATGGTGAGCTTCTTGCTGGACTTTGAAATCGTAAAATTTAAGCGAACACACTTCAAACGCATCCATTTAATTTGTGAATGTTTGCAGTCCCACTTTTAATAAGCACCCAATATTAACGATAACGCCACTCTAATCAAAATTTTCCAATAGTCAGGGTTGAAATACTGATCAATCACGCTGCCAACATTTCGGCAGACCAGGTGGGTAATGAGTTTAAAATGGTTTTGCGTAATGGGATTAATCGAATTTCATTAAGGAAGATTAGATTGCCGTCTTTGGAAGTGATCTTTTATAGTGGCTGACCATAAAAATTGCATTGCAAATACTAATTTAAGCATACATGCTATATAACCGATAAGATGGGCGAGCGTCAAGGCAAAAATAGTTGACCGTATTAATAGTTTAATCAACTAGCTTCAAGTTAATTTATAATGCGAATTAGGAAGCACTCTGGCATGCTATTAAAAACTTAAGAACTGATAAACGAAACTTAATTCCTAAAATAAAAATGTACCTAATTACTTTTATATACTATTATAAATAAAATTGTACCATGTATCGTTAAATTTGATTTAGTTACCAAGTGGTATTTGGTACGTGGCAGCATGAAATAGCTACTACTGCTAGTCTGGCTGATTAGCCAGCACTCTCAATAAACTAAGTGCAGCGTTTTGCATTTATCAGGATTTTTGGTACTCTAAACACACACTTAGATCCCAATCACCCCACAGAATAAGTTGAGCAAACCAAACCGAGCTGATTACCACAGTAGACATGATGATTAGCCGCTGCTTTATTTACTAGTGGATAATCTACTAAGCGACGCATGAATAAAAACTCGAGCGATATTTTTCCACTTTGCAGTCGCTCGAAAGCCTTTGTTTCG writeXStringSet(pseq, filepath = &quot;peaksGR.fasta&quot;) #use the names and save the peaks in fasta format, how this looks like? open it outside R! you can shange the filepath to save it any place you want. 5.7.2 Find the MOTIFS The Bioconductor package BCRANK is one of the many available for de novo discovery of DNA binding motifs in peak regions of ChIP-Seq. The main function we are using here is bcrank. when looking at the documentation we see that: “BCRANK uses a heuristic search strategy. First a score is computed for an initial short consensus sequence, typically selected at random. The score considers both the number of consensus occurrences and the rank of the genomic regions. Then all consensus sequences in a neighborhood of the start guess are evaluated and the one with highest score is kept as the starting point for the next iteration. When a local optimum is found, the algorithm is terminated and the locally optimal consensus is reported as a result. In order to increase the chance of detecting the globally optimal solution, the algorithm may be restarted several times using different random starting points. Alternatively, BCRANK can be used for assigning scores to previously established consensus sequences. The sections below describe in more detail how the neighborhood, scoring function and start guess are implemented.” We will use 25 restarts and a penalty for both repetitive sequences and non-canonical letters. P1 - Penalty on non-specific bases. Let l be the length of the consensus sequence and b the total number of fixed bases (A, C, G, T) in the sequence. If there are no fixed bases, b is set to 0.5. The penalty is then defined as P1 = b/l. P2 - Penalty on repetitive motifs. Let rn, n ∈ 1, 2 be the number of input DNA regions that contain at least n occurrences of the consensus. Then P2 = 1 − (r2/r1). set.seed(0) BCRANKout &lt;- bcrank(&quot;peaksGR.fasta&quot;, restarts=25, use.P1=TRUE, use.P2=TRUE) 5.7.3 Explore the results Then we can also see the results, we will se the results that are in the top. We can first explore the results: the matrix shows the proportion of each letter in each possition for thar specific motif. head(toptable(BCRANKout)) a&lt;-BCRANKout@toplist a[[1]] ## Consensus Score ## 1 CACGT 663.2068 ## 2 CACGT 648.6057 ## 3 GCACGT 550.5658 ## 4 ACGTGC 536.9913 ## 5 CAAAAG 491.8869 ## 6 AAAGCG 491.6031 ## ## An object of class &quot;BCRANKsearch&quot; ## ## Search path, starting from SHVWHRYYDT: ## ## Consensus Score ## 1 SHVWHRYYDT 26.19329 ## 2 SHCWHRYYDT 99.05250 ## 3 SHCWHRTYDT 147.47039 ## 4 SHCWHRTTDT 178.46498 ## 5 HCWHRTTDT 203.84605 ## 6 HCAHRTTDT 263.87039 ## 7 CAHRTTDT 315.05930 ## 8 CAHGTTDT 344.41459 ## 9 CAHGTTD 396.57309 ## 10 CACGTTD 498.50181 ## 11 CACGTT 599.45575 ## 12 CACGT 663.20680 ## ## Position weight matrix for search result (CACGT): ## ## 1 2 3 4 5 ## A 0 1 0 0 0 ## C 1 0 1 0 0 ## G 0 0 0 1 0 ## T 0 0 0 0 1 ## ## ## Use methods searchPath(object) and pwm(object) to access object slots. 5.7.4 Plot the results We can play around with the matrixes and plot them in the known DNA-Logo standard. To do this we will first store the most top motif from toptable. Then we will use the pwa function from BCRANK and the seqLogo function from seqLogo package. topMotif &lt;- toptable(BCRANKout, i=1) weightMatrix &lt;- pwm(topMotif, normalize = FALSE) weightMatrixNormalized &lt;- pwm(topMotif, normalize = TRUE) seqLogo(weightMatrixNormalized,ic.scale = T) Figure 5.5: Most significant sequence logo. We can now do the same with a different function just to show you that you can do the same things with different approaches. This is using function form the seqLogo package. p&lt;-makePWM(as.data.frame(weightMatrixNormalized)) p@consensus seqLogo(p) Figure 5.6: Most significant sequence logo. ## [1] &quot;CACGT&quot; We will create a table to be able to analyze the data topt&lt;-as.data.frame(toptable(BCRANKout)) #extract the results table head(topt) ## Consensus Score ## 1 CACGT 663.2068 ## 2 CACGT 648.6057 ## 3 GCACGT 550.5658 ## 4 ACGTGC 536.9913 ## 5 CAAAAG 491.8869 ## 6 AAAGCG 491.6031 5.7.5 Plotting with Ggplot2 Now with ggplot we will use a package called ggseqlogo. This will be nice to learn how to install packages from github (you have to use the package devtools and then the function install_github). http://www.bioconductor.org/packages//2.11/bioc/vignettes/seqLogo/inst/doc/seqLogo.pdf library(ggplot2) #install.packages(&quot;devtools&quot;) library(&quot;devtools&quot;) #this library is literally called &quot;developers tools&quot; and allow us to do more complex things as downloading packages from github ## Loading required package: usethis #install_github(&quot;omarwagih/ggseqlogo&quot;) library(ggseqlogo) 5.7.5.1 Create the matrixes for ggplot2 We will first store all the matrixes in a list so we can then just plot them all together and not only one by one. # Some example DNA sequences, lets try to go together over what is this loop doing seqs_list=list() #first we create an empty list that we will fill up over the loop for(e in 1:16){ #we will loop 16 times #print(e) #we will print every loop topMotif &lt;- toptable(BCRANKout, i=e) #we get the motif number e (ie, the iteration will let us go from top motif 1 to 16) weightMatrixNormalized &lt;- pwm(topMotif, normalize = TRUE) #do some process with the motif seqs_list[[e]]&lt;-weightMatrixNormalized #add the processed motif to the list in position e (ie. the loop allows us to fill up the list) } 5.7.5.2 Plot We can now, either plot one by one for each position in the list. # Get first set of sequences seqs_dna = seqs_list[[1]] # Plot a sequence logo with the 2 different methods available p1 = ggseqlogo( seqs_dna, method = &#39;prob&#39; ) p2 = ggseqlogo( seqs_dna, method = &#39;bits&#39; ) +labs(y=&quot;Information Content&quot;) #this changed the name of the `y` axes grid.arrange(p1, p2) Figure 3.10: Most significant sequence logo in probability and percentage of information. Or we can plot all together using the facet function to actually separate them. #Plot all the first 12 sequences ggplot() + geom_logo(seqs_list,method = &#39;prob&#39;) + theme_logo() + facet_wrap(~seq_group, ncol=4) Figure 3.11: Many significant sequence logo in probability and percentage of information. 5.8 Extra: How to solve some common annotation issues. Lets see some regular problem and how to solve it. I will show you first a regular problem we can have: annotation files do not correlate with the one previously used for annotation. txdb &lt;- makeTxDbFromGFF(file=&quot;../macs2_analysis_p0.05/Drosophila_melanogaster.BDGP6.92.gtf&quot;, format = &quot;gtf&quot;, dataSource=&quot;dm6&quot;, organism=&quot;Drosophila melanogaster&quot;) saveDb(txdb, file=&quot;./dm6.sqlite&quot;) txdb &lt;- loadDb(&quot;./dm6.sqlite&quot;) class(txdb) ## TxDb object: ## # Db type: TxDb ## # Supporting package: GenomicFeatures ## # Data source: dm6 ## # Organism: Drosophila melanogaster ## # Taxonomy ID: 7227 ## # miRBase build ID: NA ## # Genome: NA ## # transcript_nrow: 34767 ## # exon_nrow: 87482 ## # cds_nrow: 62757 ## # Db created by: GenomicFeatures package from Bioconductor ## # Creation time: 2020-08-30 21:13:02 -0400 (Sun, 30 Aug 2020) ## # GenomicFeatures version at creation time: 1.38.2 ## # RSQLite version at creation time: 2.2.0 ## # DBSCHEMAVERSION: 1.2 ## [1] &quot;TxDb&quot; ## attr(,&quot;package&quot;) ## [1] &quot;GenomicFeatures&quot; Now we can actually extract the gene location from the annotation that we created ge &lt;- genes(txdb, columns=c(&quot;tx_name&quot;, &quot;gene_id&quot;, &quot;tx_type&quot;)) #get the genes genomic ranges as.data.frame(head(ge)) ## seqnames start end width strand tx_name gene_id ## FBgn0000003 3R 6822498 6822796 299 + FBtr0081624 FBgn0000003 ## FBgn0000008 2R 22136968 22172834 35867 + FBtr0071.... FBgn0000008 ## FBgn0000014 3R 16807214 16830049 22836 - FBtr0306.... FBgn0000014 ## FBgn0000015 3R 16927212 16972236 45025 - FBtr0415.... FBgn0000015 ## FBgn0000017 3L 16615866 16647882 32017 - FBtr0112.... FBgn0000017 ## FBgn0000018 2L 10973443 10975293 1851 - FBtr0080168 FBgn0000018 ## tx_type ## FBgn0000003 transcript ## FBgn0000008 transcript ## FBgn0000014 transcript ## FBgn0000015 transcript ## FBgn0000017 transcript ## FBgn0000018 transcript Now we will use the function annotatePeakInBach ?annotatePeakInBatch() #to undestand what are the features we need peaksGR&lt;-GRanges(macs.res) # create the GRanges object of the macs-table annotatedPeak &lt;- annotatePeakInBatch(peaksGR, AnnotationData=genes(txdb)) head(annotatedPeak) ## GRanges object with 6 ranges and 16 metadata columns: ## seqnames ranges strand | length abs_summit pileup ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; | &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; ## X00001.NA chr2L 34224-34348 * | 125 34306 20.88 ## X00002.NA chr2L 34965-35180 * | 216 35108 23.26 ## X00003.NA chr2L 40369-40577 * | 209 40492 30.42 ## X00004.NA chr2L 57282-57429 * | 148 57365 22.07 ## X00005.NA chr2L 58368-58696 * | 329 58541 39.37 ## X00006.NA chr2L 62014-62139 * | 126 62048 19.68 ## X.log10.pvalue. fold_enrichment X.log10.qvalue. ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## X00001.NA 2.75497 1.97319 1.1235 ## X00002.NA 3.33362 2.0219 1.65302 ## X00003.NA 7.01721 2.83398 5.05903 ## X00004.NA 3.47781 2.08079 1.7735 ## X00005.NA 12.02019 3.64098 9.82848 ## X00006.NA 2.42109 1.86559 0.83175 ## name peak feature start_position ## &lt;factor&gt; &lt;character&gt; &lt;character&gt; &lt;integer&gt; ## X00001.NA PeakAna_clk_Ip_vs_INP_peak_1 00001 &lt;NA&gt; &lt;NA&gt; ## X00002.NA PeakAna_clk_Ip_vs_INP_peak_2 00002 &lt;NA&gt; &lt;NA&gt; ## X00003.NA PeakAna_clk_Ip_vs_INP_peak_3 00003 &lt;NA&gt; &lt;NA&gt; ## X00004.NA PeakAna_clk_Ip_vs_INP_peak_4 00004 &lt;NA&gt; &lt;NA&gt; ## X00005.NA PeakAna_clk_Ip_vs_INP_peak_5 00005 &lt;NA&gt; &lt;NA&gt; ## X00006.NA PeakAna_clk_Ip_vs_INP_peak_6 00006 &lt;NA&gt; &lt;NA&gt; ## end_position feature_strand insideFeature distancetoFeature ## &lt;integer&gt; &lt;character&gt; &lt;factor&gt; &lt;numeric&gt; ## X00001.NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## X00002.NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## X00003.NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## X00004.NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## X00005.NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## X00006.NA &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## shortestDistance fromOverlappingOrNearest ## &lt;integer&gt; &lt;character&gt; ## X00001.NA &lt;NA&gt; &lt;NA&gt; ## X00002.NA &lt;NA&gt; &lt;NA&gt; ## X00003.NA &lt;NA&gt; &lt;NA&gt; ## X00004.NA &lt;NA&gt; &lt;NA&gt; ## X00005.NA &lt;NA&gt; &lt;NA&gt; ## X00006.NA &lt;NA&gt; &lt;NA&gt; ## ------- ## seqinfo: 32 sequences from an unspecified genome; no seqlengths Here we see that the peaks have a lot of NAs so we did something wrong. If we compare the ge object and the annotated peaks object we can see the problem. as.data.frame(head(ge)) as.data.frame(head(annotatedPeak)) ## seqnames start end width strand tx_name gene_id ## FBgn0000003 3R 6822498 6822796 299 + FBtr0081624 FBgn0000003 ## FBgn0000008 2R 22136968 22172834 35867 + FBtr0071.... FBgn0000008 ## FBgn0000014 3R 16807214 16830049 22836 - FBtr0306.... FBgn0000014 ## FBgn0000015 3R 16927212 16972236 45025 - FBtr0415.... FBgn0000015 ## FBgn0000017 3L 16615866 16647882 32017 - FBtr0112.... FBgn0000017 ## FBgn0000018 2L 10973443 10975293 1851 - FBtr0080168 FBgn0000018 ## tx_type ## FBgn0000003 transcript ## FBgn0000008 transcript ## FBgn0000014 transcript ## FBgn0000015 transcript ## FBgn0000017 transcript ## FBgn0000018 transcript ## seqnames start end width strand length abs_summit pileup ## X00001.NA chr2L 34224 34348 125 * 125 34306 20.88 ## X00002.NA chr2L 34965 35180 216 * 216 35108 23.26 ## X00003.NA chr2L 40369 40577 209 * 209 40492 30.42 ## X00004.NA chr2L 57282 57429 148 * 148 57365 22.07 ## X00005.NA chr2L 58368 58696 329 * 329 58541 39.37 ## X00006.NA chr2L 62014 62139 126 * 126 62048 19.68 ## X.log10.pvalue. fold_enrichment X.log10.qvalue. ## X00001.NA 2.75497 1.97319 1.12350 ## X00002.NA 3.33362 2.02190 1.65302 ## X00003.NA 7.01721 2.83398 5.05903 ## X00004.NA 3.47781 2.08079 1.77350 ## X00005.NA 12.02019 3.64098 9.82848 ## X00006.NA 2.42109 1.86559 0.83175 ## name peak feature start_position ## X00001.NA PeakAna_clk_Ip_vs_INP_peak_1 00001 &lt;NA&gt; NA ## X00002.NA PeakAna_clk_Ip_vs_INP_peak_2 00002 &lt;NA&gt; NA ## X00003.NA PeakAna_clk_Ip_vs_INP_peak_3 00003 &lt;NA&gt; NA ## X00004.NA PeakAna_clk_Ip_vs_INP_peak_4 00004 &lt;NA&gt; NA ## X00005.NA PeakAna_clk_Ip_vs_INP_peak_5 00005 &lt;NA&gt; NA ## X00006.NA PeakAna_clk_Ip_vs_INP_peak_6 00006 &lt;NA&gt; NA ## end_position feature_strand insideFeature distancetoFeature ## X00001.NA NA &lt;NA&gt; &lt;NA&gt; NA ## X00002.NA NA &lt;NA&gt; &lt;NA&gt; NA ## X00003.NA NA &lt;NA&gt; &lt;NA&gt; NA ## X00004.NA NA &lt;NA&gt; &lt;NA&gt; NA ## X00005.NA NA &lt;NA&gt; &lt;NA&gt; NA ## X00006.NA NA &lt;NA&gt; &lt;NA&gt; NA ## shortestDistance fromOverlappingOrNearest ## X00001.NA NA &lt;NA&gt; ## X00002.NA NA &lt;NA&gt; ## X00003.NA NA &lt;NA&gt; ## X00004.NA NA &lt;NA&gt; ## X00005.NA NA &lt;NA&gt; ## X00006.NA NA &lt;NA&gt; 5.9 Extra: Detailed explanation of the MACS output files NAME_peaks.xls is a tabular file which contains information about called peaks. You can open it in excel and sort/filter using excel functions. Information include: chromosome name start position of peak end position of peak length of peak region absolute peak summit position pileup height at peak summit, -log10(pvalue) for the peak summit (e.g. pvalue =1e-10, then this value should be 10) fold enrichment for this peak summit against random Poisson distribution with local lambda, -log10(qvalue) at peak summit Coordinates in XLS is 1-based which is different with BED format. NAME_peaks.narrowPeak is BED6+4 format file which contains the peak locations together with peak summit, pvalue and qvalue. You can load it to UCSC genome browser. Definition of some specific columns are: 5th: integer score for display calculated as int(-10*log10qvalue). Please note that currently this value might be out of the [0-1000] range defined in UCSC Encode narrowPeak [format](https://genome.ucsc.edu/FAQ/FAQformat.html##format12) 7th: fold-change 8th: -log10pvalue 9th: -log10qvalue 10th: relative summit position to peak start The file can be loaded directly to UCSC genome browser. Remove the beginning track line if you want to analyze it by other tools. NAME_summits.bed is in BED format, which contains the peak summits locations for every peaks. The 5th column in this file is -log10pvalue the same as NAME_peaks.bed. If you want to find the motifs at the binding sites, this file is recommended. The file can be loaded directly to UCSC genome browser. Remove the beginning track line if you want to analyze it by other tools. NAME_peaks.broadPeak is in BED6+3 format which is similar to narrowPeak file, except for missing the 10th column for annotating peak summits. NAME_peaks.gappedPeak is in BED12+3 format which contains both the broad region and narrow peaks. The 5th column is 10-log10qvalue, to be more compatible to show grey levels on UCSC browser. Tht 7th is the start of the first narrow peak in the region, and the 8th column is the end. The 9th column should be RGB color key, however, we keep 0 here to use the default color, so change it if you want. The 10th column tells how many blocks including the starting 1bp and ending 1bp of broad regions. The 11th column shows the length of each blocks, and 12th for the starts of each blocks. 13th: fold-change, 14th: -log10pvalue, 15th: -log10qvalue. The file can be loaded directly to UCSC genome browser. NAME_model.r is an R script which you can use to produce a PDF image about the model based on your data. Load it to R by: $ Rscript NAME_model.r Then a pdf file NAME_model.pdf will be generated in your current directory. Note, R is required to draw this figure. The .bdg files are in bedGraph format which can be imported to UCSC genome browser or be converted into even smaller bigWig files. There are two kinds of bdg files: treat_pileup, and control_lambda. 5.10 Activity Slect one gene of interest and find the enrichment score. Load the aligned data in IGV and look at the peaks. Data is available in the book repository. Do the same analysis in, Cyc, the other protein of interest in the paper. Data is available in the book repository. 5.11 Resources and Bibliography Dubowy C, Sehgal A. Circadian Rhythms and Sleep in Drosophila melanogaster. Genetics. 2017;205(4):1373-1397. doi:10.1534/genetics.115.185157 MEIRELES-FILHO, Antonio Carlos Alves and KYRIACOU, Charalambos Panayiotis. Circadian rhythms in insect disease vectors. Mem. Inst. Oswaldo Cruz [online]. 2013, vol.108, suppl.1 [cited 2020-07-08], pp.48-58. A.C.A. Meireles-Filho, A.F. Bardet, J.O. Yáñez-Cuna, G. Stampfel, A. Stark cis-regulatory requirements for tissue-specific programs of the circadian clock Curr Biol, 24 (2014), pp. 1-10 Zhang, Y., Liu, T., Meyer, C.A. et al. Model-based Analysis of ChIP-Seq (MACS). Genome Biol 9, R137 (2008). https://doi.org/10.1186/gb-2008-9-9-r137 Feng, J., Liu, T., Qin, B. et al. Identifying ChIP-seq enrichment using MACS. Nat Protoc 7, 1728–1740 (2012). https://doi.org/10.1038/nprot.2012.101 https://bioconductor.org/packages/release/bioc/vignettes/ChIPseeker/inst/doc/ChIPseeker.html https://www.bioconductor.org/packages/release/bioc/vignettes/ChIPpeakAnno/inst/doc/pipeline.html 5.12 Session info: all the packages installed. This is useful when we want to de-bug a code or share a code or a problem with someone. toLatex(sessionInfo()) ## \\begin{itemize}\\raggedright ## \\item R version 3.6.2 (2019-12-12), \\verb|x86_64-apple-darwin15.6.0| ## \\item Locale: \\verb|en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8| ## \\item Running under: \\verb|macOS Mojave 10.14.6| ## \\item Random number generation: \\item RNG: \\verb|Mersenne-Twister| \\item Normal: \\verb|Inversion| \\item Sample: \\verb|Rounding| ## \\item Matrix products: default ## \\item BLAS: \\verb|/Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib| ## \\item LAPACK: \\verb|/Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib| ## \\item Base packages: base, datasets, graphics, grDevices, grid, ## methods, parallel, stats, stats4, utils ## \\item Other packages: AnnotationDbi~1.48.0, BCRANK~1.48.0, ## Biobase~2.46.0, BiocGenerics~0.32.0, Biostrings~2.54.0, ## ChIPpeakAnno~3.20.1, ChIPseeker~1.22.1, devtools~2.3.1, ## dplyr~1.0.2, forcats~0.5.0, futile.logger~1.4.3, ## GenomeInfoDb~1.22.1, GenomicFeatures~1.38.2, GenomicRanges~1.38.0, ## ggplot2~3.3.2, ggseqlogo~0.1, gridExtra~2.3, IRanges~2.20.2, ## org.Dm.eg.db~3.10.0, purrr~0.3.4, readr~1.3.1, Rsamtools~2.2.3, ## S4Vectors~0.24.4, seqLogo~1.52.0, stringr~1.4.0, tibble~3.0.3, ## tidyr~1.1.2, tidyverse~1.3.0, usethis~1.6.1, VennDiagram~1.6.20, ## webex~0.9.1, XVector~0.26.0 ## \\item Loaded via a namespace (and not attached): ade4~1.7-15, ## AnnotationFilter~1.10.0, askpass~1.1, assertthat~0.2.1, ## backports~1.1.9, BiocFileCache~1.10.2, BiocManager~1.30.10, ## BiocParallel~1.20.1, biomaRt~2.42.1, bit~4.0.4, bit64~4.0.5, ## bitops~1.0-6, blob~1.2.1, bookdown~0.20, boot~1.3-25, broom~0.7.0, ## BSgenome~1.54.0, callr~3.4.3, caTools~1.18.0, cellranger~1.1.0, ## cli~2.0.2, colorspace~1.4-1, compiler~3.6.2, cowplot~1.0.0, ## crayon~1.3.4, curl~4.3, data.table~1.13.0, DBI~1.1.0, dbplyr~1.4.4, ## DelayedArray~0.12.3, desc~1.2.0, digest~0.6.25, DO.db~2.9, ## DOSE~3.12.0, ellipsis~0.3.1, enrichplot~1.6.1, ensembldb~2.10.2, ## europepmc~0.4, evaluate~0.14, fansi~0.4.1, farver~2.0.3, ## fastmatch~1.1-0, fgsea~1.12.0, formatR~1.7, fs~1.5.0, ## futile.options~1.0.1, gdata~2.18.0, generics~0.0.2, ## GenomeInfoDbData~1.2.2, GenomicAlignments~1.22.1, ggforce~0.3.2, ## ggplotify~0.0.5, ggraph~2.0.3, ggrepel~0.8.2, ggridges~0.5.2, ## glue~1.4.2, GO.db~3.10.0, GOSemSim~2.12.1, gplots~3.0.4, ## graph~1.64.0, graphlayouts~0.7.0, gridGraphics~0.5-0, gtable~0.3.0, ## gtools~3.8.2, haven~2.3.1, highr~0.8, hms~0.5.3, htmltools~0.5.0, ## httr~1.4.2, idr~1.2, igraph~1.2.5, jsonlite~1.7.0, ## KernSmooth~2.23-17, knitr~1.29, labeling~0.3, lambda.r~1.2.4, ## lattice~0.20-41, lazyeval~0.2.2, lifecycle~0.2.0, limma~3.42.2, ## lubridate~1.7.9, magrittr~1.5, MASS~7.3-52, Matrix~1.2-18, ## matrixStats~0.56.0, memoise~1.1.0, modelr~0.1.8, multtest~2.42.0, ## munsell~0.5.0, openssl~1.4.2, pillar~1.4.6, pkgbuild~1.1.0, ## pkgconfig~2.0.3, pkgload~1.1.0, plotrix~3.7-8, plyr~1.8.6, ## polyclip~1.10-0, prettyunits~1.1.1, processx~3.4.3, progress~1.2.2, ## ProtGenerics~1.18.0, ps~1.3.4, qvalue~2.18.0, R6~2.4.1, ## rappdirs~0.3.1, RBGL~1.62.1, RColorBrewer~1.1-2, Rcpp~1.0.5, ## RCurl~1.98-1.2, readxl~1.3.1.9000, regioneR~1.18.1, remotes~2.2.0, ## reprex~0.3.0, reshape2~1.4.4, rlang~0.4.7, rmarkdown~2.3, ## rprojroot~1.3-2, RSQLite~2.2.0, rstudioapi~0.11, ## rtracklayer~1.46.0, rvcheck~0.1.8, rvest~0.3.6, scales~1.1.1, ## seqinr~3.6-1, sessioninfo~1.1.1, splines~3.6.2, stringi~1.4.6, ## SummarizedExperiment~1.16.1, survival~3.2-3, testthat~2.3.2, ## tidygraph~1.2.0, tidyselect~1.1.0, tools~3.6.2, triebeard~0.3.0, ## tweenr~1.0.1, TxDb.Hsapiens.UCSC.hg19.knownGene~3.2.2, ## urltools~1.7.3, vctrs~0.3.4, viridis~0.5.1, viridisLite~0.3.0, ## withr~2.2.0, xfun~0.16, XML~3.99-0.3, xml2~1.3.2, yaml~2.2.1, ## zlibbioc~1.32.0 ## \\end{itemize} "],
["rna-seq-analysis.html", "Lab 6 RNA-seq analysis 6.1 Objectives 6.2 Introduction 6.3 Differential gene expression 6.4 Gene Ontology (GO) term analysis 6.5 Extra: negative binomial model 6.6 Activity 6.7 Resources and Bibliography", " Lab 6 RNA-seq analysis 6.1 Objectives After this section you should be able to: Understand RNA sequencing counts. Perform distance matrix and PCA. Do differential gene expression using DeSeq2. 6.2 Introduction We will re-analyze some data from Abruzzi et al, 2017. These are data that explore gene expression in different neuronal cell types in a circadian layout. This time we will just take the process data from the paper, and no directly the Raw data like in the previous chapter (Chip-seq). The data was downloaded from GEO. The only pre-processing to the data was done to change column names. As you can see in the methods section of the paper they have different cell-types and timepoints. Let’s try to understand what type of system and data we have in hands. Circadian behavior Most living organisms change their behavior and metabolism over the day. Some animals like us have more activity over the day while others like mice have more activity over night. Flies in particular have a peak of activity the first hours of the morning and the last hours of the afternoon with a “siesta” (nap in Spanish) at the middle of the day. Figure 4.1: Fly activity over the day. Adapted from Nicholas R. J Glossop et al 2011. To meassure fly activity each individual fly is monitored either by counting when they cross a red-light bim (regular activity monitors) of by software tracking (flyboxes). These changes in behavior are govern by changes in gene expression in particular cell-types in the brain called the pace-makers. If we look at gene expression in these cells over the day we will notice that some genes oscillate. Like Clk and tim, the proteins we analyzed in the previous Lab. In the circadian field time is reported as “hours after the light is ON”. This is zeitgeber time (ZT) and it is useful to have a unified measurement of time. Most animals in labs are kept in 12 hours of light followed by 12 hours of dark. Therefore, ZT0 is the “sunrise” or lights on and ZT12 is lights off in a light/dark (LD)12:12 cycle time. Figure 4.2: Fly activity over the day with ZT scale. Figure adapted from Dubowy et al 2017 As stated before, circadian behaviors is generated by a small subset of neurons. Figure 4.3: Schematic representation of the circadian neural network. Four small ventrolateral neurons (s‐LNvs, red), the 5th s‐LNv (dark violet), four large ventrolateral neurons (l‐LNvs, brown), six dorsolateral neurons (LNds, orange), three lateral posterior neurons (LPN, green), and ca. 60 neurons per hemisphere in three dorsal groups (DN1–3, lilac, cyan, blue, respectively). Adapted from Schubert et al 2018 In the data analyzed in this lab, the authors collected RNA samples over 6 times of the day (ZT3, 7, 11, 15, 19, 23) from 4 cell-types: LNv, LNd, DN1 and Dopaminergic neurons (TH cells). This last group of cells are not part of the circadian core clock but in this study they see oscillating genes! Packages: We will use the following packages. Do not forget to executing them every time you open a new R session. Before running them for the first time, you will have to install them (go back to Lab1 if you have any doubt). library(DESeq2) #for differential expression analysis library(ggplot2) #for 2D graph library(ggrepel) #to get the names in ggplot graph library(gridExtra) #to arrange the plots library(factoextra) #extra plots library(plotly) #for 3D graphics library(plyr) #table manipulation library(dplyr)#table manipulation library(tidyr)#table manipulation library(&quot;RColorBrewer&quot;) #extra color palettes library(&quot;pheatmap&quot;) #nice heatmaps library(org.Dm.eg.db) #get annotation library(MetaCycle) # to identify cycling genes, the successor of JTK according to JTK authors library(pcaExplorer) #more PCA analysis 6.3 Differential gene expression Gene expression data is made of integer numbers by genes. Each number represents exactly how many reads aligned to the DNA sequence that is assigned to each gene. Gene counts table Gene Condition 1 replicate 1 Condition 1 replicate 2 Condition 2 replicate 1 Condition 2 replicate 2 A 20 400 60 40 B 2 50 2000 2500 C 0 5 0 0 D 5 2050 150 144 Ultimately, what we want to do is to compare gene expression between conditions. To do so we have to make some considerations. One is the fact that we want to make conclusions about the whole transcriptome of the organism we are working with. This means around 12000 comparisons (assuming 12000 genes). This implies a huge multiple-comparison correction. Another important consideration is the difference in sequencing depth, to overcame this issue the reads are normalized using an estimate that includes the total amount of reads in that sample. Finally, genes that are too lowly expressed or have a huge dispersion have to be removed from the analysis as they are too noisy to get a trustable conclusion from them. To perform differential gene expression, we have to build a model that explains the differences in gene expression using the condition we are testing, fit the data to that model and see if it can explain the differences. This is done using generalized linear models (GLM) modeled using a negative binomial distribution (NB). Why is this? Because the data are counts, ie. integers (there are not 12.5 reads, you either have 12 or 13), to model discrete counts, we use either poison or NB distribution. NB is used because it allows for expression and variance to be unlinked. Luckily for us, there are many packages dedicated to solve this problem. We will use DeSeq2 The steps performed by the DESeq function are documented in the manual page of DESeq2; briefly, they are: 1 estimation of size factors by estimateSizeFactors (this is for normalization) 2 estimation of dispersion by estimateDispersions (calculate the gene expression dispersion) 3 negative binomial GLM fitting and Wald statistics by nbinomWaldTest (this is the actual differential gene expression step) The only requirement for Deseq2 is to have the tables of data in a proper format and a meta-data object that indicates what is each sample. Imagine we have a wildtype and a mutant, DeSeq2 requires Table: 1: Data matrix with Gene name as ROWNAMES 2: MetaData (colData) in which ROWNAMES are the COLNAMES of the Data matrix and the conditions are column names Row Names WildType.1 WildType.2 Mutant.1 Mutant.2 geneA 20 400 60 40 geneB 2 50 2000 2500 geneC 0 5 0 0 geneD 5 2050 150 144 Row Names Genotype replicate WildType.1 WT 1 WildType.2 WT 2 Mutant.1 actinKD 1 Mutant.2 actinKD 2 The we can use the Genotype as a condition to compare gene expression for example. At this time, we will start by comparing gene expression at two timepoints in one cell-type. This is good to have a first impression of the data but it is not the way to go if your idea is to analyze circadian cycling behavior. 6.3.1 Loading the tables This time we have 4 gene expression tables: one for each cell type we are analyzing. Therefore, some of the processing will be done using for loops. This might be confusing at the beginning but is a really useful tool. #We can list the files that are present in our working directory, or any path we specify. Remember the path will change depending where you have your data. list.files(path = &quot;../RNAseq/&quot;) list.files(path = &quot;../RNAseq/&quot;,pattern = &quot;expression&quot;) #what do you think patter is doing? remember to go to the help page if you need to. list.files(path = &quot;../RNAseq/&quot;,pattern = &quot;expression&quot;,full.names = T) #what happened now? paper_tables&lt;-list.files(path = &quot;../RNAseq/&quot;,pattern = &quot;xpression&quot;,full.names = T) #what we are doing here?, check your environment, do you see something new? #If we try with one TH_gene_expression&lt;-read.table(&quot;../RNAseq/TH_gene_expression.txt&quot;,header = T) ## [1] &quot;all_tables.rdata&quot; &quot;circadianact.png&quot; ## [3] &quot;circadianbrain.png&quot; &quot;circadiancells.png&quot; ## [5] &quot;cycDN1_reults.txt&quot; &quot;cycDN1.csv&quot; ## [7] &quot;cycwithzt.png&quot; &quot;DN1_gene_expression.txt&quot; ## [9] &quot;F1.large.jpg&quot; &quot;howcircadian.png&quot; ## [11] &quot;LNd_gene_expression.txt&quot; &quot;LNv_gene_expression.txt&quot; ## [13] &quot;RNASeq_DeSeq2.html&quot; &quot;RNASeq_DeSeq2.rmd&quot; ## [15] &quot;RNAseqDataPrep.html&quot; &quot;TableMod.rmd&quot; ## [17] &quot;TH_gene_expression.txt&quot; ## [1] &quot;DN1_gene_expression.txt&quot; &quot;LNd_gene_expression.txt&quot; ## [3] &quot;LNv_gene_expression.txt&quot; &quot;TH_gene_expression.txt&quot; ## [1] &quot;../RNAseq//DN1_gene_expression.txt&quot; &quot;../RNAseq//LNd_gene_expression.txt&quot; ## [3] &quot;../RNAseq//LNv_gene_expression.txt&quot; &quot;../RNAseq//TH_gene_expression.txt&quot; How can we make it work for all the tables? We want to change the name, we basically want to remove the “.txt” ending. That can be done using gsub. We want to remove “.txt”, so we replace it for an empty string. gsub(x = &quot;../RNAseq/TH_gene_expression.txt&quot;,pattern =&quot;.txt&quot;, replacement = &quot;&quot;) ## [1] &quot;../RNAseq/TH_gene_expression&quot; #We also need to remove the path file gsub(x = &quot;../RNAseq/TH_gene_expression.txt&quot;,pattern =&quot;../RNAseq/&quot;, replacement = &quot;&quot;) ## [1] &quot;TH_gene_expression.txt&quot; Now we can try to do it for all of them, just trying to see if changing the names is working but NOT applying it to anything until we know it works. for (e in (paper_tables)){ print(&quot;original name: &quot;) print(e) # this is printing e n&lt;-gsub(pattern =&quot;.txt&quot;, replacement = &quot;&quot;,x = e) n&lt;-gsub(pattern =&quot;../RNAseq//&quot;, replacement = &quot;&quot;,x = n) print(&quot;final name: &quot;) print(n) } ## [1] &quot;original name: &quot; ## [1] &quot;../RNAseq//DN1_gene_expression.txt&quot; ## [1] &quot;final name: &quot; ## [1] &quot;DN1_gene_expression&quot; ## [1] &quot;original name: &quot; ## [1] &quot;../RNAseq//LNd_gene_expression.txt&quot; ## [1] &quot;final name: &quot; ## [1] &quot;LNd_gene_expression&quot; ## [1] &quot;original name: &quot; ## [1] &quot;../RNAseq//LNv_gene_expression.txt&quot; ## [1] &quot;final name: &quot; ## [1] &quot;LNv_gene_expression&quot; ## [1] &quot;original name: &quot; ## [1] &quot;../RNAseq//TH_gene_expression.txt&quot; ## [1] &quot;final name: &quot; ## [1] &quot;TH_gene_expression&quot; What is this for loop doing? Do you think it is working? Why? Now we will read the tables and put them in the names we created. To do this we will use the function assign, that actually assign anything to a given name. The name is stored in “n”. What we want to assign is the “read.delim” of the file name stored in e. for (e in (paper_tables)){ n&lt;-gsub(pattern =&quot;.txt&quot;, replacement = &quot;&quot;,x = e) n&lt;-gsub(pattern =&quot;../RNAseq//&quot;, replacement = &quot;&quot;,x = n) print(paste0(&quot;I am reading: &quot;,n)) assign(n,read.delim(e)) } ## [1] &quot;I am reading: DN1_gene_expression&quot; ## [1] &quot;I am reading: LNd_gene_expression&quot; ## [1] &quot;I am reading: LNv_gene_expression&quot; ## [1] &quot;I am reading: TH_gene_expression&quot; 6.3.2 Create the DeSeq2 count matrix DeSeq2 expects to have a data.frame with the gene-names as row.names and then just the counts. I will first show it for one of the tables and then do a for loop to do it for all of them. #We do not want to overwrite the raw tables. So, we will create new objects with the same data and we will modify these new objects and preserve the original data. Is like doing &quot;save as&quot; in word. ds2_DN1_gene_expression_try&lt;-DN1_gene_expression #what is this doing? #We do now the loop for all of them to create the `ds2_` objects ls(pattern = &quot;gene_expression&quot;) #this list the objects in the environment that has the selected pattern in its name ## [1] &quot;DN1_gene_expression&quot; &quot;ds2_DN1_gene_expression_try&quot; ## [3] &quot;LNd_gene_expression&quot; &quot;LNv_gene_expression&quot; ## [5] &quot;TH_gene_expression&quot; #The new name we want is just adding &quot;ds2_&quot; to the beginning of the object name. We can do this with the paste0 function. paste0(&quot;ds2_&quot;,&quot;DN1_gene_expression&quot;) for (e in ls(pattern = &quot;gene_expression&quot;)){ x = paste0(&quot;ds2&quot;, sep=&quot;_&quot;,e) #this is the new name print(&quot;new name is:&quot;) print(x) assign(x, get(e)) #get is a function that extracts the data from an object name } ## [1] &quot;ds2_DN1_gene_expression&quot; ## [1] &quot;new name is:&quot; ## [1] &quot;ds2_DN1_gene_expression&quot; ## [1] &quot;new name is:&quot; ## [1] &quot;ds2_ds2_DN1_gene_expression_try&quot; ## [1] &quot;new name is:&quot; ## [1] &quot;ds2_LNd_gene_expression&quot; ## [1] &quot;new name is:&quot; ## [1] &quot;ds2_LNv_gene_expression&quot; ## [1] &quot;new name is:&quot; ## [1] &quot;ds2_TH_gene_expression&quot; Now we have to do some manipulation in the tables for them to work with Deseq2. ds2_DN1_gene_expression_try &lt;- ds2_DN1_gene_expression row.names(ds2_DN1_gene_expression_try) = ds2_DN1_gene_expression$Symbol # we put the symbols as row.names ds2_DN1_gene_expression_try&lt;-ds2_DN1_gene_expression_try[,-1] # we take the symbols column out head(ds2_DN1_gene_expression_try) # we can see that now the table is what we need rm(ds2_DN1_gene_expression_try) #remove it because you do not need it anymore and because it can create problems ## DN1_ZT3_1 DN1_ZT7_1 DN1_ZT11_1 DN1_ZT15_1 DN1_ZT19_1 DN1_ZT23_1 ## FBtr0070202 0 0 0 0 0 0 ## FBtr0070207 0 0 0 0 14 0 ## FBtr0070238 0 0 0 0 21 0 ## FBtr0070251 0 0 0 0 0 0 ## FBtr0070484 0 0 0 0 0 0 ## FBtr0070489 0 0 0 0 0 0 ## DN1_ZT3_2 DN1_ZT7_2 DN1_ZT11_2 DN1_ZT15_2 DN1_ZT19_2 DN1_ZT23_2 ## FBtr0070202 0 0 0 0 0 0 ## FBtr0070207 0 0 0 0 16 7 ## FBtr0070238 0 0 0 0 15 9 ## FBtr0070251 0 0 1 0 2 0 ## FBtr0070484 0 0 0 0 0 1 ## FBtr0070489 0 0 0 0 0 0 We can add this step to the for loop, or even better we can create a function and practice something new in R. #We create a small function to remember sum2&lt;-function(x){ y=x+2 return(y) } sum2(4) ## [1] 6 what is this doing? why? #Now we create a function that takes the data frame and does all the transformation we did before create_ds2= function(df_name){ df = as.data.frame(get(df_name)) row.names(df) = as.character(df[,1]) df=df[,-1] return(df) # this actually tells the function to return the transformed data.frame } #Let&#39;s try the function in one of the ds2 objects #head(create_ds2(ds2_LNd_gene_expression))[,c(1:3)] for (e in ls(pattern = &quot;ds2_&quot;)){ print(e) assign(e,create_ds2(e)) #this should actually run the function and apply it to the data frame } ## [1] &quot;ds2_DN1_gene_expression&quot; ## [1] &quot;ds2_ds2_DN1_gene_expression_try&quot; ## [1] &quot;ds2_LNd_gene_expression&quot; ## [1] &quot;ds2_LNv_gene_expression&quot; ## [1] &quot;ds2_TH_gene_expression&quot; 6.3.3 Meta-data (colData) preparation We now need to have a data.frame with the mapping between the columns and the ZT, the program call this colData. Is what is usually called “meta data”. Is a file that explains what each object/column is. We will do it by hand just changing the names. No more loops for now. After you execute each step I recommend you to inspect the object to see what is happening. DN1 #takes the names in the data frame and put them in the new objects. We want to get the information for each colData.DN1 = as.data.frame(names(ds2_DN1_gene_expression)) #now we put them as row.names rownames(colData.DN1) = colData.DN1[,1] #now we take the columns out colData.DN1 =colData.DN1[,-1] #this is taking the last part of the rownames and put them in a column named `ZT` colData.DN1$ZT = sapply(strsplit(rownames(colData.DN1),&quot;_&quot;),&quot;[[&quot;,2) colData.DN1$rep = sapply(strsplit(rownames(colData.DN1),&quot;_&quot;),&quot;[[&quot;,3) head(colData.DN1) ## ZT rep ## DN1_ZT3_1 ZT3 1 ## DN1_ZT7_1 ZT7 1 ## DN1_ZT11_1 ZT11 1 ## DN1_ZT15_1 ZT15 1 ## DN1_ZT19_1 ZT19 1 ## DN1_ZT23_1 ZT23 1 LNv colData.LNv = as.data.frame(names(ds2_LNv_gene_expression)) #now we put them as row.names rownames(colData.LNv) = colData.LNv[,1] #now we take the columns out colData.LNv =colData.LNv[,-1] #this is taking the last part of the rownames and put them in a column named `ZT` colData.LNv$ZT = sapply(strsplit(rownames(colData.LNv),&quot;_&quot;),&quot;[[&quot;,2) colData.LNv$rep = sapply(strsplit(rownames(colData.LNv),&quot;_&quot;),&quot;[[&quot;,3) LNd colData.LNd = as.data.frame(names(ds2_LNd_gene_expression)) #now we put them as row.names rownames(colData.LNd) = colData.LNd[,1] #now we take the columns out colData.LNd =colData.LNd[,-1] #this is taking the last part of the rownames and put them in a column named `ZT` colData.LNd$ZT = sapply(strsplit(rownames(colData.LNd),&quot;_&quot;),&quot;[[&quot;,2) colData.LNd$rep = sapply(strsplit(rownames(colData.LNd),&quot;_&quot;),&quot;[[&quot;,3) TH colData.TH = as.data.frame(names(ds2_TH_gene_expression)) #now we put them as row.names rownames(colData.TH) = colData.TH[,1] #now we take the columns out and colData.TH =colData.TH[,-1] colData.TH$ZT = sapply(strsplit(rownames(colData.TH),&quot;_&quot;),&quot;[[&quot;,2) colData.TH$rep = sapply(strsplit(rownames(colData.TH),&quot;_&quot;),&quot;[[&quot;,3) 6.3.4 Quality filtering: Distance matrix and principal component analysis (PCA) If we want to evaluate the difference between two conditions we have to make sure that the difference between replicates of the same conditions are smaller. In other words, we expect the replicates of the same condition to be similar to each other. Checking this is a regular procedure in differential gene expression analysis as it helps us to identify samples that might be outliers. To evaluate this, we will use two different approaches. Firstly, we will calculate a distance matrix, this is basically calculating the difference between each sample. To visualize this, we will use a heatmap. Secondly, we will do a principal component analysis (PCA) to get an idea on how similar are the samples between each other. To make it simple (but not completely correct) PCA is a way to reduce the dimensions (in this case many many genes) to a set of vectors (principal components, PC) that summarize the combination of the gene information. Then, if two samples have similar values in this PCs then they are similar to each other. We first have to initiate the DeSeq2 object. This imply telling the package which is the matrix of read counts, the colData (meta data) and the design. The design is what the program uses to do the differential expression. Is simple in this case: only the ZT. Initialize the data #This is actually the main function of the package and prepares everything to run the differential expression analysis. dds.DN1 &lt;- DESeqDataSetFromMatrix(countData = as.matrix(ds2_DN1_gene_expression), colData = colData.DN1,design = ~ ZT) #class of dds.DN1 class(dds.DN1) ## [1] &quot;DESeqDataSet&quot; ## attr(,&quot;package&quot;) ## [1] &quot;DESeq2&quot; Distance Matrix As stated before, a distance matrix is a way to quantify differences. In this case each column of the data matrix will be compared with all the others. You can read more here or here. dist() is the function that calculates the Euclidean distance, you can select which type of distance you want to calculate, read the help page for more information. # Calculate the distance matrix sampleDists &lt;- dist(t(assay(dds.DN1))) # Lets look at this step by step: # assay(dds.DN1) # extract the reads # t(assay(dds.DN1)) #transpose the matrix, this has to do with the fact that we want to calculate the distance between samples, if we do not transpose we will literally calculate the difference between genes across samples #Then we take this in a matrix and create the heatmap sampleDistMatrix &lt;- as.matrix(sampleDists) #convert to matrix rownames(sampleDistMatrix) &lt;- paste(dds.DN1$ZT,dds.DN1$rep,sep=&quot;_rep_&quot;) # put the rownames colnames(sampleDistMatrix) &lt;- NULL colors &lt;- colorRampPalette( rev(brewer.pal(9, &quot;Blues&quot;)) )(255)#select color #Heatmap function pheatmap(sampleDistMatrix, clustering_distance_rows=sampleDists, clustering_distance_cols=sampleDists, annotation_row = rownames(sampleDists), annotation_col = rownames(sampleDists), cutree_rows = 2, cutree_cols = 2, col=colors) Figure 6.1: Heatmap representing distance between samples PCA using DeSeq2 We have to do a logarithmic transformation to see how the data looks like after minimizing differences between samples for rows with small counts, and which normalizes with respect to library size. You can read the help executing ?rlog. rdl.DN1 &lt;- rlog(dds.DN1) Now we can plot the PCA analysis already integrated in the DeSeq2 package. plotPCA(rdl.DN1, intgroup=c(&quot;ZT&quot;)) Figure 6.2: PCA coloring by ZT PCA using basic R We will use the function prcomp() to calculate the PCs. But before we do that we will select the most variable genes across samples. If a gene has the same value across all the samples will not be explicative or informative. rv &lt;- rowVars(assay(rdl.DN1)) # we calcualte the total variation in each gene (in this case rows), rowwVars literally calculates the variance in the rows ntop &lt;- 10000 # we select how many gene we want to use sg &lt;- order(rv, decreasing = TRUE)[seq_len(min(ntop, length(rv)))] # here we select the most variable genes acording to the ntop value we set up before mat &lt;- t(assay(rdl.DN1)[sg, ]) # here we extract then the counts using the function assay from DeSeq2 pc &lt;- prcomp(mat) # calcualte PCs #head(pc,n=3L) To select how many PCs are “important” we will use the percentage of variance explained by each PC. This takes us to the next step of understanding PCA. Each PC might be seen as a vector that explain some part of the variation of the data. Then if a PC explains only 2% of the data it makes no sense to pay attention to if we compared it to other PCs that might explain more. fviz_eig(pc, addlabels = TRUE) Figure 5.3: Variance explained by each PC Now we can plot more than 2 PCs pc_df=as.data.frame(pc$x) #transform to data frame pc_df=merge(pc_df,colData.DN1,by=&quot;row.names&quot;,all=T) # merge with the colData to have the meta data of each saple rownames(pc_df)=pc_df$Row.names p1=ggplot(pc_df, aes(PC1, PC2, color=ZT)) + geom_point(size=3) + theme_minimal() p2=ggplot(pc_df, aes(PC3, PC2, color=ZT)) + geom_point(size=3) + theme_minimal() #and both together grid.arrange(p1,p2, ncol=2) Figure 5.4: Ploting many principal components p1=ggplot(pc_df, aes(PC1, PC2, color=ZT,label=Row.names)) + geom_point(size=3) + geom_label_repel(aes(label = Row.names), box.padding = 0.35, point.padding = 0.5, segment.color = &#39;grey50&#39;) + theme_minimal() p2=ggplot(pc_df, aes(PC3, PC2, color=ZT,label=Row.names)) + geom_point(size=3) + geom_label_repel(aes(label = Row.names), box.padding = 0.35, point.padding = 0.5, segment.color = &#39;grey50&#39;) + theme_minimal() #and both together grid.arrange(p1,p2, ncol=2) Figure 6.3: Ploting many principal components #We can do some fancy 3D plots also, try them! plot_ly(pc_df, x = ~PC1, y = ~PC2, z = ~PC3, color = ~ZT,colorscale = c(&#39;#FFE1A1&#39;, &#39;#683531&#39;)) plot_ly(pc_df, x = ~PC2, y = ~PC3, z = ~PC4, color = ~ZT,colorscale = c(&#39;#FFE1A1&#39;, &#39;#683531&#39;)) 6.3.5 Differential gene expression analysis between ZT. We already saw that for DN1: ZT19 and ZT23 looks more similar between them and also ZT3, 7, 15 and 11. We will now explore particular differences. DESeq is the main function here it acts over the object created previously. It executes the normalization and differential gene expression analysis. Run differentially expression dds.DN1 = DESeq(dds.DN1) ## estimating size factors ## estimating dispersions ## gene-wise dispersion estimates ## mean-dispersion relationship ## final dispersion estimates ## fitting model and testing #The resultNames is taking the names of the comparisons done by the DESeq function resultsNames(dds.DN1) ## [1] &quot;Intercept&quot; &quot;ZT_ZT15_vs_ZT11&quot; &quot;ZT_ZT19_vs_ZT11&quot; &quot;ZT_ZT23_vs_ZT11&quot; ## [5] &quot;ZT_ZT3_vs_ZT11&quot; &quot;ZT_ZT7_vs_ZT11&quot; The results function extract this result, we will compare ZT3 vs ZT15. Use ?results to explore this function further. res.ZT3vsZT15.DN1 &lt;- results( dds.DN1, contrast = c(&quot;ZT&quot;,&quot;ZT3&quot;, &quot;ZT15&quot;),alpha=0.05) head(res.ZT3vsZT15.DN1) ## log2 fold change (MLE): ZT ZT3 vs ZT15 ## Wald test p-value: ZT ZT3 vs ZT15 ## DataFrame with 6 rows and 6 columns ## baseMean log2FoldChange lfcSE stat ## &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; ## FBtr0070202 0 NA NA NA ## FBtr0070207 2.1168359707544 0 5.24448449612991 0 ## FBtr0070238 2.68357323289241 0 4.8861753047644 0 ## FBtr0070251 0.304433817751997 0 5.39799191011387 0 ## FBtr0070484 0.151419583982656 0 5.39799191011387 0 ## FBtr0070489 0 NA NA NA ## pvalue padj ## &lt;numeric&gt; &lt;numeric&gt; ## FBtr0070202 NA NA ## FBtr0070207 1 1 ## FBtr0070238 1 1 ## FBtr0070251 1 NA ## FBtr0070484 1 NA ## FBtr0070489 NA NA What do you think is each column? mcols(res.ZT3vsZT15.DN1)$description ## [1] &quot;mean of normalized counts for all samples&quot; ## [2] &quot;log2 fold change (MLE): ZT ZT3 vs ZT15&quot; ## [3] &quot;standard error: ZT ZT3 vs ZT15&quot; ## [4] &quot;Wald statistic: ZT ZT3 vs ZT15&quot; ## [5] &quot;Wald test p-value: ZT ZT3 vs ZT15&quot; ## [6] &quot;BH adjusted p-values&quot; We can see the distribution of each variable using the function summary summary(res.ZT3vsZT15.DN1) ## ## out of 25337 with nonzero total read count ## adjusted p-value &lt; 0.05 ## LFC &gt; 0 (up) : 79, 0.31% ## LFC &lt; 0 (down) : 55, 0.22% ## outliers [1] : 0, 0% ## low counts [2] : 3419, 13% ## (mean count &lt; 2) ## [1] see &#39;cooksCutoff&#39; argument of ?results ## [2] see &#39;independentFiltering&#39; argument of ?results Identify differentially expressed genes: Multiple comparison correction and adjusted pvalue You might have noticed that apart from pvalues there are adjusted pvalues. Just to recap, when we want to make conclusion we always have some chance to make a mistake. This chance increase with each element we add to out conclusions. Image what happens when we want to make a conclusion about 10.000 genes! We then correct the pvalue. There are different methods, in this case DeSeq2 uses Benjamini-Hochberg adjusted P value. We can now do an histogram to explore how is the distribution of the padj. #histogram hist(res.ZT3vsZT15.DN1$padj, breaks=100, col=&quot;skyblue&quot;, border=&quot;slateblue&quot;, main=&quot;&quot;) Figure 6.4: Histogram of pjusted value distribution Identify differentially expressed genes: Log2(FoldChange) Identify differentially expressed genes is a combination of pvalue and a fold change. Fold change is literally the comparison of 2 conditions. Let’s go back to our example. Row Names WildType.1 WildType.2 Mutant.1 Mutant.2 geneA 230 210 420 412 Here, geneA seems to be around 2 times more in Mutant compared with the WildType. This would be an UPregulated gene. \\[ Mutant/WT=400/200=2 \\] If we imagine the opposite situation, a DOWNregulated gene, the same comparison would give a not-such intuitive result. Row Names WildType.1 WildType.2 Mutant.1 Mutant.2 geneA 430 410 220 212 \\[ Mutant/WT=200/400=0.5 \\] To avoid this, in differential gene expression we use log2. This will give us the following: \\[ UPregulated: log2(Mutant/WT)=log2(400/200)=1 \\] \\[ DOWNregulated: log2(Mutant/WT)=log2(200/400)=-1 \\] To know what is being used as denominator (control) we can look into the DeSeq2 manual: “With no additional arguments to results(), the log2 fold change and Wald test p value will be for the last variable in the design formula, and if this is a factor, the comparison will be the last level of this variable over the reference level.” In our case then ZT15 is being used as reference To see significance is to use MA plots which shows log2 fold changes (on the y-axis) versus the mean of normalized counts (on the x-axis). plotMA(res.ZT3vsZT15.DN1,alpha=0.05) #In red everything with padj &lt; 0.05 Figure 6.5: MA plot: log2 fold changes vs normalized counts 6.3.6 Explore results We can create a data frame of the results and play around. res.ZT3vsZT15.DN1_df&lt;-as.data.frame(res.ZT3vsZT15.DN1) res.ZT3vsZT15.DN1_df=res.ZT3vsZT15.DN1_df[complete.cases(res.ZT3vsZT15.DN1_df),]#remove NAs res.ZT3vsZT15.DN1_df$transcript_name=rownames(res.ZT3vsZT15.DN1_df) head(res.ZT3vsZT15.DN1_df) ## baseMean log2FoldChange lfcSE stat pvalue padj ## FBtr0070207 2.116836 0.0000000 5.2444845 0.000000 1.00000000 1 ## FBtr0070238 2.683573 0.0000000 4.8861753 0.000000 1.00000000 1 ## FBtr0070658 2.762362 0.0000000 5.3979919 0.000000 1.00000000 1 ## FBtr0071170 16.483738 2.1943705 1.1682234 1.878383 0.06032885 1 ## FBtr0071173 4.674766 0.0000000 5.3502754 0.000000 1.00000000 1 ## FBtr0071619 49.515374 -0.8457701 0.6368886 -1.327972 0.18418743 1 ## transcript_name ## FBtr0070207 FBtr0070207 ## FBtr0070238 FBtr0070238 ## FBtr0070658 FBtr0070658 ## FBtr0071170 FBtr0071170 ## FBtr0071173 FBtr0071173 ## FBtr0071619 FBtr0071619 Change the gene names As you can see, the names of the genes are in a nomenclature that is not intuitive. We can then use some functions that will allow us to change the names for some more informative. Let’s take one example: FBtr0070207, is a transcript name (not a gene name, but one of the possible variants of the gene) http://flybase.org/reports/FBtr0070207. We want for this analysis the gene name. For that we will use the package org.Dm.eg.db (each model organism has one of this: https://bioconductor.org/packages/release/BiocViews.html#___AnnotationData) #Explore the options that the package gives us keytypes(org.Dm.eg.db) ## [1] &quot;ACCNUM&quot; &quot;ALIAS&quot; &quot;ENSEMBL&quot; &quot;ENSEMBLPROT&quot; &quot;ENSEMBLTRANS&quot; ## [6] &quot;ENTREZID&quot; &quot;ENZYME&quot; &quot;EVIDENCE&quot; &quot;EVIDENCEALL&quot; &quot;FLYBASE&quot; ## [11] &quot;FLYBASECG&quot; &quot;FLYBASEPROT&quot; &quot;GENENAME&quot; &quot;GO&quot; &quot;GOALL&quot; ## [16] &quot;MAP&quot; &quot;ONTOLOGY&quot; &quot;ONTOLOGYALL&quot; &quot;PATH&quot; &quot;PMID&quot; ## [21] &quot;REFSEQ&quot; &quot;SYMBOL&quot; &quot;UNIGENE&quot; &quot;UNIPROT&quot; #We have here the ENSEMBLE transcript names, so we will use that keytype genenames &lt;- mapIds(org.Dm.eg.db,keys = rownames(dds.DN1),column = &quot;SYMBOL&quot;,keytype=&quot;ENSEMBLTRANS&quot;) annotation_DN1 &lt;- data.frame(gene_name = genenames, transcript_name=rownames(dds.DN1), row.names = rownames(dds.DN1), stringsAsFactors = FALSE) head(annotation_DN1) ## gene_name transcript_name ## FBtr0070202 CG14625 FBtr0070202 ## FBtr0070207 fs(1)N FBtr0070207 ## FBtr0070238 CG11409 FBtr0070238 ## FBtr0070251 CG11384 FBtr0070251 ## FBtr0070484 fs(1)Yb FBtr0070484 ## FBtr0070489 CG12498 FBtr0070489 Now that we have a “mapping” we can use it. We will use the function merge. res.ZT3vsZT15.DN1_df=merge(res.ZT3vsZT15.DN1_df,annotation_DN1,by=&quot;transcript_name&quot;) head(res.ZT3vsZT15.DN1_df) ## transcript_name baseMean log2FoldChange lfcSE stat pvalue padj ## 1 FBtr0005088 404.52656 -0.3962867 0.4939109 -0.8023445 0.4223537 1 ## 2 FBtr0005673 2.35263 1.7199349 2.8262384 0.6085598 0.5428163 1 ## 3 FBtr0005674 2.35263 1.7199349 2.8262384 0.6085598 0.5428163 1 ## 4 FBtr0070000 44.02153 -0.7589507 1.1324434 -0.6701886 0.5027375 1 ## 5 FBtr0070002 4.30420 3.7116759 2.5555706 1.4523863 0.1463942 1 ## 6 FBtr0070006 23.06487 -1.1075368 1.0502903 -1.0545054 0.2916516 1 ## gene_name ## 1 Pp2A-29B ## 2 &lt;NA&gt; ## 3 &lt;NA&gt; ## 4 Nep3 ## 5 CG9570 ## 6 CG9572 UP regulated genes Now let’s look for the genes that are changing with than Log2foldChange &gt; 1 (which is a fold change of 2) sig_down=unique(res.ZT3vsZT15.DN1_df$gene_name[(res.ZT3vsZT15.DN1_df$padj&lt;0.05&amp;res.ZT3vsZT15.DN1_df$log2FoldChange&lt;(-1))]) head(sig_down) ## [1] NA &quot;CG14089&quot; &quot;CG13041&quot; &quot;CG32137&quot; &quot;Pdp1&quot; &quot;tim&quot; DOWN regualted genes Now let’s look for the genes that are changing with than Log2foldChange &lt; -1 (which is a fold change of 0.5, so a downregulation of 2 times) sig_up=unique(res.ZT3vsZT15.DN1_df$gene_name[(res.ZT3vsZT15.DN1_df$padj&lt;0.05&amp;res.ZT3vsZT15.DN1_df$log2FoldChange&gt;1)]) head(sig_down) ## [1] NA &quot;CG14089&quot; &quot;CG13041&quot; &quot;CG32137&quot; &quot;Pdp1&quot; &quot;tim&quot; Plot genes Let’s plot some genes using DeSeq2. plotCounts(dds.DN1, gene=which.min(res.ZT3vsZT15.DN1$padj), intgroup=&quot;ZT&quot;) Figure 6.6: Plot gene expression. plotCounts(dds.DN1, gene=&quot;FBtr0077567&quot;, intgroup=&quot;ZT&quot;) Figure 6.7: Plot gene expression. We can do this in ggplot2 d &lt;- plotCounts(dds.DN1, gene=&quot;FBtr0077567&quot;, intgroup=&quot;ZT&quot;, returnData=TRUE) #extract eh data from the plot ggplot(d, aes(x=ZT, y=count)) + geom_point(position=position_jitter(w=0.1,h=0)) #use it to plot in a better way Figure 3.11: Plot gene expression using ggplot. Let’s discuss what we see in the graphics. We have some of the figures that seems to have the exactly same values for each replicate. This is at least suspicious. This might be just the same quantification so it might not be correct to say that they are different isoforms and maybe it is better to collapse them or change the strategy to analyze different isoforms. This also shows us the limitations we have when we use the data already aligned. 6.3.7 Plot counts using ggplot Let’s see how we can plot the transcript reads in a better way. Doing a few manipulations on the table we can have even better plots. #big plot #I take the normalized values and do the plots toplot&lt;-as.data.frame(as.data.frame(counts(dds.DN1, normalized=T))) toplot$transcript_name&lt;-rownames(toplot) toplot&lt;-toplot %&gt;% gather(zt_rep, value, -transcript_name) #This is a more complex line of code, let’s explore the results. head(toplot) ## transcript_name zt_rep value ## 1 FBtr0070202 DN1_ZT3_1 0 ## 2 FBtr0070207 DN1_ZT3_1 0 ## 3 FBtr0070238 DN1_ZT3_1 0 ## 4 FBtr0070251 DN1_ZT3_1 0 ## 5 FBtr0070484 DN1_ZT3_1 0 ## 6 FBtr0070489 DN1_ZT3_1 0 toplot=merge(toplot,annotation_DN1,by=&quot;transcript_name&quot;) head(toplot) ## transcript_name zt_rep value gene_name ## 1 FBtr0005088 DN1_ZT11_2 333.0941 Pp2A-29B ## 2 FBtr0005088 DN1_ZT19_2 332.2765 Pp2A-29B ## 3 FBtr0005088 DN1_ZT7_2 520.4211 Pp2A-29B ## 4 FBtr0005088 DN1_ZT3_2 235.0216 Pp2A-29B ## 5 FBtr0005088 DN1_ZT23_2 392.4796 Pp2A-29B ## 6 FBtr0005088 DN1_ZT19_1 406.2523 Pp2A-29B What changed here? How this allow for better plotting? #Lets create now more meta data toplot$zt&lt;-sapply(strsplit(as.character(toplot$zt_rep),&quot;_&quot;),&quot;[[&quot;,2) toplot$ztime&lt;-gsub(toplot$zt,pattern = &quot;ZT&quot;,replacement = &quot;&quot;) toplot$rep&lt;-sapply(strsplit(as.character(toplot$zt_rep),&quot;_&quot;),&quot;[[&quot;,3) toplot$ztime_2&lt;-as.numeric(toplot$ztime) toplot$ztime_2[toplot$rep==&quot;2&quot;]&lt;-toplot$ztime_2[toplot$rep==&quot;2&quot;]+24 #And plot genes.cyc = c(&quot;tim&quot;,&quot;Clk&quot;,&quot;per&quot;,&quot;cwo&quot;) #you can put here as many genes as you want ggplot(toplot[toplot$gene_name %in% genes.cyc ,],aes(x = as.numeric(ztime),y = value,color=gene_name,shape=rep)) + geom_point() + geom_line() Figure 6.8: Count plots with ggplot ggplot(toplot[toplot$gene_name %in% genes.cyc ,],aes(x =ztime_2,y = value,color=gene_name,shape=rep)) + geom_point() + geom_line() Figure 6.9: Count plots with ggplot using zt time ggplot(toplot[toplot$gene_name %in% genes.cyc ,],aes(x =ztime_2,y = value,color=gene_name,shape=rep)) + geom_point() + geom_line() + facet_wrap(scales = &quot;free&quot;,facets = ~gene_name ) Figure 3.16: Count plots with ggplot sepparating by gene name 6.4 Gene Ontology (GO) term analysis The main objective of GO term analysis is to identify common features in a list of gene shared feature that might be “enriched” when compared with the background list of of genes. There are 3 GO term sets: Molecular Function(MF): Molecular function or activities performed by gene product. Examples can be for example catalysis or transport. Biological Process(BP): The larger processes, or ‘biological programs’ that these genes takes part in. Examples can be DNA repair or signal transduction. Cellular Component(CC): The locations relative to cellular structures in which a gene product performs a function, either cellular compartments. For this we use the known information about each gene. Lets see one example: Gad1. From FlyBase: “Glutamic acid decarboxylase 1 (Gad1) encodes an essential, nervous system-specific glutamic acid decarboxylase, which is the synthetic enzyme for the major inhibitory neurotransmitter gamma-Aminobutyric acid (GABA). It is required for a multitude of physiological functions and adult behaviors dependent on GABA, including sleep, memory, circadian rhythms and egg hatching.” Then, MF GO term are glutamate decarboxylase activity, glutamate decarboxylase activity, pyridoxal phosphate binding. BP: gamma-aminobutyric acid biosynthetic process,glutamate catabolic process,larval locomotor behavior,neuromuscular junction development,neurotransmitter receptor metabolic process,olfactory learning CC: cytosol Basically then, if a term appears more than “by chance” in a gene list, it will be then significantly enriched. There are many online tools to do this type of analysis (http://cbl-gorilla.cs.technion.ac.il/, ) but here we will use the R package topGO. We will analyze the results from the RNA seq. It is important to know what to use as a background list of genes. In this case, any expressed gene in the cell-type we are analyzing. topGO requires a list of genes with an indicator of 1 for the genes that should be taken into the analysis and the rest with 0. The full list of genes will be used as background. To get the list of expressed genes we will use the fact that DeSeq2 actually puts NA in the padjusted column to the lowly expressed genes. #Libraries library(&quot;topGO&quot;) library(&quot;org.Dm.eg.db&quot;) #Prepare list of genes that are expressed, complete cases will get rid of the genes with NAs genes&lt;-as.data.frame(res.ZT3vsZT15.DN1_df$gene_name[complete.cases(res.ZT3vsZT15.DN1_df)]) names(genes)&lt;-&quot;gene_name&quot; #Add the indicator genes$ind=0 genes$ind[genes$gene_name %in% sig_up] = 1 alg &lt;- factor( as.integer( genes$ind ) ) names(alg) &lt;- genes$gene_name onts = c( &quot;MF&quot;, &quot;BP&quot;, &quot;CC&quot; ) tab = as.list(onts) listGOtab = as.list(onts) names(tab) = onts #For loop going over the 3 GO term sets for(e in 1:3){ #start topGO data tgd &lt;- new( &quot;topGOdata&quot;, ontology=onts[e], allGenes = alg, nodeSize=5, annot=annFUN.org, mapping=&quot;org.Dm.eg.db&quot;, ID = &quot;symbol&quot; ) listGO = genesInTerm(tgd) resultTopGO.elim &lt;- runTest(tgd, algorithm = &quot;elim&quot;, statistic = &quot;Fisher&quot; ) resultTopGO.classic &lt;- runTest(tgd, algorithm = &quot;classic&quot;, statistic = &quot;Fisher&quot; ) tab[[e]] &lt;- GenTable( tgd, Fisher.elim = resultTopGO.elim, Fisher.classic = resultTopGO.classic, orderBy = &quot;Fisher.classic&quot;, topNodes = 100) tab[[e]]$FDR&lt;-p.adjust(tab[[e]]$Fisher.classic,method = &quot;fdr&quot;) #I correct the pvalues tab[[e]]$ontology=onts[e] } allGO = rbind (as.data.frame(tab[[2]]),as.data.frame(tab[[1]]),as.data.frame(tab[[3]])) write.table(allGO, paste0(&quot;GOterm.txt&quot;),sep = &quot;\\t&quot; , row.names=F) 6.5 Extra: negative binomial model The model would be then: counts Kij for gene i, sample j are modeled using a negative binomial distribution with fitted mean μij and a gene-specific dispersion parameter αi. The fitted mean is composed of a sample-specific size factor sj and a parameter qij proportional to the expected true concentration of fragments for sample j. \\[ K_{ij}∼NB(μ_{ij},α_i) \\] \\[ μij=s_jq_{ij} \\] 6.6 Activity Finish the analysis for the other cell-types. Find a way to compare the results (hint: look at dendrograms) 6.7 Resources and Bibliography Dubowy C, Sehgal A. Circadian Rhythms and Sleep in Drosophila melanogaster. Genetics. 2017;205(4):1373-1397. doi:10.1534/genetics.115.185157 MEIRELES-FILHO, Antonio Carlos Alves and KYRIACOU, Charalambos Panayiotis. Circadian rhythms in insect disease vectors. Mem. Inst. Oswaldo Cruz [online]. 2013, vol.108, suppl.1 [cited 2020-07-08], pp.48-58. Abruzzi KC, Zadina A, Luo W, Wiyanto E, Rahman R, Guo F, et al. (2017) RNA-seq analysis of Drosophila clock and non-clock neurons reveals neuron-specific cycling and novel candidate neuropeptides. PLoS Genet 13(2): e1006613. https://doi.org/10.1371/journal.pgen.1006613 Schubert FK, Hagedorn N, Yoshii T, Helfrich-Förster C, Rieger D. Neuroanatomical details of the lateral neurons of Drosophila melanogaster support their functional role in the circadian system. J Comp Neurol. 2018;526(7):1209-1231. doi:10.1002/cne.24406 DeSeq2 documentations: http://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html Introduction to implementation steps of MetaCycle Gang Wu, Ron Anafi, Michael Hughes, Karl Kornacker, and John Hogenesch 2015-12-04 https://cran.r-project.org/web/packages/MetaCycle/vignettes/implementation.html Gene Ontology overview http://geneontology.org/docs/ontology-documentation/ "],
["circadian-analysis.html", "Lab 7 Circadian analysis 7.1 Objectives 7.2 Introduction 7.3 Cycling genes analysis 7.4 Cycling genes analysis normalizing by maximum 7.5 Activity 7.6 Resources and Bibliography", " Lab 7 Circadian analysis 7.1 Objectives After this section you should be able to: Analyze circadian data doing different normalization techniques. Plot circadian data in different formats. 7.2 Introduction In this chapter we will continue re-analyzing some data from Abruzzi et al, 2017. These are data that explore gene expression in different neuronal cell types in a circadian layout. Circadian behavior Most living organisms change their behavior and metabolism over the day. Some animals like us have more activity over the day while others like mice have more activity over night. Flies in particular have a peak of activity the first hours of the morning and the last hours of the afternoon with a “siesta” (nap in Spanish) at the middle of the day. Figure 7.1: Fly activity over the day. Adapted from Nicholas R. J Glossop et al 2011. To meassure fly activity each individual fly is monitored either by counting when they cross a red-light bim (regular activity monitors) of by software tracking (flyboxes). These changes in behavior are govern by changes in gene expression in particular cell-types in the brain called the pace-makers. If we look at gene expression in these cells over the day we will notice that some genes oscillate. Like Clk and tim, the proteins we analyzed in the previous Lab. In the circadian field time is reported as “hours after the light is ON”. This is zeitgeber time (ZT) and it is useful to have a unified measurement of time. Most animals in labs are kept in 12 hours of light followed by 12 hours of dark. Therefore, ZT0 is the “sunrise” or lights on and ZT12 is lights off in a light/dark (LD)12:12 cycle time. Figure 7.2: Fly activity over the day with ZT scale. Figure adapted from Dubowy et al 2017 As stated before, circadian behaviors is generated by a small subset of neurons. Figure 3.17: Schematic representation of the circadian neural network. Four small ventrolateral neurons (s‐LNvs, red), the 5th s‐LNv (dark violet), four large ventrolateral neurons (l‐LNvs, brown), six dorsolateral neurons (LNds, orange), three lateral posterior neurons (LPN, green), and ca. 60 neurons per hemisphere in three dorsal groups (DN1–3, lilac, cyan, blue, respectively). Adapted from Schubert et al 2018 In the data analyzed in this lab, the authors collected RNA samples over 6 times of the day (ZT3, 7, 11, 15, 19, 23) from 4 cell-types: LNv, LNd, DN1 and Dopaminergic neurons (TH cells). This last group of cells are not part of the circadian core clock but in this study they see oscillating genes! Packages: We will use the following packages. library(ggplot2) #for 2D graph library(ggrepel) #to get the names in ggplot graph library(gridExtra) #to arrange the plots library(factoextra) #extra plots library(plyr) #table manipulation library(dplyr)#table manipulation library(tidyr)#table manipulation library(&quot;RColorBrewer&quot;) #extra color palettes library(&quot;pheatmap&quot;) #nice heatmaps library(org.Dm.eg.db) #get annotation library(MetaCycle) # to identify cycling genes, the successor of JTK according to JTK authors library(pcaExplorer) #more PCA analysis 7.3 Cycling genes analysis As stated before, if we want to see cycling we have to look at repetitive patterns in the data cross the day. To determine cycling genes, different approaches can be done. But basically, the idea is to assess for each gene: 1.Identify cycling elements in the data. (ie which genes are changing between the timepoints) 2.If so, in which time point that particular gene has its peak. 3.Which is the amplitude and the period of the cycle: ie. how pronounced is the peak and how often it is cycling. One popular algorithm used is JTK And its description says: “Its purpose is to identify rhythmic components in large, genome-scale data sets and estimate their period length, phase, and amplitude” We will use the library: MetaCycle It is the successor of JTK according to JTK authors and it incorporates different approaches: “Using the same input file, MetaCycle::meta2d implements ARSER (ARS), JTK_CYCLE (JTK) and Lomb-Scargle (LS), from dramatically different disciplines, computer science, statistics and physics, respectively. Three independent algorithms (ARS, JTK and LS) were then selected from best of breed methods (Deckard et al., 2013; Wu et al., 2014). If set analysisStrategy as”auto“(default), it will automatically select proper method from cycMethod for each input dataset” There is a nice tutorial only from the CRAN repository And of course you can always use the internal R help ?meta2d #We already have the tables prepared head(DN1_gene_expression) ## Symbol DN1_ZT3_1 DN1_ZT7_1 DN1_ZT11_1 DN1_ZT15_1 DN1_ZT19_1 DN1_ZT23_1 ## 1 FBtr0070202 0 0 0 0 0 0 ## 2 FBtr0070207 0 0 0 0 14 0 ## 3 FBtr0070238 0 0 0 0 21 0 ## 4 FBtr0070251 0 0 0 0 0 0 ## 5 FBtr0070484 0 0 0 0 0 0 ## 6 FBtr0070489 0 0 0 0 0 0 ## DN1_ZT3_2 DN1_ZT7_2 DN1_ZT11_2 DN1_ZT15_2 DN1_ZT19_2 DN1_ZT23_2 ## 1 0 0 0 0 0 0 ## 2 0 0 0 0 16 7 ## 3 0 0 0 0 15 9 ## 4 0 0 1 0 2 0 ## 5 0 0 0 0 0 1 ## 6 0 0 0 0 0 0 This is the raw data, but we should use the normalized one. head(counts(dds.DN1, normalized=T)) ## DN1_ZT3_1 DN1_ZT7_1 DN1_ZT11_1 DN1_ZT15_1 DN1_ZT19_1 DN1_ZT23_1 ## FBtr0070202 0 0 0 0 0.000000 0 ## FBtr0070207 0 0 0 0 7.039025 0 ## FBtr0070238 0 0 0 0 10.558537 0 ## FBtr0070251 0 0 0 0 0.000000 0 ## FBtr0070484 0 0 0 0 0.000000 0 ## FBtr0070489 0 0 0 0 0.000000 0 ## DN1_ZT3_2 DN1_ZT7_2 DN1_ZT11_2 DN1_ZT15_2 DN1_ZT19_2 DN1_ZT23_2 ## FBtr0070202 0 0 0.000000 0 0.0000000 0.000000 ## FBtr0070207 0 0 0.000000 0 5.6437621 12.719245 ## FBtr0070238 0 0 0.000000 0 5.2910269 16.353315 ## FBtr0070251 0 0 2.947736 0 0.7054703 0.000000 ## FBtr0070484 0 0 0.000000 0 0.0000000 1.817035 ## FBtr0070489 0 0 0.000000 0 0.0000000 0.000000 If you read the specifications of meta2d, you need the first column to be the gene name. Lets do it. We can do it wiht base R or with specific packages. 7.3.1 Prepare the tables We need now to write them in an outside file and run the command. Note that you might be able to use the original data, this is just to keep on learning how to manage the data. DN1_gene_expression_norm &lt;-as.data.frame(counts(dds.DN1, normalized=T)) DN1_gene_expression_norm &lt;- cbind(Genes = rownames(DN1_gene_expression_norm), DN1_gene_expression_norm) write.csv(DN1_gene_expression_norm, file=&quot;cycDN1.csv&quot;, row.names=FALSE) 7.3.2 Meta2d DN1_cyc &lt;- meta2d(infile=&quot;cycDN1.csv&quot;,filestyle=&quot;csv&quot;, timepoints=(rep(c(3,7,11,15,19,23),2)),outputFile=FALSE,outRawData=F) ## The JTK is in process from 21:14:19 08-30-2020 ## Warning: the input &#39;maxper&#39; is not suitable for JTK, it was reset as 24 ## The analysis by JTK is finished at 21:14:45 08-30-2020 ## The LS is in process from 21:14:45 08-30-2020 ## The analysis by LS is finished at 21:20:08 08-30-2020 ## DONE! The analysis about &#39; cycDN1.csv &#39; has been finished. ## user.self sys.self elapsed user.child sys.child ## &quot;Time used:&quot; &quot;356.725&quot; &quot;12.003&quot; &quot;370.861&quot; &quot;0&quot; &quot;0&quot; As we can read in the help page ?meta2d the output of this function is: meta2d will write analysis results in different files under output directory (outdir) if set outputFile = TRUE. Files named with “ARSresult”, “JTKresult” and “LSreult” store analysis results from ARS, JTK and LS respectively. The file named with “meta2d” is the integration file, and it stores integrated values in columns with a common name tag-“meta2d”. The integration file also contains p-value, FDR value, period, phase(adjusted phase if adjustedPhase = “predictedPer”) and amplitude values calculated by each method. If outputFile = FALSE is selected, meta2d will return a list containing the following components: ARS analysis results from ARS method JTK analysis results from JTK method LS analysis results from LS method meta the integrated analysis results as mentioned above Let’s explore the results head(DN1_cyc$JTK) ## CycID BH.Q ADJ.P PER LAG AMP ## 1 FBtr0070202 1 1 0 0 0 ## 2 FBtr0070207 1 1 0 0 0 ## 3 FBtr0070238 1 1 0 0 0 ## 4 FBtr0070251 1 1 0 0 0 ## 5 FBtr0070484 1 1 0 0 0 ## 6 FBtr0070489 1 1 0 0 0 head(DN1_cyc$LS) ## CycID PhaseShift PhaseShiftHeight PeakIndex PeakSPD Period p ## 1 FBtr0070202 22.999926 0.000000 NA NA NA 1.0000000 ## 2 FBtr0070207 22.999922 6.795629 1 2.5714094 28 0.4706206 ## 3 FBtr0070238 22.999926 8.713640 1 2.4520804 28 0.5134413 ## 4 FBtr0070251 10.999996 1.473868 48 0.9032149 20 0.9843473 ## 5 FBtr0070484 7.721415 0.000000 1 1.2731542 28 0.9277372 ## 6 FBtr0070489 22.999926 0.000000 NA NA NA 1.0000000 ## N Nindependent Nyquist BH.Q ## 1 12 8 NA 1 ## 2 12 8 0.3 1 ## 3 12 8 0.3 1 ## 4 12 8 0.3 1 ## 5 12 8 0.3 1 ## 6 12 8 NA 1 head(DN1_cyc$meta) ## CycID JTK_pvalue JTK_BH.Q JTK_period JTK_adjphase JTK_amplitude ## 1 FBtr0070202 1 1 0 NaN 0 ## 2 FBtr0070207 1 1 0 NaN 0 ## 3 FBtr0070238 1 1 0 NaN 0 ## 4 FBtr0070251 1 1 0 NaN 0 ## 5 FBtr0070484 1 1 0 NaN 0 ## 6 FBtr0070489 1 1 0 NaN 0 ## LS_pvalue LS_BH.Q LS_period LS_adjphase LS_amplitude meta2d_pvalue ## 1 1.0000000 1 NA NA 0.000000 1.0000000 ## 2 0.4706206 1 28 22.999922 6.795629 0.8253288 ## 3 0.5134413 1 28 22.999926 8.713640 0.8557113 ## 4 0.9843473 1 20 10.999996 1.473868 0.9998769 ## 5 0.9277372 1 28 7.721415 0.000000 0.9973238 ## 6 1.0000000 1 NA NA 0.000000 1.0000000 ## meta2d_BH.Q meta2d_period meta2d_phase meta2d_Base meta2d_AMP meta2d_rAMP ## 1 1 NA NA 0.0000000 NA NA ## 2 1 28 22.999922 2.4093672 2.81516339 1.16842439 ## 3 1 28 22.999926 3.0549360 3.57379221 1.16984191 ## 4 1 20 10.999996 0.3720886 0.50175568 0.50175568 ## 5 1 28 7.721415 0.1560293 0.07341249 0.07341249 ## 6 1 NA NA 0.0000000 NA NA Clearly the “meta” is what we want. We can store it in another object to explore it in R or just write a table DN1_cyc_meta&lt;- as.data.frame(DN1_cyc$meta) #We will add the gene-names and then export it DN1_cyc_meta$transcript_name=DN1_cyc_meta$CycID DN1_cyc_meta=merge(DN1_cyc_meta,annotation_DN1,by=&quot;transcript_name&quot;) #the tim, clk and per: DN1_cyc_meta[which(DN1_cyc_meta$gene_name %in% c(&quot;tim&quot;,&quot;Clk&quot;,&quot;per&quot;)),] ## transcript_name CycID JTK_pvalue JTK_BH.Q JTK_period ## 368 FBtr0070477 FBtr0070477 0.0080482069 0.5867038 24 ## 5185 FBtr0076785 FBtr0076785 0.0285920047 0.8536843 20 ## 5743 FBtr0077567 FBtr0077567 0.0007025279 0.3232319 20 ## 15490 FBtr0100132 FBtr0100132 0.0285920047 0.8536843 20 ## 15491 FBtr0100134 FBtr0100134 0.0285920047 0.8536843 20 ## 26382 FBtr0332311 FBtr0332311 0.0285920047 0.8536843 24 ## 27307 FBtr0333252 FBtr0333252 0.0007025279 0.3232319 20 ## 27308 FBtr0333253 FBtr0333253 0.0007025279 0.3232319 20 ## 27309 FBtr0333254 FBtr0333254 0.0285920047 0.8536843 24 ## 27310 FBtr0333255 FBtr0333255 0.0285920047 0.8536843 24 ## 27311 FBtr0333256 FBtr0333256 0.0007025279 0.3232319 20 ## 27312 FBtr0333258 FBtr0333258 0.0007025279 0.3232319 20 ## 27313 FBtr0333259 FBtr0333259 0.0007025279 0.3232319 20 ## JTK_adjphase JTK_amplitude LS_pvalue LS_BH.Q LS_period LS_adjphase ## 368 13 305.3228 0.2045246 1 23.25088 12.95559 ## 5185 3 128.3993 0.4297392 1 27.76371 22.99993 ## 5743 13 1648.7247 0.0751332 1 23.08772 14.72816 ## 15490 3 128.3993 0.4297392 1 27.76371 22.99993 ## 15491 3 128.3993 0.4297392 1 27.76371 22.99993 ## 26382 13 318.0454 0.3542849 1 23.25088 14.29129 ## 27307 13 1648.7247 0.0751332 1 23.08772 14.72816 ## 27308 13 1648.7247 0.0751332 1 23.08772 14.72816 ## 27309 15 139.8126 0.1773643 1 22.15488 15.32424 ## 27310 15 139.8126 0.1773643 1 22.15488 15.32424 ## 27311 13 1648.7247 0.0751332 1 23.08772 14.72816 ## 27312 13 1648.7247 0.0751332 1 23.08772 14.72816 ## 27313 13 1648.7247 0.0751332 1 23.08772 14.72816 ## LS_amplitude meta2d_pvalue meta2d_BH.Q meta2d_period meta2d_phase ## 368 724.5210 0.0121962439 1.0000000 23.62544 12.98070 ## 5185 488.6181 0.0663405962 1.0000000 23.88186 23.62413 ## 5743 4366.7125 0.0005726614 0.4069818 21.54386 13.87341 ## 15490 488.6181 0.0663405962 1.0000000 23.88186 23.62413 ## 15491 488.6181 0.0663405962 1.0000000 23.88186 23.62413 ## 26382 790.6228 0.0566482210 1.0000000 23.62544 13.65932 ## 27307 4366.7125 0.0005726614 0.4069818 21.54386 13.87341 ## 27308 4366.7125 0.0005726614 0.4069818 21.54386 13.87341 ## 27309 320.8403 0.0318683270 1.0000000 23.07744 15.19288 ## 27310 320.8403 0.0318683270 1.0000000 23.07744 15.19288 ## 27311 4366.7125 0.0005726614 0.4069818 21.54386 13.87341 ## 27312 4366.7125 0.0005726614 0.4069818 21.54386 13.87341 ## 27313 4366.7125 0.0005726614 0.4069818 21.54386 13.87341 ## meta2d_Base meta2d_AMP meta2d_rAMP gene_name ## 368 404.2411 310.1832 0.7673221 per ## 5185 428.9183 455.0223 1.0608602 Clk ## 5743 1976.0053 1791.7205 0.9067387 tim ## 15490 428.9183 455.0223 1.0608602 Clk ## 15491 428.9183 455.0223 1.0608602 Clk ## 26382 420.1319 314.4002 0.7483370 per ## 27307 1976.0053 1791.7205 0.9067387 tim ## 27308 1976.0053 1791.7205 0.9067387 tim ## 27309 150.3703 156.7295 1.0422898 tim ## 27310 150.3703 156.7295 1.0422898 tim ## 27311 1976.0053 1791.7205 0.9067387 tim ## 27312 1976.0053 1791.7205 0.9067387 tim ## 27313 1976.0053 1791.7205 0.9067387 tim Export the results in a table write.table(x = DN1_cyc_meta, file=&quot;cycDN1_reults.txt&quot;,sep = &quot;\\t&quot;,row.names = F,col.names = T) 7.3.3 Plot the data. This it really useful to make plots. We will use the object created before. genes.cyc = DN1_cyc_meta$gene_name[c(DN1_cyc_meta$JTK_pvalue&lt;0.05 &amp; DN1_cyc_meta$JTK_amplitude&gt;128.3)]#you can put here as many genes as you want, I am seleceting genes with amplitud bigger than clock (Clk) #I pick the first 8 genes, but you can look at all of them. ggplot(toplot[toplot$gene_name %in% genes.cyc[1:8] ,],aes(x = as.numeric(ztime),y = value,color=gene_name,shape=rep)) + geom_point() + geom_line() Figure 7.3: Cycling genes. ggplot(toplot[toplot$gene_name %in% genes.cyc[1:8] ,],aes(x =ztime_2,y = value,color=gene_name,shape=rep)) + geom_point() + geom_line() Figure 7.4: Cycling genes. ggplot(toplot[toplot$gene_name %in% genes.cyc[1:8] ,],aes(x =ztime_2,y = value,color=gene_name,shape=rep)) + geom_point() + geom_line() + facet_wrap(scales = &quot;free&quot;,facets = ~gene_name ) Figure 7.5: Cycling genes. 7.4 Cycling genes analysis normalizing by maximum This is a more complex set-up I arrived after many trials this is way I found to get more reliable results: Before doing the analysis, I normalize the expression by the maximum level in each replicate. This mean that for all the replicates the levels will be between 0 and 1. I calculate the amplitude manually: this is just Maximum/Minimum. I share here some of the code to do it. Remove the genes that are all zeros x&lt;-DN1_gene_expression_norm # copy the DeSeq2 normalized reads ind=apply(x[-1], 1, function(x)(sum(x)&gt;0)) # remove the genes that are not expressed at all x=x[ind,] names(x) ## [1] &quot;Genes&quot; &quot;DN1_ZT3_1&quot; &quot;DN1_ZT7_1&quot; &quot;DN1_ZT11_1&quot; &quot;DN1_ZT15_1&quot; ## [6] &quot;DN1_ZT19_1&quot; &quot;DN1_ZT23_1&quot; &quot;DN1_ZT3_2&quot; &quot;DN1_ZT7_2&quot; &quot;DN1_ZT11_2&quot; ## [11] &quot;DN1_ZT15_2&quot; &quot;DN1_ZT19_2&quot; &quot;DN1_ZT23_2&quot; Separate by replicate x1&lt;-x[,c(1,grep(pattern = &quot;_1&quot;,names(x)))] x2&lt;-x[,c(1,grep(&quot;_2&quot;,names(x)))] Normalization by max x1&lt;-t(apply((x1[,-1]), 1, function(x)(x/max(x)))) #this is the function that normalize each gene by its maximum x1&lt;-cbind(as.data.frame(x$Gene),x1) names(x1)[1]=&quot;Gene&quot; x2&lt;-t(apply((x2[,-1]), 1, function(x)(x/max(x)))) Bind the replicates and run the meta2d x&lt;-cbind(x1,x2) x&lt;-x[complete.cases(x),] write.table(x, file=&quot;normtomax.csv&quot;, row.names=FALSE,sep = &quot;,&quot;) # Extract the times from the colnames timepoints=as.numeric(gsub(pattern = &quot;ZT&quot;, replacement = &quot;&quot;, sapply(strsplit(names(x)[-1],&quot;_&quot;),&quot;[[&quot;,2))) DN1_cyc_norm &lt;-meta2d(infile=&quot;normtomax.csv&quot;,filestyle=&quot;csv&quot;, timepoints=timepoints,outputFile=FALSE,outRawData=F) DN1_cyc_norm_meta2d &lt;- as.data.frame(DN1_cyc_norm$meta) ## The JTK is in process from 21:20:39 08-30-2020 ## Warning: the input &#39;maxper&#39; is not suitable for JTK, it was reset as 24 ## The analysis by JTK is finished at 21:21:01 08-30-2020 ## The LS is in process from 21:21:01 08-30-2020 ## The analysis by LS is finished at 21:25:12 08-30-2020 ## DONE! The analysis about &#39; normtomax.csv &#39; has been finished. ## user.self sys.self elapsed user.child sys.child ## &quot;Time used:&quot; &quot;279.973&quot; &quot;10.08&quot; &quot;293.003&quot; &quot;0&quot; &quot;0&quot; Calculate the amplitude manually for each replicate For this, create a function that merge the results from the cycling analysis and the read counts and calculates the amplitude manually. mean_nona=function(x){ mean(x,na.rm =TRUE) } merge_counts=function(cyc,cs){ cs$mean.exp=apply(cs[,-c(1)],1,mean_nona) cs=cs[order(cs$Gene),] cyc=cyc[order(cyc$CycID),] print(unique(cyc$CycID==cs$Gene)) #make sure the we are merging the same genes cyc&lt;-cbind(cyc, cs) toMatch &lt;- c(&quot;_1&quot;, &quot;_2&quot;) cyc$zero=(apply((cyc)[,grep(paste(toMatch,collapse=&quot;|&quot;),names(cyc))],1,function(x)(length(which(x %in% 0))&gt;1))) cyc=cyc[cyc$zero==F,] cyc$AMP_1=(apply((cyc)[,grep(&quot;_1&quot;,names(cyc))],1,function(x)(1/min(x)))) # amplitude for replicate 1 cyc$AMP_2=(apply((cyc)[,grep(&quot;_2&quot;,names(cyc))],1,function(x)(1/min(x)))) # amplitude for replicate 2 cyc$AMP_min=(apply((cyc)[,grep(&quot;^AMP&quot;,names(cyc))],1,function(x)(min(x)))) # get the minimum amplitude cyc$AMP_min[cyc$AMP_min==&quot;Inf&quot;]=10 # if the minimum is infinite (ie the minimum is cero), I set an arbitrary amplitude return(cyc) } DN1_cyc_norm_meta2d_mergecounts&lt;-merge_counts(cyc = DN1_cyc_norm_meta2d,cs = x) ## [1] TRUE 7.5 Activity Finish the analysis for the other cell-types. Find a way to compare the results (hint: look at dendrograms) Plot the data for the results of the normalized expression. 7.6 Resources and Bibliography Dubowy C, Sehgal A. Circadian Rhythms and Sleep in Drosophila melanogaster. Genetics. 2017;205(4):1373-1397. doi:10.1534/genetics.115.185157 MEIRELES-FILHO, Antonio Carlos Alves and KYRIACOU, Charalambos Panayiotis. Circadian rhythms in insect disease vectors. Mem. Inst. Oswaldo Cruz [online]. 2013, vol.108, suppl.1 [cited 2020-07-08], pp.48-58. Abruzzi KC, Zadina A, Luo W, Wiyanto E, Rahman R, Guo F, et al. (2017) RNA-seq analysis of Drosophila clock and non-clock neurons reveals neuron-specific cycling and novel candidate neuropeptides. PLoS Genet 13(2): e1006613. https://doi.org/10.1371/journal.pgen.1006613 Schubert FK, Hagedorn N, Yoshii T, Helfrich-Förster C, Rieger D. Neuroanatomical details of the lateral neurons of Drosophila melanogaster support their functional role in the circadian system. J Comp Neurol. 2018;526(7):1209-1231. doi:10.1002/cne.24406 DeSeq2 documentations: http://bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html Introduction to implementation steps of MetaCycle Gang Wu, Ron Anafi, Michael Hughes, Karl Kornacker, and John Hogenesch 2015-12-04 https://cran.r-project.org/web/packages/MetaCycle/vignettes/implementation.html Gene Ontology overview http://geneontology.org/docs/ontology-documentation/ "],
["single-cell-rna-seq.html", "Lab 8 Single cell RNA-seq 8.1 Objectives 8.2 Introduction 8.3 Packages used 8.4 Initialize the data 8.5 Quality filtering 8.6 Normalizing the data 8.7 Detection of variable genes across the single cells 8.8 Integrating ALL the samples. 8.9 Scaling the data and removing unwanted sources of variation 8.10 Perform linear dimensional reduction 8.11 Clustering 8.12 Visualization 8.13 Finding differentially expressed features (cluster biomarkers)", " Lab 8 Single cell RNA-seq 8.1 Objectives After this section you should be able to: Understand single cell RNA sequencing data. Do quality filtering. Perform clustering analysis and plots using Seurat. 8.2 Introduction In this class we will reanalyze single cell data on fruit fly brain from Cellular diversity in the Drosophila midbrain revealed by single-cell transcriptomics. Croset et al. elife 2018. Figure 4.1: Drop-seq reveals neuronal clusters in the Drosophila brain. (A) Schematic of the experimental procedure. Drosophila brains were dissected and dissociated prior to Drop-seq. After sequencing and alignment, a digital expression matrix containing information about the number of UMIs found for each gene, in each cell, was generated and used for PCA and subsequent analyses. See Materials and methods section for details. (B) Two-dimensional representation (t-SNE) of 10,286 Drosophila brain cells, manually classified into 28 clusters. Based on the recovery of cell-types of known abundance in the brain, we estimate that there are 45,000 cells in the fly midbrain. We will analyze only three of the samples so everything is easier to run. We will use the package Seurat that allows us to do everything in a user-friendly way. The single cell data structure is exactly like the RNA-seq data we saw in last chapter but in this case each sample is one individual cell. sc.small ## cell1 cell2 cell3 ... ## genA 0 43 22 92 ## genB 0 21 68 22 ## genC 9 10 54 36 ## ... 0 0 0 0 Other difference is that in this case we do not have a meta data file, we do not know anything about each cell before starting the analysis. And that is a key about our objectives with this data: Quality filtering Clustering analysis Cell type identification 8.3 Packages used Remember that if you need to install them you will have to try with install.packages() or BiocManager::install() before loading the library. In this case you will have to install Seurat for sure: BiocManager::install(\"Seurat\") library(Seurat) library(dplyr) library(Matrix) library(ggplot2) library(cowplot) library(patchwork) 8.4 Initialize the data We need to load the table and create the Seurat object. ## Initialize the Seurat object with the raw (non-normalized data) #We need to read the tables, change the file path accordingly dm.1&lt;- read.delim(file = &quot;./single_cell_WT/REPLICATE1.dge.txt.gz&quot;, header=T) dm.2&lt;- read.delim(file = &quot;./single_cell_WT/REPLICATE2.dge.txt.gz&quot;, header=T) dm.3&lt;- read.delim(file = &quot;./single_cell_WT/REPLICATE3.dge.txt.gz&quot;, header=T) #And do some manipulation. This is to put the data in the right format. #First, we remove the NA and replace it with 0. dm.1[is.na(dm.1)] =0 dm.2[is.na(dm.2)] =0 dm.3[is.na(dm.3)] =0 #Then, we store the data in another object and modify that. We put then the &quot;Gene&quot; column as rowname. d.dm.1 =dm.1 row.names(d.dm.1) = d.dm.1$GENE d.dm.1 = d.dm.1[,-1] d.dm.2 =dm.2 row.names(d.dm.2) = d.dm.2$GENE d.dm.2 = d.dm.2[,-1] d.dm.3 =dm.3 row.names(d.dm.3) = d.dm.3$GENE d.dm.3 = d.dm.3[,-1] #We finally initialize the Seurat object using this function: DM.1&lt;- CreateSeuratObject(counts = d.dm.1, project =&quot;DM.1&quot;, min.cells = 3, min.features = 200) DM.2&lt;- CreateSeuratObject(counts = d.dm.2, project =&quot;DM.2&quot;, min.cells = 3, min.features = 200) DM.3&lt;- CreateSeuratObject(counts = d.dm.3, project =&quot;DM.3&quot;, min.cells = 3, min.features = 200) #lets see what is this DM.1 What is min.cells = 3 and min.features = 200 doing? Why do you think this is important? 8.5 Quality filtering All data that you work with needs to be curated. This means to be filtered in a controlled and user-managed way. Not only in this type of data this is done. Any of you that has done a q-rt-pcr knows that some points are taken out. I will use a nice image from the internet: Figure 4.5: Why we should do quality filtering to the data. Origin unknown. So, which is the idea, what are the concerns we have with this type of data? Cells are no really cells (empty droplets). Cells are not sequenced deeply enough to get an idea of which separates one cell from another. Cells are broken. Doublets: More than two cells in one droplet. To solve each of these problems we have different strategies. This is usually discarded before the alignment. Cells with too low reads are not taken forward. We will select reads with more than certain amount of UMIs, in this case: 500UMIs per cells. This is usually addressed in the field by counting % of mitochondrial genes. If a cell is broken, many mRNAs will fall out but the mitochondrial RNA will stay. This is a tough one. Usually in the field people sequence cells from two different organisms and see how many cells have genes from both organisms, and say that they do not have a high percentage of Doublets. 8.5.1 Get number of genes captured and number of UMI (remember the difference between reads and UMI) They are both calculated automatically by Seurat and stored in an object called meta.data. In the new version of Seurat, they call features to genes and counts to the UMIs. This is because more and more the single cell data became not only RNA sequencing data but also images, DNA, etc. However, I will call them genes because we are only using RNA data. You can access that object using the @ simbol and runing in this case: We will use this object to inspect the data and see the distribution of them. ```r #Lets see how is it organized: head(DM.1@meta.data) ## orig.ident nCount_RNA nFeature_RNA ## CAAGAATTTTTC DM.1 21318 3001 ## AAAAAAAAAAAA DM.1 1339 1316 ## AGTCATCCGAGC DM.1 16101 2802 ## CAACACATGTAT DM.1 8323 2001 ## ATCTTTTTTTCG DM.1 4426 2178 ## TGAACTCTTGTC DM.1 6896 1946 What is each row? And each column? #We can explore the columns of this data, as any other data frame, with the $ sign. unique(DM.1@meta.data$orig.ident) #We can also see the distribution of the variables summary(DM.1@meta.data) #We can plot now the distribution of all the interesting things p1=ggplot(data=DM.1@meta.data, aes(x=nCount_RNA, fill=orig.ident)) + geom_density(alpha=0.3) + #xlim(c(0,2000))+ scale_fill_brewer(palette=&quot;Dark2&quot;) + theme_minimal()+ labs(main=&quot;nUMI&quot;) p2=ggplot(data=DM.1@meta.data, aes(x=nFeature_RNA, fill=orig.ident)) + geom_density(alpha=0.3) + #xlim(c(0,500))+ scale_fill_brewer(palette=&quot;Dark2&quot;) + theme_minimal()+ labs(main=&quot;nGene&quot;) plot_grid(p1,p2) Figure 8.1: CAPTION THIS FIGURE!! #We can also see how is the realtion between nGenes and nUMI p3=ggplot(data = DM.1@meta.data ,aes(y = nFeature_RNA, x = nCount_RNA,color=orig.ident)) + geom_point(dotsize=0.5, alpha=0.5) + scale_fill_brewer(palette=&quot;Dark2&quot;) + theme_minimal() p4=ggplot(data = DM.1@meta.data ,aes(y =nFeature_RNA, x = nCount_RNA,color=orig.ident)) + geom_point(dotsize=0.5, alpha=0.5) + scale_fill_brewer(palette=&quot;Dark2&quot;) + theme_minimal() + xlim(0,1000) + ylim(0,1000) plot_grid(p3,p4,labels = c(&quot;nGene_vs_nUMI&quot;,&quot;zoom&quot;)) Figure 8.2: CAPTION THIS FIGURE!! ## [1] DM.1 ## Levels: DM.1 ## orig.ident nCount_RNA nFeature_RNA ## DM.1:907 Min. : 702 Min. : 200.0 ## 1st Qu.: 967 1st Qu.: 545.0 ## Median : 1443 Median : 724.0 ## Mean : 1928 Mean : 816.8 ## 3rd Qu.: 2383 3rd Qu.: 997.5 ## Max. :21318 Max. :3001.0 What is each point? How did we achieve the zoom? Why is there is cut at 200? Try it with the other replicates, what do you see? Can you think of a way to have them all together in the same plot? 8.5.2 Calculate percentage of mitochondrial genes: We calculate it as the proportion. Unfortunately we can see in our data that the mitochondrial genes are not included in the gene mapping. We are interested in the genes encoded by the mitochondrial genome. These are named in a particular way. You can explore them in FlyBase and in UCSC For this we will use a function named grep that is used to extract elements that contain certain pattern from a vector or list. #nGene and nUMI are automatically calculated for every object by Seurat. For non-UMI data. ## We calculate the percentage of mitochondrial genes here and store it in percent.mito using the AddMetaData. The % of UMI mapping to MT-genes is a common scRNA-seq QC metric. #We can explore the genes in each object rownames(DM.1@assays$RNA)[1:5] #mitochondrial genes have certain pattern grep(pattern = &quot;^mt-&quot;,x= rownames(DM.1@assays$RNA), value = T) #Here we are taking the data that actually is mitochondrial genes #We will try with some other names for the mitochondrial genes: http://flybase.org/reports/FBgn0013676 for example grep(&quot;CO&quot;,x= rownames(DM.1@assays$RNA), value = T) grep(&quot;co&quot;,x= rownames(DM.1@assays$RNA), value = T) ## [1] &quot;128up&quot; &quot;14-3-3epsilon&quot; &quot;14-3-3zeta&quot; ## [4] &quot;140up&quot; &quot;18SrRNA-Psi:CR41602&quot; ## character(0) ## [1] &quot;COQ7&quot; &quot;COX4&quot; &quot;COX5A&quot; &quot;COX5B&quot; &quot;COX6B&quot; ## [6] &quot;COX7A&quot; &quot;COX7C&quot; &quot;COX8&quot; &quot;SCOT&quot; &quot;alphaCOP&quot; ## [11] &quot;betaCOP&quot; &quot;betapCOP&quot; &quot;deltaCOP&quot; &quot;epsilonCOP&quot; &quot;gammaCOP&quot; ## [16] &quot;zetaCOP&quot; ## [1] &quot;Acon&quot; &quot;Acox57D-p&quot; &quot;Glycogenin&quot; &quot;Mco1&quot; &quot;Ncoa6&quot; ## [6] &quot;Orco&quot; &quot;Orcokinin&quot; &quot;Picot&quot; &quot;Scox&quot; &quot;chico&quot; ## [11] &quot;coil&quot; &quot;cold&quot; &quot;colt&quot; &quot;comm&quot; &quot;comt&quot; ## [16] &quot;conu&quot; &quot;cora&quot; &quot;corn&quot; &quot;coro&quot; &quot;cort&quot; ## [21] &quot;corto&quot; &quot;cos&quot; &quot;dco&quot; &quot;disco&quot; &quot;disco-r&quot; ## [26] &quot;eco&quot; &quot;loco&quot; &quot;pico&quot; #The CO3 is not there, you can try this for all of the mitochondrial genes. #Anyways, once you have a list this is the way to proceed (we will not do this because we do not have the genes in the annotation): percent.mito &lt;- grep(&quot;^mt-&quot;,x= rownames(DM.1@assays$RNA), value = T) percent.mito &lt;- colSums(DM.1@raw.data[mito.genes, ])/colSums(ALL@raw.data) DM.1[[&quot;percent.mt&quot;]] &lt;- AddMetaData(DM.1, percent.mito, &quot;percent.mito&quot;) #Or this other way DM.1[[&quot;percent.mt&quot;]] &lt;- PercentageFeatureSet(DM.1, pattern = &quot;^mt-&quot;) 8.5.3 Removing low quality cells We will do the same cutoff as the paper: nUMI&gt;700, I added the nGene&gt;100 #How many cells there are? nrow(DM.1@meta.data) #Subset in ALL the data sets DM.1 &lt;- subset(DM.1, subset = nFeature_RNA &gt; 100 &amp; nCount_RNA&gt; 700) #How many cells are now? nrow(DM.1@meta.data) ## [1] 907 ## [1] 907 8.6 Normalizing the data Now we want to normalize the data. Remember that in the previous chapter we normalized by library depth to able to compare the different samples. For single cell we do the same but a different way. Seurat uses a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression (like library depth), multiplies this by a scale factor (this helps to increase the level, as in single cell the gene expression is really low), and log-transforms the result (this helps reduce the variability). DM.1 &lt;- NormalizeData(object = DM.1, normalization.method = &quot;LogNormalize&quot;, scale.factor = 10000,verbose = F) 8.7 Detection of variable genes across the single cells To be able to differentiate once cell from another we need to focus in the genes that are different between cells and not in the ones that are similar. For example, if we want to differentiate two neurons from each other looking at the levels of actin makes no much sense, but looking at the genes that have different levels in these neurons can be indicative of the identity of them. Seurat calculates highly variable genes and focuses on these for downstream analysis. FindVariableGenes calculates the average expression and dispersion for each gene. This helps control for the relationship between variability and average expression. Then we decide how many genes to get. The default is 2000. Please look at the data and try to understand what each axis means. DM.1 &lt;- FindVariableFeatures(DM.1, selection.method = &quot;vst&quot;, nfeatures = 2000,verbose = F) ## Identify the 10 most highly variable genes top10 &lt;- head(VariableFeatures(DM.1), 10) ## plot variable features with and without labels plot1 &lt;- VariableFeaturePlot(DM.1) plot2 &lt;- LabelPoints(plot = plot1, points = top10, repel = TRUE) plot2 Figure 8.3: Variable genes plot What are the top 10 genes? Make sense that they appear in this data? 8.8 Integrating ALL the samples. We have more than one replicate. Seurat has recently implemented a new way to integrate different data sets. This imply looking at the similitude between cells after normalization and variable genes. For that they create a set of anchores between the cells. This is used to integrate replicates, different data types, etc. Figure 8.4: Figure from: Comprehensive Integration of Single-Cell Data, Stuart et al. Cell 2019 Therefore, to integrate this data we will: 1. Do the same processing we just did for all of them (normalization and variable genes). 2. Find the anchors and create a new integrated object. This integrated object has a new Assay with the integrated (or ‘batch-corrected’) expression matrix for all cells. This allows for an easier and better joint analysis. #create a list dm.list&lt;-list(DM.1,DM.2,DM.3) #do a FOR loop to loop over all of them for (i in 1:length(dm.list)) { dm.list[[i]] &lt;- subset(dm.list[[i]], subset = nFeature_RNA &gt; 100 &amp; nCount_RNA&gt; 700) dm.list[[i]] &lt;- NormalizeData(dm.list[[i]], verbose = FALSE) #normalize dm.list[[i]] &lt;- FindVariableFeatures(dm.list[[i]], selection.method = &quot;vst&quot;, nfeatures = 2000, verbose = FALSE) #find variable genes } #Find anchors anchors &lt;- FindIntegrationAnchors(object.list = dm.list, dims = 1:30,verbose = F) ALL &lt;- IntegrateData(anchorset = anchors, dims = 1:30,verbose = F) #remove the anchors, they are too big and we will not use them anymore rm(anchors) head(as.data.frame(ALL@meta.data)) head(unique(ALL@meta.data$orig.ident)) ## orig.ident nCount_RNA nFeature_RNA ## CAAGAATTTTTC_1 DM.1 21318 3001 ## AAAAAAAAAAAA_1 DM.1 1339 1316 ## AGTCATCCGAGC_1 DM.1 16101 2802 ## CAACACATGTAT_1 DM.1 8323 2001 ## ATCTTTTTTTCG_1 DM.1 4426 2178 ## TGAACTCTTGTC_1 DM.1 6896 1946 ## [1] &quot;DM.1&quot; &quot;DM.2&quot; &quot;DM.3&quot; How does the meta.data looks like now? how many “orig.ident” there are? We can plot the quality plots now and compare the replicates ggplot(data = ALL@meta.data ,aes(y =nFeature_RNA, x = nCount_RNA,color=orig.ident)) + geom_point(dotsize=0.5, alpha=0.5) + scale_fill_brewer(palette=&quot;Dark2&quot;) + theme_minimal() Figure 8.5: Number of Genes and Number of UMIs p1=ggplot(data=ALL@meta.data, aes(x=nCount_RNA, fill=orig.ident)) + geom_density(alpha=0.3) + #xlim(c(0,2000))+ scale_fill_brewer(palette=&quot;Dark2&quot;) + theme_minimal()+ labs(main=&quot;nUMI&quot;) p2=ggplot(data=ALL@meta.data, aes(x=nFeature_RNA, fill=orig.ident)) + geom_density(alpha=0.3) + #xlim(c(0,500))+ scale_fill_brewer(palette=&quot;Dark2&quot;) + theme_minimal()+ labs(main=&quot;nGene&quot;) plot_grid(p1,p2) Figure 8.6: Number of Genes and Number of UMIs Try to describe in your own words what is this for loop doing. What are the dimensions in the integration? 8.9 Scaling the data and removing unwanted sources of variation Scale the data allows for better comparison. Basically, it takes care of the differences between genes that are highly expressed and lowly expressed. Z-score is a commonly used method to scale the data. To sum up: 1. Shifts the expression of each gene, so that the mean expression across cells is 0 2. Scales the expression of each gene, so that the variance across cells is 1 This step gives equal weight in downstream analyses, so that highly-expressed genes do not dominate. Single-cell data has sources of variation that are not biologically interesting. For example, each sample was prepared in a different batch (batch effect, already reduced by the integration), some cells are just more deeply sequenced (we already took care of these with normalization) or some cells are just healthier than others or in another cell cycle state (not important for brain data but super important for other data sets). We can regress out cell-cell variation in gene expression driven by batch (if applicable), cell alignment rate (as provided by Drop-seq tools for Drop-seq data), the number of detected molecules, and mitochondrial gene expression. As we just said, we took care of most of the problems. But if you want, there is an option in this function that allows you to do that. ALL &lt;-ScaleData(object = ALL,verbose = F) 8.10 Perform linear dimensional reduction Dimensional reduction literally means that: reduce dimensions. This means that we will use less variables. This was already done by reducing the number of genes we will use for downstream analysis. Now we apply another one that you already saw and that is useful for clustering: PCA. So, we will perform PCA on the scaled data using the 2000 more variable genes. You can play with the number of genes using the feature option. ## switch to integrated assay. The variable features of this assay are automatically ## set during IntegrateData DefaultAssay(ALL) &lt;- &quot;integrated&quot; ## Run the standard workflow for visualization and clustering ALL &lt;- ScaleData(ALL, verbose = FALSE) #The scaling is now done on the integrated data #Run the PCA, npcs is the maximum PCs computed ALL &lt;- RunPCA(ALL, npcs = 30, verbose = FALSE) ## Visualizing the PCs and determine the significance ElbowPlot(ALL,ndims = 30) + geom_hline(yintercept = 2,linetype=2) Figure 8.7: PCA plots does this plot ring any bell? How many PCs would you select? p1=DimPlot(ALL, reduction = &quot;pca&quot;,dims = c(1,2)) p2=DimPlot(ALL, reduction = &quot;pca&quot;,dims = c(2,3)) p3=DimPlot(ALL, reduction = &quot;pca&quot;,dims = c(2,5)) p4=DimPlot(ALL, reduction = &quot;pca&quot;,dims = c(21,3)) p1+p2+p3+p4 Figure 8.8: PCA plots What about this? What are we looking for here? #Other way to see this DimHeatmap(ALL, dims = 1:6, cells = 500, balanced = TRUE) Figure 8.9: PCA heatmap plots Are 2 dimensions enough to descrive the data? 8.11 Clustering Once you have explored the PCs, you can do the clustering an visualization. We will use all the 30 PCs. There are many ways to cluster data. The main idea is to be able to identify the points that are more similar to each other and the ones that are more different from each other. Seurat calculates the distance/similarity between cells in the function FindNeighbors. This performs a KNN graph based on the Euclidean distance in PCA space (this means using the PCs values and NOT the gene values), and refine the edge weights between any two cells based on the shared overlap in their local neighborhoods (Jaccard similarity). To cluster the cells Surat can use different algorithms in the function FindClusters. As default it uses Louvain algorithm. The main idea is to iteratively group cells together. One of the most important things to tune in this function is the resolution. This will impact the number of final clusters. In out case we expect to have a LOT of clusters because we are working with a complex tissue. ALL &lt;- FindNeighbors(ALL, dims = 1:30,reduction = &quot;pca&quot;) #What are these dimensions? ALL &lt;- FindClusters(ALL, resolution = 3) #explore the meta data now, what is new now? as.data.frame(head(ALL@meta.data)) ## Modularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck ## ## Number of nodes: 2573 ## Number of edges: 123835 ## ## Running Louvain algorithm... ## Maximum modularity in 10 random starts: 0.5747 ## Number of communities: 27 ## Elapsed time: 0 seconds ## orig.ident nCount_RNA nFeature_RNA integrated_snn_res.3 ## CAAGAATTTTTC_1 DM.1 21318 3001 14 ## AAAAAAAAAAAA_1 DM.1 1339 1316 26 ## AGTCATCCGAGC_1 DM.1 16101 2802 8 ## CAACACATGTAT_1 DM.1 8323 2001 21 ## ATCTTTTTTTCG_1 DM.1 4426 2178 12 ## TGAACTCTTGTC_1 DM.1 6896 1946 10 ## seurat_clusters ## CAAGAATTTTTC_1 14 ## AAAAAAAAAAAA_1 26 ## AGTCATCCGAGC_1 8 ## CAACACATGTAT_1 21 ## ATCTTTTTTTCG_1 12 ## TGAACTCTTGTC_1 10 8.12 Visualization To visualize this data, as we already saw, PC is not enough. So, we need to find a way to visualize the clusters in the 30! PCs we used for clustering. For this we will use UMAP. You can think of it as a compressed version of the 30PCs. ALL &lt;- RunUMAP(ALL, reduction = &quot;pca&quot;, dims = 1:30) #explore the meta data now, what is new now? as.data.frame(head(ALL@meta.data)) #Plot DimPlot(object = ALL,label = T) Figure 8.10: UMAP plot p1 &lt;- DimPlot(ALL, reduction = &quot;umap&quot;, group.by = &quot;orig.ident&quot;) #we can color the cells based on any of the things in the meta.data p2 &lt;- DimPlot(ALL, reduction = &quot;umap&quot;, label = T,repel = TRUE) + NoLegend() p1 + p2 Figure 8.11: UMAP plot ## orig.ident nCount_RNA nFeature_RNA integrated_snn_res.3 ## CAAGAATTTTTC_1 DM.1 21318 3001 14 ## AAAAAAAAAAAA_1 DM.1 1339 1316 26 ## AGTCATCCGAGC_1 DM.1 16101 2802 8 ## CAACACATGTAT_1 DM.1 8323 2001 21 ## ATCTTTTTTTCG_1 DM.1 4426 2178 12 ## TGAACTCTTGTC_1 DM.1 6896 1946 10 ## seurat_clusters ## CAAGAATTTTTC_1 14 ## AAAAAAAAAAAA_1 26 ## AGTCATCCGAGC_1 8 ## CAACACATGTAT_1 21 ## ATCTTTTTTTCG_1 12 ## TGAACTCTTGTC_1 10 How many clusters we have? Do you think this is enough? Any explanation? 8.13 Finding differentially expressed features (cluster biomarkers) What is missing now? Basically, we want to identify the genes that makes one cluster different from the rest. How would you do it? FindAllMarkers is the function that does the job. Is basically doing a differential gene expression between the clusters. Important parameters: 1. The min.pct argument determines that the genes reported have to be detected at a minimum percentage in either of the two groups of cells 2. The logfc.threshold is setting a threshold in the foldchange of he reported genes. 3. The only.pos argument determine if the reported genes will be only the ones with a positive foldchange in the cluster (important for markers). There is an option to compare cluster by cluster. This is useful for example if you want to focus in one cluster for some reason. FindMarkers function where ident.1 and ident.2 will be compared. ## find markers for every cluster compared to all remaining cells, report only the positive ones markers.all &lt;- FindAllMarkers(ALL, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25,verbose = F) top10.markers.all &lt;- markers.all %&gt;% group_by(cluster) %&gt;% top_n(n = 10, wt = avg_logFC) #what do you think this is doing? #Visualization DoHeatmap(ALL, features = top10.markers.all$gene) + NoLegend() Figure 6.2: Heatmap of marker genes per cluster #If you want to save ALL the data in an object you can share with anyone and with yourself in the future :) #save.image(file = &quot;sc_class.RData&quot;) What are the colors representing here? Try to play with them. Do you think all the clusters are equally important? What happens in cluster 0? There are other ways to visualize this. Please go to https://satijalab.org/seurat/v3.1/pbmc3k_tutorial.html and explore other options. Pickup one cluster and determine the cell identity in biological terms. How do think this can be done? As a note of color: Who was Seurat and why do you think the single cell package is names after him? Here a small hint. Figure 5.2: A Sunday Afternoon on the Island of La Grande Jatte or Un dimanche après-midi à l’Île de la Grande Jatte, Georges Seurat, Oil on canvas, 1884–1886 "]
]
